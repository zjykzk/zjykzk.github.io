<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>mq on 老K随笔</title>
    <link>http://zjykzk.github.io/tags/mq/</link>
    <description>Recent content in mq on 老K随笔</description>
    <generator>Hugo -- gohugo.io</generator>
    <managingEditor>zhangkai.zju@gmail.com (zenk)</managingEditor>
    <webMaster>zhangkai.zju@gmail.com (zenk)</webMaster>
    <copyright>(c) 2017 zenk.</copyright>
    <lastBuildDate>Fri, 25 Jan 2019 15:35:52 +0800</lastBuildDate><atom:link href="http://zjykzk.github.io/tags/mq/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>RocketMQ HA实现</title>
      <link>http://zjykzk.github.io/posts/cs/rocketmq/ha/</link>
      <pubDate>Fri, 25 Jan 2019 15:35:52 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/posts/cs/rocketmq/ha/</guid>
      <description>HA原理 RocketMQ支持主结点的数据同步到从结点。同步的数据依赖于当前从结点的状态。从结点连接到主结点的时候会上报自己的当前commitlog的最大偏移量。主结点收到以后会根据这个值计算出传输的起始位置，如果上报的commitlog的最大偏移量：
 等于0，主结点会从当前最大偏移量减去一个log文件大小那个位置开始传输。如果小于0，那么从0开始传输。 大于0，从该值开始传输。 小于0，这种情况不存在。  所以，这里我们可以知道如果从结点已经就有数据情况，如果数据不是从主结点同步过来的，那么同步之后就会有问题了。比如说：从结点已经有10000条数据，同时某个topic，暂时就叫OLD_TOPIC的消费队列0长度1000。这个时候，主结点就会从第10000条数据开始同步，可能会发送几种情况：
 主结点没有10000数据，那么就不会同步数据，造成从结点上面数据丢失。 主结点有超过10000数据，但是它的OLD_TOPIC的消费队列0的长度小于1000，那么同步过来的数据就会覆盖原来的数据。  所以，从结点的初始状态需要从0开始或者本来就是和主同步过的状态。因此，在删除topic的时候从结点要保证删除干净，不然从结点就会脏数据，影响消费。
为什么这样同步不会有问题呢？
那是因为同步的数据里面包含了具体消费队列ID，队列中的偏移量以及消息的偏移量，所以同步的时候能够写到同一个位置。
主结点同步逻辑 发送一条消息的时候，在开启SYNC_MASTER情况下，需要四个线程合作才能完成消息的发送。
 SendMessageProcessor负责处理接收发送消息的请求并落盘（异步或者同步），接着向GroupTransferService发送等待同步完成的请求，然后等待知道超时或者GroupTransferService通知同步完成。同时，还会同时WriteSocketService有数据可以写了。 WriteSocketService负责根据从结点上报的位置（变量slaveRequestOffset），不断的向从结点传输数据。同时会维护和从结点的一个心跳，如果一段时间没有通不过数据，就会发送一个消息头，包含当前同步的起始位置。 GroupTransferService不断的轮询比较当前已经被从结点同步的最大偏移（变量push2SlaveMaxOffset）和SendMessageProcessor发送过来的请求中包含的偏移量，如果大于或者等于就会通知SendMessageProcessor。 ReadSocketService负责读取从结点上报上来的同步偏移量。更新变量push2SlaveMaxOffset和slaveRequestOffset并通知GroupTransferService。从而，它也会影响WriteSocketService的行为。同时，它还维护着和从结点连接的过期工作，如果超过指定时间没有收到消息就会断开连接，同时会停止WriteSocketService。  从结点同步逻辑 从结点的同步逻辑相对简单主要做几件事情：
 管理和主结点的连接，如果超过一段时间没有收到主点结点的数据，就会断开连接。这个时间戳保存在变量lastWriteTimestamp中，刚刚连接上主结点和从主结点读到数据都会更新该变量。 上报当前commitlog的最大偏移量，该行为会发生三个地方：a.写完一个消息；b.处理完当前收到的所有数据；c.一段时间内没有收到主结点的数据。 维护收到的数据。这里有两个接收数据的buffer，主要方便处理当一个buffer的空间用完以后处理剩余的消息。一个buffer的情况下，先拷贝到一个临时byte数据，然后再拷贝回去，需要两次内存拷贝。如果两个buffer只需要一次拷贝。 写消息。把从主结点同步过来的数据写到磁盘。收到数据的时候会判断主结点发过来的偏移量是否等于自己当前的偏移量如果不一样就会断开和主结点的连接。 任何从连接中读数据的时候如果有错误就会断开连接。  </description>
    </item>
    
    <item>
      <title>slave和master同步连接经常重连，导致发送消息失败</title>
      <link>http://zjykzk.github.io/posts/cs/rocketmq/slave-sync-from-master-disconnect/</link>
      <pubDate>Mon, 22 Oct 2018 17:07:02 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/posts/cs/rocketmq/slave-sync-from-master-disconnect/</guid>
      <description>缘起 封装RocketMQ的组件boots-broker每天都返回几个的500。排查发现是因为slave向master同步消息的时候，由于没有及时向master报告自己的同步进度，从而master没有向slave及时同步消息，导致消息发送失败。
排查过程 查看boots-broker日志，发现问题日志：
[TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 1008ms, size of queue: 0 说明，RocketMQ处理发送消息比较慢。可是，从size of queue可以看出，堆积的消息为0。
查看机器资源消耗情况，发现资源都是充裕的。
查看RocketMQ日志，发现store.log中有异常，master中的store.log周期性的发生以下日志：
2018-10-22 15:44:07 INFO AcceptSocketService - HAService receive new connection, /10.38.34.27:54052 2018-10-22 15:44:07 INFO ReadSocketService - ReadSocketService service started 2018-10-22 15:44:07 INFO WriteSocketService - WriteSocketService service started 2018-10-22 15:44:08 INFO WriteSocketService - WriteSocketService service end 2018-10-22 15:44:12 INFO ReadSocketService - slave[/10.38.34.27:54052] request offset 157843228 2018-10-22 15:44:12 INFO WriteSocketService - master transfer data from 157843228 to slave[/10.</description>
    </item>
    
    <item>
      <title>rocketmq store模块</title>
      <link>http://zjykzk.github.io/posts/cs/rocketmq/store/</link>
      <pubDate>Fri, 08 Dec 2017 17:59:56 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/posts/cs/rocketmq/store/</guid>
      <description>功能 store模块是rocketmq的核心模块。主要功能有：
 消息存储 消息索引 消费队列 主从同步 延迟消息 清理过期的消息和消费队列  消息存储 负责消息存储，包括写消息，刷盘。
消息文件 消息保存在默认值为${user.home}\store\commitlog文件夹下，可以通过配置项storePathCommitLog修改。所有的消息都写入一个逻辑文件，每个逻辑文件包含大小相等的物理文件。
写消息 写消息在不同的场景下面会有不同的逻辑。
同步刷盘 每条消息要写到磁盘以后才算完成。
在同步刷盘的场景下，会有一个定期检查消息是否已经写入磁盘的线程：GroupCommitService，除了检查还会进行刷盘的操作 。写消息的时候会生成一个GroupCommitRequest提交到GroupCommitService，并等待被唤醒或者超时。当GroupCommitService发现已经刷盘的最后一个消息的索引大于等于本消息的索引时就会唤醒GroupCommitRequest。
备注：以上的场景还依赖于消息的属性WAIT，只有该属性为空或者为true才会执行同步刷盘逻辑，默认是空的。
异步刷盘 在异步刷盘的场景下，会有一个把数据刷到磁盘的辅助线程：FlushRealTimeService。写消息仅仅唤醒该线程就结束了写盘操作。
主从同步 每条消息要等一个从broker同步完才算完成。
在主从同步的场景下，会有一个定期检查消息是否已经被从broker同步的辅助线程：GroupTransferService。写消息的时候会生成一个GroupCommitRequest提交给GroupTransferService，并等待被唤醒或者超时。当GroupTransferService发现从broker已经同步的最后一个消息的索引大于本次消息的索引时就会唤醒GroupCommitRequest。
写buffer 使用了写buffer以后，写消息的全部逻辑就是把消息写入buffer。同时，系统会有一个线程CommitRealTimeService定期把消息写入文件。
核心代码 org.apache.rocketmq.store.CommitLog 消费队列 每个topic对应多个消费队列，这个是提高消费并发度的前提。
结构 每个消费队列对应一个逻辑文件，文件中对应每个消息的内容大小是固定的20个字节，包含消息的偏移量，大小以及tag哈希值。
文件目录 数据保存在目录${rootpath}/consumequeue下面，rootpath 通过配置项storePathRootDir指定，默认的是${user.home}/store。
${rootpath}/consumequeue └── 0%default // topic ├── 0 // queue 0 │ └── 00000000000000000000 ├── 1 // queue 1 │ └── 00000000000000000000 ├── 2 // queue 2 │ └── 00000000000000000000 └── 3 // queue 3 └── 00000000000000000000 队列元素 |&amp;lt;----- 8 byte -----&amp;gt;|&amp;lt;- 4 byte -&amp;gt;|&amp;lt;------ 8 byte ------&amp;gt;| +--------------------+------------+----------------------+ | commitlog offset | size | message tag hash code| +--------------------+------------+----------------------+ 执行 通过线程ReputMessageService的分派消息的逻辑执行。</description>
    </item>
    
  </channel>
</rss>
