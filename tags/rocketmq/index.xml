<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rocketmq on 老K随笔</title>
    <link>http://zjykzk.github.io/tags/rocketmq/</link>
    <description>Recent content in Rocketmq on 老K随笔</description>
    <generator>Hugo -- gohugo.io</generator>
    <managingEditor>zhangkai.zju@gmail.com (zenk)</managingEditor>
    <webMaster>zhangkai.zju@gmail.com (zenk)</webMaster>
    <copyright>(c) 2017 zenk.</copyright>
    <lastBuildDate>Fri, 25 Jan 2019 15:35:52 +0800</lastBuildDate>
    
	<atom:link href="http://zjykzk.github.io/tags/rocketmq/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>RocketMQ HA实现</title>
      <link>http://zjykzk.github.io/post/cs/rocketmq/ha/</link>
      <pubDate>Fri, 25 Jan 2019 15:35:52 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/rocketmq/ha/</guid>
      <description> HA原理 RocketMQ支持主结点的数据同步到从结点。同步的数据依赖于当前从结点的状态。从结点连接到主结点的时候会上报自己的当前commitlog的最大偏移量。主结点收到以后会根据这个值计算出传输的起始位置，如果上报的commitlog的最大偏移量：
 等于0，主结点会从当前最新commitlog文件中第一个消息的偏移量开始传输。
 大于0，从该值开始传输。
 小于0，这种情况不存在。
  所以，这里我们可以知道如果从结点已经就有数据情况，如果数据不是从主结点同步过来的，那么同步之后就会有问题了。比如说：从结点已经有10000条数据，同时某个topic，暂时就叫OLD_TOPIC的*消费队列0*长度1000。这个时候，主结点就会从第10000条数据开始同步，可能会发送几种情况：
 主结点没有10000数据，那么就不会同步数据，造成从结点上面数据丢失。
 主结点有超过10000数据，但是它的OLD_TOPIC的*消费队列0*的长度小于1000，那么同步过来的数据就会覆盖原来的数据。
  所以，从结点的初始状态需要从0开始或者本来就是和主同步过的状态。因此，在删除topic的时候从结点要保证删除干净，不然从结点就会脏数据，影响消费。
为什么这样同步不会有问题呢？
那是因为同步的数据里面包含了具体消费队列ID，队列中的偏移量以及消息的偏移量，所以同步的时候能够写到同一个位置。
主结点同步逻辑 发送一条消息的时候，在开启SYNC_MASTER情况下，需要四个线程合作才能完成消息的发送。
 SendMessageProcessor负责处理接收发送消息的请求并落盘（异步或者同步），接着向GroupTransferService发送等待同步完成的请求，然后等待知道超时或者GroupTransferService通知同步完成。同时，还会同时WriteSocketService有数据可以写了。
 WriteSocketService负责根据从结点上报的位置（变量slaveRequestOffset），不断的向从结点传输数据。同时会维护和从结点的一个心跳，如果一段时间没有通不过数据，就会发送一个消息头，包含当前同步的起始位置。
 GroupTransferService不断的轮询比较当前已经被从结点同步的最大偏移（变量push2SlaveMaxOffset）和SendMessageProcessor发送过来的请求中包含的偏移量，如果大于或者等于就会通知SendMessageProcessor。
 ReadSocketService负责读取从结点上报上来的同步偏移量。更新变量push2SlaveMaxOffset和slaveRequestOffset并通知GroupTransferService。从而，它也会影响WriteSocketService的行为。同时，它还维护着和从结点连接的过期工作，如果超过指定时间没有收到消息就会断开连接，同时会停止WriteSocketService。
  从结点同步逻辑 从结点的同步逻辑相对简单主要做几件事情：
 管理和主结点的连接，如果超过一段时间没有收到主点结点的数据，就会断开连接。这个时间戳保存在变量lastWriteTimestamp中，刚刚连接上主结点和从主结点读到数据都会更新该变量。
 上报当前commitlog的最大偏移量，该行为会发生三个地方：a.写完一个消息；b.处理完当前收到的所有数据；c.一段时间内没有收到主结点的数据。
 维护收到的数据。这里有两个接收数据的buffer，主要方便处理当一个buffer的空间用完以后处理剩余的消息。一个buffer的情况下，先拷贝到一个临时byte数据，然后再拷贝回去，需要两次内存拷贝。如果两个buffer只需要一次拷贝。
 写消息。把从主结点同步过来的数据写到磁盘。收到数据的时候会判断主结点发过来的偏移量是否等于自己当前的偏移量如果不一样就会断开和主结点的连接。
 任何从连接中读数据的时候如果有错误就会断开连接。
  </description>
    </item>
    
    <item>
      <title>RocketMQ offset管理</title>
      <link>http://zjykzk.github.io/post/cs/rocketmq/offset/</link>
      <pubDate>Fri, 28 Dec 2018 16:03:51 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/rocketmq/offset/</guid>
      <description> 作用 记录每个消费队列的消费进度。以topic，group为单位。
类型 根据保存的位置可以分为本地和远程两种类型。本地类型就是以文本文件的形式保存在客户端，内容是非正式的json数据，而远程类型是指数据保存在broker服务器上面，内容同样是非正式的json数据。
代码
本地类型：org.apache.rocketmq.client.consumer.store.LocalFileOffsetStore。
远程类型：org.apache.rocketmq.client.consumer.store.RemoteBrokerOffsetStore。
使用
默认情况，当消费模式是*广播*的时候使用*本地类型*，因为每个消费者管理自己的进度，而且是所有消费队列的进度，各个消费者之间也不会有消费进度的交集。当消费模式是*集群*的时候使用*远程类型*，因为消息被多个消费者消费，每个消费者只负责消费其中部分消费队列，在添加、删除消费者的时候，原来消费者负责的消费队列会动态变化，因此需要集中管理消费进度，不然就冲突了。
但是，代码中依然提供了接口，让用户自己指定类型，比如可以保存数据到monogodb。
存储 本地类型
数据保存在$storeDir/.rocketmq_offsets/$clientID/$group/offsets.json中，里面的数据是非标准json数据，用的是阿里的fastjson这个库。其中$storeDir是可以通过系统变量rocketmq.client.localOffsetStoreDir配置，如果没有指定参数就使用HOME目录。$clientID和$group分别表示消费者的id和分组。
// example {&amp;quot;offsetTable&amp;quot;:{{&amp;quot;brokerName&amp;quot;:&amp;quot;topic&amp;quot;,&amp;quot;queueId&amp;quot;:1,&amp;quot;topic&amp;quot;:&amp;quot;broker&amp;quot;}:0}}  远程类型
数据保存在$rootPath/config/consumerOffset.json文件中，里面的数据是非标准json数据，用的是阿里的fastjson这个库。offsetTable中的key格式是topic@group，value格式queueID:offset。
// example { &amp;quot;offsetTable&amp;quot;:{ &amp;quot;test@benchmark_consumer_61&amp;quot;:{ 0:5280,1:5312,2:5312,3:5312 } } }  接口 通过接口类型org.apache.rocketmq.client.consumer.store.OffsetStore抽象了消费进度的相关操作。
load
在消费者启动的时候，需要把消费进度载入内存。只有本地类型会载入数据。
updateOffset
更新消费队列的进度。可以选择在比当前消费进度大的时候才更新，这个目的主要用于push模式下面消息是并发消费的，这样每批消息完成以后更新进度是并发，可能会导致进度低的晚于进度高的更新，这个模式就是为了避免这个情况。代码在类ConsumeMessageConcurrentlyService中。
readOffset
读取消费队列的消费进度，数据存在内存和存储（本地或者broker服务）中，提供了三种读取的方式：1.内存；2.存储；3.先内存，如果没有后存储。在两个地方的实现中，从存储中读到数据以后会更新到内存。
persistAll
持久化指定的多个消费队列的消费进度。本地类型的实现中只会持久化内存中的消费进度。远程类型除此之外，还会把指定的消费队列以外的那些队列从内存中移除。
persist
持久化指定的单个消费队列的消费进度。只有远程类型实现了该接口。
removeOffset
移除某个消费队列的消费进度。只有远程类型实现了该接口。
updateConsumeOffsetToBroker
更新消费队列到broker服务，只有远程类型实现了该接口。（这个设计好尴尬，本地类型需要么。。。）
管理 org.apache.rocketmq.client.impl.consumer.RebalanceImpl.updateProcessQueueTableInRebalance做消费的负载均衡时，会对消费进度做管理。这个过程通过对比新分配的消费队列（简称新队列）和org.apache.rocketmq.client.impl.consumer.RebalanceImpl.processQueueTable维护的消费队列（简称旧队列），有几种情况：
 如果旧队列的消费队列不在新队列中，那么就会先持久化该队列的消费进度，再做删除操作。push模式同时优势有序的集群消费还需要做外的事情。
 如果如果旧队列的消费队列在新队列中，push模式下检查是否过期，过期的化先持久化，再删除进度。
 如果新队列的消费队列不在旧队列中，删除消费进度。本地模式不会做删除操作，远程模式会把内存中的消费进度删除掉。同时，push模式下面会从存储中拉取消费进度并保存到内存。
  </description>
    </item>
    
    <item>
      <title>slave和master同步连接经常重连，导致发送消息失败</title>
      <link>http://zjykzk.github.io/post/cs/rocketmq/slave-sync-from-master-disconnect/</link>
      <pubDate>Mon, 22 Oct 2018 17:07:02 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/rocketmq/slave-sync-from-master-disconnect/</guid>
      <description>缘起 封装RocketMQ的组件boots-broker每天都返回几个的500。排查发现是因为slave向master同步消息的时候，由于没有及时向master报告自己的同步进度，从而master没有向slave及时同步消息，导致消息发送失败。
排查过程 查看boots-broker日志，发现问题日志：
[TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 1008ms, size of queue: 0  说明，RocketMQ处理发送消息比较慢。可是，从size of queue可以看出，堆积的消息为0。
查看机器资源消耗情况，发现资源都是充裕的。
查看RocketMQ日志，发现store.log中有异常，master中的store.log周期性的发生以下日志：
2018-10-22 15:44:07 INFO AcceptSocketService - HAService receive new connection, /10.38.34.27:54052 2018-10-22 15:44:07 INFO ReadSocketService - ReadSocketService service started 2018-10-22 15:44:07 INFO WriteSocketService - WriteSocketService service started 2018-10-22 15:44:08 INFO WriteSocketService - WriteSocketService service end 2018-10-22 15:44:12 INFO ReadSocketService - slave[/10.38.34.27:54052] request offset 157843228 2018-10-22 15:44:12 INFO WriteSocketService - master transfer data from 157843228 to slave[/10.</description>
    </item>
    
    <item>
      <title>rocketmq store模块</title>
      <link>http://zjykzk.github.io/post/cs/rocketmq/store/</link>
      <pubDate>Fri, 08 Dec 2017 17:59:56 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/rocketmq/store/</guid>
      <description>功能 store模块是rocketmq的核心模块。主要功能有：
 消息存储
 消息索引
 消费队列
 主从同步
 延迟消息
 清理过期的消息和消费队列
  消息存储 负责消息存储，包括写消息，刷盘。
消息文件 消息保存在默认值为${user.home}\store\commitlog文件夹下，可以通过配置项storePathCommitLog修改。所有的消息都写入一个逻辑文件，每个逻辑文件包含大小相等的物理文件。
写消息 写消息在不同的场景下面会有不同的逻辑。
同步刷盘 每条消息要写到磁盘以后才算完成。
在同步刷盘的场景下，会有一个定期检查消息是否已经写入磁盘的线程：GroupCommitService，除了检查还会进行刷盘的操作 。写消息的时候会生成一个GroupCommitRequest提交到GroupCommitService，并等待被唤醒或者超时。当GroupCommitService发现已经刷盘的最后一个消息的索引大于等于本消息的索引时就会唤醒GroupCommitRequest。
备注：以上的场景还依赖于消息的属性WAIT，只有该属性为空或者为true才会执行同步刷盘逻辑，默认是空的。
异步刷盘 在异步刷盘的场景下，会有一个把数据刷到磁盘的辅助线程：FlushRealTimeService。写消息仅仅唤醒该线程就结束了写盘操作。
主从同步 每条消息要等一个从broker同步完才算完成。
在主从同步的场景下，会有一个定期检查消息是否已经被从broker同步的辅助线程：GroupTransferService。写消息的时候会生成一个GroupCommitRequest提交给GroupTransferService，并等待被唤醒或者超时。当GroupTransferService发现从broker已经同步的最后一个消息的索引大于本次消息的索引时就会唤醒GroupCommitRequest。
写buffer 使用了写buffer以后，写消息的全部逻辑就是把消息写入buffer。同时，系统会有一个线程CommitRealTimeService定期把消息写入文件。
核心代码 org.apache.rocketmq.store.CommitLog  消费队列 每个topic对应多个消费队列，这个是提高消费并发度的前提。
结构 每个消费队列对应一个逻辑文件，文件中对应每个消息的内容大小是固定的20个字节，包含消息的偏移量，大小以及tag哈希值。
文件目录 数据保存在目录${rootpath}/consumequeue下面，rootpath 通过配置项storePathRootDir指定，默认的是${user.home}/store。
${rootpath}/consumequeue └── 0%default // topic ├── 0 // queue 0 │ └── 00000000000000000000 ├── 1 // queue 1 │ └── 00000000000000000000 ├── 2 // queue 2 │ └── 00000000000000000000 └── 3 // queue 3 └── 00000000000000000000  队列元素 |&amp;lt;----- 8 byte -----&amp;gt;|&amp;lt;- 4 byte -&amp;gt;|&amp;lt;------ 8 byte ------&amp;gt;| +--------------------+------------+----------------------+ | commitlog offset | size | message tag hash code| +--------------------+------------+----------------------+  执行 通过线程ReputMessageService的分派消息的逻辑执行。</description>
    </item>
    
  </channel>
</rss>