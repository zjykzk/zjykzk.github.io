<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Algo on 老K随笔</title>
    <link>http://zjykzk.github.io/tags/algo/</link>
    <description>Recent content in Algo on 老K随笔</description>
    <generator>Hugo -- gohugo.io</generator>
    <managingEditor>zhangkai.zju@gmail.com (zenk)</managingEditor>
    <webMaster>zhangkai.zju@gmail.com (zenk)</webMaster>
    <copyright>(c) 2017 zenk.</copyright>
    <lastBuildDate>Thu, 30 Aug 2018 16:48:26 +0800</lastBuildDate>
    
	<atom:link href="http://zjykzk.github.io/tags/algo/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>限流</title>
      <link>http://zjykzk.github.io/posts/cs/dist/rate-limit/</link>
      <pubDate>Thu, 30 Aug 2018 16:48:26 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/posts/cs/dist/rate-limit/</guid>
      <description>缘起 为了保证API的可用性，以及系统的可靠性，需要为API限速。不然，API请求量大到系统无法处理时就会出现系统变慢，甚至宕机的情况。常见的限速场景：
 挡住某个用户的过多请求（用户激增或者恶意请求），确保正常处理其他用户请求。
 挡住过多的低优先级的请求，确保核心请求得到处理。
 由于系统内部错误，导致系统处理能力下降，调节系统的处理能力。
 挡住过多某类请求，确保其他请求可以得到处理。
  限速类型 请求限速
限制API在一秒中内能够处理的请求数量。如果超过这个数量，等待或者拒绝服务。通常情况下这个是首选。
并发限制
针对资源敏感的请求，比如CPU密集型API，进行并发限制，限制某一时刻最多只有有限个请求正在被处理。防止因为这些请求占用资源，导致其他请求得不到处理。
基于资源利用率限速
针对不同的请求分配了不同百分比的资源，当某一类请求超载时，对这类请求限速。
基于worker限速
这个是基于代码特征的限速。每类API通过不同的worker线程负责处理，当worker线程中出现请求堆积时进行限速。
限速结果 http服务的话按照场景返回429或者503。
常用算法 计数
单位时间内计数，超过这个数量时，拒绝服务，每个单位时间开始后计数清零。缺点是在时间边界处，会超过上限。比如，每秒限速100，在0.9s的时候来了100个请求全部得到处理，在下一秒0.1s来了100个请求。在0.9s到1.1s这个范围小于1s，但是请求达到了200。
 0.1s 0.2s 0.3s 0.4s 0.5s 0.6s 0.7s 0.8s 0.9s 0.1s 0.2s +----+----+----+----+----+----+----+----+----+----+----+--- | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 100| 100| 0 | 0 +----+----+----+----+----+----+----+----+----+----+----+---  队列
请求过来的时候，先如队列，处理逻辑处理队列中的请求。
 基于大小的队列：当队列大小超过一个阀值的时候，拒绝新来的请求。
 基于时间的队列：请求在队列里面的时间超过多长时间没有被处理，立即返回。RocketMQ就是采用这种方式。</description>
    </item>
    
    <item>
      <title>分布式ID生成算法</title>
      <link>http://zjykzk.github.io/posts/cs/dist/uuid/</link>
      <pubDate>Wed, 22 Aug 2018 11:08:28 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/posts/cs/dist/uuid/</guid>
      <description>分布式Unique ID在分布式系统使用很广泛，常用的用途有：
 请求的ID，用于跟踪请求链路。
 消息队列中的unique id。
 业务对象的id。
  总结下生成分布式ID常用算法。
数据库自增id 通过MySQL中的auto_increment特性来实现数据库唯一的ID。问题是扩展性差，性能受限于一台机器。可以做的优化是使用多个数据库实例，设置相同的步长和不同的起始值，避免重复产生ID。通过一个这种方式可以利用多台机器的资源。同时，还有一个优化是获取ID的时候可以批量获取ID，这样可以减少DB的操作，减少响应时间。
基于Redis，Postgres，Oracle也有类似的方案。
UUID UUID由[0-9a-f-]字符组成，总共16个字节，转换成16进制的格式为：XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX。
数据由5个部分组成：
 时间戳，占60位。
 时钟序列，占13位。
 结点编号，占48位。
 版本号，版本不同以上1-3个字段的数据来源也不一样，占4位。
 UUID类型，用于解析UUID数据中的意义，占3位。
  每个数据的位置：
 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | time_low | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | time_mid | time_hi_and_version | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |clk_seq_hi_res | clk_seq_low | node (0-1) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | node (2-5) | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+  time_hi_and_version的第4-7位是版本号，clk_seq_hi_res的第5-7位是UUID类型编号。</description>
    </item>
    
    <item>
      <title>一致性hash算法</title>
      <link>http://zjykzk.github.io/posts/cs/dist/cons-hash/</link>
      <pubDate>Sat, 28 Apr 2018 13:58:46 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/posts/cs/dist/cons-hash/</guid>
      <description>一致性hash 目标 缓存的机器扩容、缩容时，尽量保持数据的命中率。常规的hash算法，hash(key)mod N （N表示缓存结点），当N变化时同一个key查询的缓存结点都会变化，导致缓存没有命中，造成很大的数据库压力。
原理 hash函数值大小32位，因此输出的范围是0~2^32-1。把这个范围形成一个环，同时对数据进行hash计算以外，对缓存的机器也做hash计算。这些计算出来的值在这个环上都有对应的一个点。
假设数据的hash值分别为K1,K2,K3,K4,K5,K6，以及缓存结点的hash值H1,H2,H3,大小关系为H1&amp;lt;K3&amp;lt;K4&amp;lt;K5&amp;lt;H2&amp;lt;K6&amp;lt;H3&amp;lt;K1&amp;lt;K2。
每个数据所在的缓存结点是在这个环上顺时针方向遇到的第一个缓存结点既是。
因此K1,K2落在H1,K3,K4,K5落在H2,K6落在H3。
添加一个新的缓存结点H4，它的hash值落在K4和K5之间。按照规则，K3,K4将落在H4，也就是说K3,K4将会失效而其他的数据不会影响。
减少缓存结点H3，K6会受到影响，它将落在缓存结点H1。
在次基础上可以抽象出一层缓存的虚拟缓存结点，这样的好处是可以事先确定缓存结点数量，让数据均匀的分布在每个虚拟缓存结点上面。每个物理缓存结点对应一个或者多个缓存结点。如下图中，有个4个虚拟缓存结点VH1/VH2/VH3/VH4，两个物理缓存结点H1/H2，分别对应VH1/VH2和VH3/VH4。</description>
    </item>
    
  </channel>
</rss>