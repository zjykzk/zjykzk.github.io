<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cs on 老K随笔</title>
    <link>http://zjykzk.github.io/categories/cs/</link>
    <description>Recent content in Cs on 老K随笔</description>
    <generator>Hugo -- gohugo.io</generator>
    <managingEditor>zhangkai.zju@gmail.com (zenk)</managingEditor>
    <webMaster>zhangkai.zju@gmail.com (zenk)</webMaster>
    <copyright>(c) 2017 zenk.</copyright>
    <lastBuildDate>Wed, 24 Oct 2018 14:57:53 +0800</lastBuildDate>
    <atom:link href="http://zjykzk.github.io/categories/cs/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>如何定位一个文件。</title>
      <link>http://zjykzk.github.io/post/cs/linux/open-file-progress/</link>
      <pubDate>Wed, 24 Oct 2018 14:57:53 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/linux/open-file-progress/</guid>
      <description>&lt;p&gt;linux的VFS包含4个重要概念：&lt;br /&gt;
1. superblock，包含文件系统的信息，管理整个文件系统。&lt;br /&gt;
2. inode，索引文件（index node），代表一个文件，包含文件的元数据和数据，不包含文件名。&lt;br /&gt;
3. dentry，目录项，代表路径中的每个部分，包含文件路径到inode的映射。&lt;br /&gt;
4. file，文件，是文件在进程中的表示。&lt;/p&gt;

&lt;p&gt;同时，在linux中一切兼文件，包括目录。目录的内容是文件名和inode号。&lt;/p&gt;

&lt;p&gt;当打开一个文件&lt;code&gt;/bin/vim&lt;/code&gt;，系统首先把路径分解成&lt;code&gt;/&lt;/code&gt;、&lt;code&gt;bin&lt;/code&gt;、&lt;code&gt;vim&lt;/code&gt;，根据dentry查&lt;code&gt;vim&lt;/code&gt;的inode，如果dentry还没有&lt;code&gt;bin&lt;/code&gt;，会根据superblock中&lt;strong&gt;根目录&lt;/strong&gt;的inode号得到它的子目录信息，其中就有&lt;code&gt;bin&lt;/code&gt;和它的inode，并把它放到dentry中，然后根据&lt;code&gt;bin&lt;/code&gt;的内容找到&lt;code&gt;vim&lt;/code&gt;的inode。最终，返回一个文件描述符（file descriptor）。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>slave和master同步连接经常重连，导致发送消息失败</title>
      <link>http://zjykzk.github.io/post/cs/rocketmq/slave-sync-from-master-disconnect/</link>
      <pubDate>Mon, 22 Oct 2018 17:07:02 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/rocketmq/slave-sync-from-master-disconnect/</guid>
      <description>

&lt;h2 id=&#34;缘起&#34;&gt;缘起&lt;/h2&gt;

&lt;p&gt;封装RocketMQ的组件boots-broker每天都返回几个的500。排查发现是因为slave向master同步消息的时候，由于没有及时向master报告自己的同步进度，从而master没有向slave及时同步消息，导致消息发送失败。&lt;/p&gt;

&lt;h2 id=&#34;排查过程&#34;&gt;排查过程&lt;/h2&gt;

&lt;p&gt;查看boots-broker日志，发现问题日志：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 1008ms, size of queue: 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;说明，RocketMQ处理发送消息比较慢。可是，从&lt;code&gt;size of queue&lt;/code&gt;可以看出，堆积的消息为0。&lt;/p&gt;

&lt;p&gt;查看机器资源消耗情况，发现资源都是充裕的。&lt;/p&gt;

&lt;p&gt;查看RocketMQ日志，发现store.log中有异常，master中的store.log周期性的发生以下日志：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2018-10-22 15:44:07 INFO AcceptSocketService - HAService receive new connection, /10.38.34.27:54052
2018-10-22 15:44:07 INFO ReadSocketService - ReadSocketService service started
2018-10-22 15:44:07 INFO WriteSocketService - WriteSocketService service started
2018-10-22 15:44:08 INFO WriteSocketService - WriteSocketService service end
2018-10-22 15:44:12 INFO ReadSocketService - slave[/10.38.34.27:54052] request offset 157843228
2018-10-22 15:44:12 INFO WriteSocketService - master transfer data from 157843228 to slave[/10.38.34.27:54052], and slave request 157843228
2018-10-22 15:44:33 WARN ReadSocketService - ha housekeeping, found this connection[/10.38.34.27:54052] expired, 20019
2018-10-22 15:44:33 INFO ReadSocketService - ReadSocketService service end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上可以看出，slave主动向master建立连接，5s之后发送自己当前同步的进度，master收到以后向slave发送同步数据，最后master由于slave的连接过期，主动断开连接。&lt;/p&gt;

&lt;p&gt;slave中的store.log周期性的发生以下日志：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2018-10-22 15:44:07 WARN HAClient - HAClient, housekeeping, found this connection[10.38.33.22:10912] expired, 1540194247979
2018-10-22 15:44:07 WARN HAClient - HAClient, master not response some time, so close connection
2018-10-22 15:44:33 INFO HAClient - HAClient, processReadEvent read socket &amp;lt; 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从上可以看出，slave也发现和master的连接超时，断开连接。&lt;/p&gt;

&lt;p&gt;到这里，非常困惑，master和slave都主动断开连接！看代码，master的同步比较清晰和日志也比较一致。slave的同步日志和日志不一致。slave的同步代码核心&lt;a href=&#34;https://github.com/zjykzk/rocketmq/blob/master/store/src/main/java/org/apache/rocketmq/store/ha/HAService.java#L546&#34;&gt;代码&lt;/a&gt;中通过比较&lt;code&gt;lastWriteTimestamp&lt;/code&gt;和当前时间判断出与master的同步连接过期，以及master没有响应。在接收到master的消息、创建连接、关闭连接的时候都修改这个&lt;code&gt;lastWriteTimestamp&lt;/code&gt;值。关闭重置为0，其他重置为当前时间。看日志发现&lt;code&gt;lastWriteTimestamp&lt;/code&gt;和当前的时间差别巨大是&lt;code&gt;1540194247979&lt;/code&gt;，可以得出&lt;code&gt;lastWriteTimestamp&lt;/code&gt;其实是0。基本上可以判断是因为master主动关闭的。后来，通过tcpdump抓包得到了确认。这里要吐槽这个日志了，slave是被关闭的却是提示master没响应，其实master在关闭之前总共发了5次同步信息。&lt;/p&gt;

&lt;p&gt;确认是master主动关闭，接下来的问题是为什么slave没有告诉master自己的进度。日志已经无能为力了，看到代码中有&lt;code&gt;while(true)&lt;/code&gt;片段，猜测会不会是死循环，通过&lt;code&gt;jstack&lt;/code&gt;发现没有。最后，通过手动添加日志发现master向slave发送的同步信息，slave都收到了，然后把&lt;code&gt;lastWriteTimestamp&lt;/code&gt;重置为当前的时间，巧合的是，每次函数&lt;code&gt;isTimeToReportOffset&lt;/code&gt;判断是否需要发送同步进度的时候恰好都为&lt;code&gt;false&lt;/code&gt;。这是因为master向slave同步间隔和slave向master报告同步进度的间隔默认都是5s，slave处理master的同步信息以后会重置&lt;code&gt;lastWriteTimestamp&lt;/code&gt;为当前时间，因此一直无法满足同步的条件，导致以上的现象。&lt;/p&gt;

&lt;h2 id=&#34;解决方案&#34;&gt;解决方案&lt;/h2&gt;

&lt;p&gt;可以知道，连接经常断开显然会影响同步的效率。解决方案可以把master同步时间设置的比slave的同步长，比如slave的同步间隔为3s，master同步间隔为5s。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>熔断</title>
      <link>http://zjykzk.github.io/post/cs/dist/circuit-breaker/</link>
      <pubDate>Fri, 12 Oct 2018 14:23:18 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/dist/circuit-breaker/</guid>
      <description>

&lt;h2 id=&#34;缘起&#34;&gt;缘起&lt;/h2&gt;

&lt;p&gt;在分布式系统中，会有很多的RPC调用，当某个服务超载时候，继续接收请求只会让系统变得不可用，甚至会导致多个系统的连锁反应。因此在这样的情况下，最好是把后续的请求挡住，直接返回错误。等到系统恢复正常以后再处理请求。熔断借鉴了电闸中的保险丝功能，当因为某个意外原因（比如插座进水导致短路）导致线路中的电流过大而产生大量热量，保险丝就会被融化掉，从而中断线路中的电流，防止事故发生。&lt;/p&gt;

&lt;h2 id=&#34;设计&#34;&gt;设计&lt;/h2&gt;

&lt;p&gt;通俗来说，它是一个服务代理（逻辑上说），监测服务的状态，决定是否处理当前的请求，如果不处理返回错误。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;服务状态&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;服务状态一般是通过记录请求失败的情况来表示，比如说服务因为文件句柄占用过多导致一致无法建立连接，从而请求失败，熔断器认为当前服务状态存在不可用情况。&lt;/p&gt;

&lt;p&gt;熔断器包含三个状态：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;关闭（Closed）状态：在这个状态下，请求都会被转发给后端服务。同时会记录请求失败的次数，当请求失败次数在一段时间超过一定次数就会进入&lt;strong&gt;打开&lt;/strong&gt;状态。另外，失败次数会在特定时间间隔内重置。最后，除了基于一段时间内失败次数这个条件以外还可以使用连续失败次数。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;打开（Open）状态：在这个状态下，熔断器会直接拒绝请求，返回错误，而不去调用后端服务。同时，会有一个定时器，时间到的时候会变成&lt;strong&gt;半打开&lt;/strong&gt;状态。目的假设服务会在一段时间内恢复正常。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;半打开（Half Open）状态：在这个状态下，熔断器会尝试把部分请求转发给后端服务，目的是为了探测后端服务是否恢复。当请求失败的情况下会进入&lt;strong&gt;打开&lt;/strong&gt;状态，成功情况下会进入&lt;strong&gt;关闭&lt;/strong&gt;状态，同时重置计数。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;http://zjykzk.github.io/imgs/circuit-breaker.png&#34; alt=&#34;circuit breaker&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;设计重点&#34;&gt;设计重点&lt;/h2&gt;

&lt;p&gt;在设计过程中需要考虑以下几个点。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;错误类型。后端服务会因为不同的问题返回不同的错误信息。针对不同的错误信息，熔断器可以采取不同的策略。比如说，针对限流错误，可以采用重试，如果连接拒绝大概率是服务宕机了，这中情况直接返回错误就可以了。另外，根据不同的错误类型可以使用不同的熔断条件，比如超时的threshold为10， 而连接拒绝的threshold值为3。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;日志监控。熔断器记录状态变化以及失败的请求应该被记录下来。这些信息反应的服务质量。方便管理员进一步处理。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;测试服务可用。在&lt;strong&gt;半打开&lt;/strong&gt;状态下，可以通过定制的接口探测后端服务是否恢复，而不是用用户的请求来探测。可以提高服务的质量。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;返回错误。返回给用户的错误，区分后端服务返回的错误和熔断器产生的错误。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;手工重置。因为有时候后端服务恢复时间的不确定性，导致熔断器判断失误。提供手工重置，可以方便熔断器的状态切换。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;并发问题。熔断器需要做计数，多个请求之间存在数据竞争。需要避免熔断器自己的开销影响请求的响应时间。可以采用无锁计数实现。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;资源区分。有时候，资源是分布在不同的服务器上，是独立。最好，熔断器对请求也做资源区分，针对在不同资源请求做熔断，不然一个资源有问题会影响其他资源的访问。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;重试错误的请求。有时候，错误和请求的参数有关系。把这部分请求记录下来，可以准备探测后端服务是否恢复。但是要做好重复请求的处理，比如幂等。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;实现&#34;&gt;实现&lt;/h2&gt;

&lt;p&gt;Netflix中的&lt;a href=&#34;https://github.com/Netflix/Hystrix/wiki/How-it-Works#CircuitBreaker&#34;&gt;Hystrix&lt;/a&gt;有一个完整的实现。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://zjykzk.github.io/imgs/hystrix-circuit-breaker-1280.png&#34; alt=&#34;hystrix circuit breaker，图片来自hystrix的github wiki&#34; /&gt;&lt;/p&gt;

&lt;p&gt;流程如下：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;allowRequest()&lt;/code&gt;通过函数&lt;code&gt;isOpen()&lt;/code&gt;判断是否处理请求。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;isOpen()&lt;/code&gt;判断逻辑：&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;如果熔断器处在打开状态，并且定时没到，返回&lt;code&gt;false&lt;/code&gt;，请求处理完毕，否则进入半打开状态并返回&lt;code&gt;true&lt;/code&gt;，走下一步。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;如果最近一秒内失败率超过了某个百分比，返回&lt;code&gt;false&lt;/code&gt;，请求处理完毕，否则返回&lt;code&gt;true&lt;/code&gt;，走下一步。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;返回&lt;code&gt;true&lt;/code&gt;，走下一步。&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;markSuccess(duration)&lt;/code&gt;，表示请求处理成功，更新处理成功次数和处理时间，同时如果熔断器处于打开状态，那么需要重置计数，并把状态变成关闭状态。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;markFailure(duration)&lt;/code&gt;，表示请求处理失败，更新处理失败次数。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Hystrix维护了10个时间间隔为1秒的桶，用于记录请求处理结果成功、失败、超时、拒绝的数量。每过1秒就会创建一个新的桶，如果桶的数量超过10个，最旧的那个会被删除掉。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>guava中RateLimiter的设计</title>
      <link>http://zjykzk.github.io/post/cs/design/guava-ratelimiter/</link>
      <pubDate>Thu, 11 Oct 2018 15:33:32 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/design/guava-ratelimiter/</guid>
      <description>

&lt;p&gt;guava中的&lt;a href=&#34;https://github.com/google/guava/blob/master/guava/src/com/google/common/util/concurrent/RateLimiter.java#L131&#34;&gt;RateLimiter&lt;/a&gt;实现了比较有意思的功能：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;平滑。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;记录未使用的信息。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;保存下次请求被满足的时间。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;平滑&#34;&gt;平滑&lt;/h2&gt;

&lt;p&gt;通过令牌桶算法实现。&lt;/p&gt;

&lt;h2 id=&#34;记录未使用信息&#34;&gt;记录未使用信息&lt;/h2&gt;

&lt;p&gt;实现中通过&lt;code&gt;storedPermits&lt;/code&gt;表示有多长时间没有被使用了。这个信息可以处理资源的两种情况：&lt;br /&gt;
1. 资源充足。这个实现是Burst模式。&lt;br /&gt;
2. 资源超载。比如说缓存过期，导致请求处理变慢。这个实现是Warmup模式。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;storedPermits&lt;/code&gt;的计算公式：&lt;code&gt;min(maxPermits, timeNotUsedMicros/coolDownIntervalMicros())&lt;/code&gt;，其中&lt;code&gt;coolDownIntervalMicros()&lt;/code&gt;和&lt;code&gt;maxPermits&lt;/code&gt;在不同模式下面计算方式不同。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Burst模式&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;当RateLimiter发现资源没有没使用一段时间以后，任务现在资源的十分充分的，当请求过来的时候直接可以满足。&lt;code&gt;storedPermits&lt;/code&gt;代表的就是当前充足资源的数量。&lt;/p&gt;

&lt;p&gt;另外，&lt;code&gt;coolDownIntervalMicros()&lt;/code&gt;返回&lt;code&gt;stableIntervalMicros&lt;/code&gt;，&lt;code&gt;maxPermits&lt;/code&gt;等于&lt;code&gt;permitsPerSecond&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Warmup模式&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;          ^ throttling
          |
    cold  +                  /
 interval |                 /.
          |                / .
          |               /  .   ← &amp;quot;warmup period&amp;quot; is the area of the trapezoid between
          |              /   .     thresholdPermits and maxPermits
          |             /    .
          |            /     .
          |           /      .
   stable +----------/  WARM .
 interval |          .   UP  .
          |          . PERIOD.
          |          .       .
        0 +----------+-------+--------------→ storedPermits
          0 thresholdPermits maxPermits
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上图是warmup模式消耗&lt;code&gt;storedPermits&lt;/code&gt;所需要时间的建模。&lt;br /&gt;
1. RateLimiter的状态是一条垂直线，包含两个信息：当前的&lt;code&gt;storedPermits&lt;/code&gt;和被消耗时需要的时间。&lt;br /&gt;
2. 当RateLimiter没有被使用时，&lt;code&gt;storedPermits&lt;/code&gt;向&lt;code&gt;maxPermits&lt;/code&gt;增加，增速是&lt;code&gt;warmupPeriodMicro/maxPermits&lt;/code&gt;。&lt;br /&gt;
3. 当RateLimiter被使用时，&lt;code&gt;storedPermits&lt;/code&gt;向0减少，需要的时间是这个函数的积分。&lt;/p&gt;

&lt;p&gt;注意：&lt;br /&gt;
1. 这里&lt;code&gt;thresholdPermits&lt;/code&gt;是任意值，源代码中假设&lt;code&gt;storedPermits&lt;/code&gt;从&lt;code&gt;thresholdPermits&lt;/code&gt;减少到0需要的时间为&lt;code&gt;warmupPeriod/2&lt;/code&gt;。因此，&lt;code&gt;thresholdPermits=0.5*warmupPeriod/stableInterval&lt;/code&gt;。&lt;br /&gt;
2. 另外，&lt;code&gt;storedPermits&lt;/code&gt;从&lt;code&gt;maxPermits&lt;/code&gt;减少到&lt;code&gt;thresholdPermits&lt;/code&gt;需要的时间为&lt;code&gt;warmupPeriod&lt;/code&gt;，因此&lt;code&gt;maxPermits=thresholdPermits + 2 * warmupPeriod / (stableInterval + coldInterval)&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;当RateLimiter发现资源没有没使用一段时间以后，请求再来的时候，资源需要一个预热，这个过程中请求处理会比预热完以后有一个变化。这个变化的效果可以是快也可以是慢，这个是根据&lt;code&gt;coldFactor&lt;/code&gt;来定义。当这个值分三种情况：&lt;br /&gt;
1. 等于1，相当于没有预热效果。&lt;br /&gt;
2. 小于1，表示在没有使用这段时间里面，资源会有一部分的囤积，可以较快处理请求。&lt;br /&gt;
3. 大于1，表示在没有使用这段时间里面，资源被回收，需要重新申请来处理请求，所以会比较慢。&lt;/p&gt;

&lt;p&gt;另外，&lt;code&gt;coolDownIntervalMicros()&lt;/code&gt;返回&lt;code&gt;warmupPeriodMicro/maxPermits&lt;/code&gt;。这是一个任意值，没有理论依据。&lt;/p&gt;

&lt;h2 id=&#34;保存下次请求被满足的时间&#34;&gt;保存下次请求被满足的时间&lt;/h2&gt;

&lt;p&gt;这样做的好处是，可以比较方便判断在一段时间内，多个资源是否被满足的逻辑。permit的使用来源于两个地方：一段时间未使用而累积的&lt;code&gt;storedPermits&lt;/code&gt;，以及一段时间以后才能满足的，假设用&lt;code&gt;freshPermits&lt;/code&gt;表示。在不同模式下面消耗&lt;code&gt;storedPermits&lt;/code&gt;和&lt;code&gt;freshPermits&lt;/code&gt;需要的时间是不一样的。总的公式：&lt;code&gt;freshPermits * stableIntervalMicros + storedPermitsToWaitTime(storedPermits,permitsToTake)&lt;/code&gt;，其中&lt;code&gt;storedPermitsToWaitTime(...)&lt;/code&gt;在不同模式下面，实现方式不一样。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Burst模式&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在这个模式下面，&lt;code&gt;storedPermitsToWaitTime(storedPermits,permitsToTake)&lt;/code&gt;返回值是0。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Warmup模式&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;storedPermitsToWaitTime(storedPermits,permitsToTake)&lt;/code&gt;返回的是建模函数在&lt;code&gt;storedPermits,permitsToTake&lt;/code&gt;之间的积分（图像面积）。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>限流</title>
      <link>http://zjykzk.github.io/post/cs/dist/rate-limit/</link>
      <pubDate>Thu, 30 Aug 2018 16:48:26 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/dist/rate-limit/</guid>
      <description>

&lt;h2 id=&#34;缘起&#34;&gt;缘起&lt;/h2&gt;

&lt;p&gt;为了保证API的可用性，以及系统的可靠性，需要为API限速。不然，API请求量大到系统无法处理时就会出现系统变慢，甚至宕机的情况。常见的限速场景：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;挡住某个用户的过多请求（用户激增或者恶意请求），确保正常处理其他用户请求。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;挡住过多的低优先级的请求，确保核心请求得到处理。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;由于系统内部错误，导致系统处理能力下降，调节系统的处理能力。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;挡住过多某类请求，确保其他请求可以得到处理。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;限速类型&#34;&gt;限速类型&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;请求限速&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;限制API在一秒中内能够处理的请求数量。如果超过这个数量，等待或者拒绝服务。通常情况下这个是首选。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;并发限制&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;针对资源敏感的请求，比如CPU密集型API，进行并发限制，限制某一时刻最多只有有限个请求正在被处理。防止因为这些请求占用资源，导致其他请求得不到处理。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;基于资源利用率限速&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;针对不同的请求分配了不同百分比的资源，当某一类请求超载时，对这类请求限速。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;基于worker限速&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这个是基于代码特征的限速。每类API通过不同的worker线程负责处理，当worker线程中出现请求堆积时进行限速。&lt;/p&gt;

&lt;h2 id=&#34;限速结果&#34;&gt;限速结果&lt;/h2&gt;

&lt;p&gt;http服务的话按照场景返回429或者503。&lt;/p&gt;

&lt;h2 id=&#34;常用算法&#34;&gt;常用算法&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;计数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;单位时间内计数，超过这个数量时，拒绝服务，每个单位时间开始后计数清零。缺点是在时间边界处，会超过上限。比如，每秒限速100，在0.9s的时候来了100个请求全部得到处理，在下一秒0.1s来了100个请求。在0.9s到1.1s这个范围小于1s，但是请求达到了200。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; 0.1s 0.2s 0.3s 0.4s 0.5s 0.6s 0.7s 0.8s 0.9s 0.1s 0.2s
+----+----+----+----+----+----+----+----+----+----+----+---
| 0  | 0  | 0  | 0  | 0  | 0  | 0  | 0  | 100| 100| 0  | 0 
+----+----+----+----+----+----+----+----+----+----+----+---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;队列&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;请求过来的时候，先如队列，处理逻辑处理队列中的请求。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;基于大小的队列：当队列大小超过一个阀值的时候，拒绝新来的请求。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;基于时间的队列：请求在队列里面的时间超过多长时间没有被处理，立即返回。RocketMQ就是采用这种方式。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;优先级队列：对请求做优先级分类，不同优先级的请求进入不同的队列。为了避免低优先级请求被饿死，需要对不同优先级队列分配不同的处理时间。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Leaky_bucket&#34;&gt;漏桶&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://zjykzk.github.io/imgs/leaky-bucket.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;有一个容量固定的桶，桶中的请求以恒定的速率被处理。请求过来的时候，尝试进入桶，当桶满时被丢弃。本质上是队列后面加一个速率限制器。&lt;/p&gt;

&lt;p&gt;漏桶还有一个变形，在漏桶前面加一个队列。当桶满的时候，先放入队列，这样可以保留一部分请求。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Token_bucket&#34;&gt;令牌桶&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://zjykzk.github.io/imgs/token-bucket.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;以恒定的速率向桶中加入token，当请求过来的时候从桶中获取token。如果桶空了，请求等待或者丢弃。相比漏桶令牌桶还可以做蓄水，当桶满的时候可以预留一部分token，可以做到突发(burst)的请求。&lt;/p&gt;

&lt;h2 id=&#34;实现&#34;&gt;实现&lt;/h2&gt;

&lt;p&gt;Guava中的&lt;a href=&#34;https://github.com/google/guava/blob/master/guava/src/com/google/common/util/concurrent/RateLimiter.java#L131&#34;&gt;RateLimter&lt;/a&gt;是一个平滑的基于令牌桶的实现，同时还实现了warm up特点的一个&lt;a href=&#34;https://github.com/google/guava/blob/master/guava/src/com/google/common/util/concurrent/RateLimiter.java#L161&#34;&gt;Ratelimiter&lt;/a&gt;。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>分布式ID生成算法</title>
      <link>http://zjykzk.github.io/post/cs/dist/uuid/</link>
      <pubDate>Wed, 22 Aug 2018 11:08:28 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/dist/uuid/</guid>
      <description>

&lt;p&gt;分布式Unique ID在分布式系统使用很广泛，常用的用途有：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;请求的ID，用于跟踪请求链路。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;消息队列中的unique id。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;业务对象的id。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;总结下生成分布式ID常用算法。&lt;/p&gt;

&lt;h2 id=&#34;数据库自增id&#34;&gt;数据库自增id&lt;/h2&gt;

&lt;p&gt;通过MySQL中的&lt;code&gt;auto_increment&lt;/code&gt;特性来实现数据库唯一的ID。问题是扩展性差，性能受限于一台机器。可以做的优化是使用多个数据库实例，设置相同的步长和不同的起始值，避免重复产生ID。通过一个这种方式可以利用多台机器的资源。同时，还有一个优化是获取ID的时候可以批量获取ID，这样可以减少DB的操作，减少响应时间。&lt;/p&gt;

&lt;p&gt;基于Redis，Postgres，Oracle也有类似的方案。&lt;/p&gt;

&lt;h2 id=&#34;uuid-http-www-ietf-org-rfc-rfc4122-txt&#34;&gt;&lt;a href=&#34;http://www.ietf.org/rfc/rfc4122.txt&#34;&gt;UUID&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;UUID由&lt;code&gt;[0-9a-f-]&lt;/code&gt;字符组成，总共16个字节，转换成16进制的格式为：&lt;code&gt;XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;数据由5个部分组成：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;时间戳，占60位。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;时钟序列，占13位。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;结点编号，占48位。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;版本号，版本不同以上1-3个字段的数据来源也不一样，占4位。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;UUID类型，用于解析UUID数据中的意义，占3位。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;每个数据的位置：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                          time_low                             |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |       time_mid                |         time_hi_and_version   |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |clk_seq_hi_res |  clk_seq_low  |         node (0-1)            |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
   |                         node (2-5)                            |
   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;time_hi_and_version&lt;/code&gt;的第4-7位是版本号，&lt;code&gt;clk_seq_hi_res&lt;/code&gt;的第5-7位是UUID类型编号。&lt;/p&gt;

&lt;p&gt;UUID类型常用的有是&lt;strong&gt;IETF&lt;/strong&gt;和微软兼容的类型，UUID类型编号分别是&lt;code&gt;10x&lt;/code&gt;和&lt;code&gt;110&lt;/code&gt;，x是任意值。以下讨论的是IETF。&lt;/p&gt;

&lt;p&gt;UUID总共有5个版本，每个版本数据源和算法各有差异。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;版本&lt;/th&gt;
&lt;th&gt;时间戳&lt;/th&gt;
&lt;th&gt;时钟序列&lt;/th&gt;
&lt;th&gt;结点编号&lt;/th&gt;
&lt;th&gt;版本号&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;自1582年10月15号，100纳秒数&lt;/td&gt;
&lt;td&gt;随机数。&lt;br /&gt;如果时间戳回退，这个值需要在上一个序列上面递增&lt;/td&gt;
&lt;td&gt;mac地址&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;自1582年10月15号，100纳秒数，同时会把低4个字节替换成GID或者UID（根据domain值）&lt;/td&gt;
&lt;td&gt;随机数。但是最低位会被替换成domain&lt;/td&gt;
&lt;td&gt;mac地址&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;给定命名空间和字符串通过MD5计算散列值&lt;/td&gt;
&lt;td&gt;散列值&lt;/td&gt;
&lt;td&gt;散列值&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;随机数&lt;/td&gt;
&lt;td&gt;随机数&lt;/td&gt;
&lt;td&gt;随机数&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;给定命名空间和字符串通过SHA-1计算散列值&lt;/td&gt;
&lt;td&gt;散列值&lt;/td&gt;
&lt;td&gt;散列值&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;最常用的还是版本1和4。显然，两个版本都无法保证绝对唯一。版本1在100纳秒里面就会重复，而版本4就是概率问题了。&lt;/p&gt;

&lt;h2 id=&#34;mongodb的objectid&#34;&gt;mongodb的ObjectID&lt;/h2&gt;

&lt;p&gt;ObjectID是UUID版本1的变种。总共12个字节。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;4个字节时间戳，unix时间，秒。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;3个字节机器标识。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;2个字节进程id。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;3个字节计数，起始值是一个随机数，过秒不归零。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;每秒能支持2^24-1个不同的id，千万级别。&lt;/p&gt;

&lt;h2 id=&#34;twitter-snowflake派号器&#34;&gt;twitter snowflake派号器&lt;/h2&gt;

&lt;p&gt;snowflake占8个字节。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;1个bit保留。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;41个bit的时间戳，unix时间，毫秒。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;10个bit机器标识，5 bit是data center标识，5 bit是work标识。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;12个bit的序号，过毫秒归零，保证id的递增。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;没毫秒支持2^12=4096个不同的id。&lt;/p&gt;

&lt;h2 id=&#34;uid要求&#34;&gt;UID要求&lt;/h2&gt;

&lt;p&gt;文章&lt;a href=&#34;http://ericliang.info/what-kind-of-id-generator-we-need-in-business-systems/&#34;&gt;《业务系统需要什么样的ID生成器》&lt;/a&gt;的提法很好： 唯一性，时间相关，粗略有序，可反解，可制造。&lt;/p&gt;

&lt;h2 id=&#34;扩展阅读&#34;&gt;扩展阅读&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://calvin1978.blogcn.com/articles/uuid.html&#34;&gt;《服务化框架－分布式Unique ID的生成方法一览》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://calvin1978.blogcn.com/articles/%E2%80%9Chttp://chuansong.me/n/2459549%E2%80%9D&#34;&gt;《细聊分布式ID生成方法》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://mp.weixin.qq.com/s?__biz=MzA5Nzc4OTA1Mw==&amp;amp;mid=2659598286&amp;amp;idx=1&amp;amp;sn=3172172ccea316b0ed83429ae718b54d&amp;amp;chksm=8be9eadcbc9e63caa10d708274b4fa34ceffa416ef4527e10e6b7a1a2d2f32cf8592d65bf728&#34;&gt;《生成全局唯一ID的3个思路，来自一个资深架构师的总结》&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>mongodb索引</title>
      <link>http://zjykzk.github.io/post/cs/mongodb/</link>
      <pubDate>Fri, 20 Jul 2018 16:18:23 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/mongodb/</guid>
      <description>

&lt;h2 id=&#34;默认索引&#34;&gt;默认索引&lt;/h2&gt;

&lt;p&gt;每个文档默认都有一个字段&lt;code&gt;_id&lt;/code&gt;，这个字段会自动生成唯一索引，这个索引无法删除。这个字段的值可以是用户指定，如果不指定mongodb会自动生成。&lt;/p&gt;

&lt;p&gt;生成的规则：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;|&amp;lt;-- 4 --&amp;gt;|&amp;lt;- 3 -&amp;gt;|&amp;lt;-2-&amp;gt;|&amp;lt;-- 3 --&amp;gt;|
+---------+-------+-----+---------+
|unix time| mid   | pid | counter |
+---------+-------+-----+---------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;包含四个字段：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;unix时间戳，4个字节&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;机器id，3个字节&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;进程id，2个字节&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;计数器，3个字节，自增，从一个随机数开始&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;索引类型&#34;&gt;索引类型&lt;/h2&gt;

&lt;h3 id=&#34;单字段索引&#34;&gt;单字段索引&lt;/h3&gt;

&lt;p&gt;文档中的任何字段或者子文档的字段都可以当作索引，字段的值也可以是一个文档。&lt;/p&gt;

&lt;h3 id=&#34;复合索引-compound-index&#34;&gt;复合索引（compound index）&lt;/h3&gt;

&lt;p&gt;一个文档中的多个字段组成一个索引。最多支持31个字段。&lt;/p&gt;

&lt;h4 id=&#34;prefixes&#34;&gt;Prefixes&lt;/h4&gt;

&lt;p&gt;当查询的条件是索引的前面几个字段时会使用复合索引。&lt;/p&gt;

&lt;p&gt;比如：有索引&lt;code&gt;{a:1,b:1,c:1}&lt;/code&gt;，查询条件&lt;code&gt;{a:&amp;quot;a&amp;quot;,b:&amp;quot;b&amp;quot;}&lt;/code&gt;就会使用这个索引，但是&lt;code&gt;{b:&amp;quot;b&amp;quot;}&lt;/code&gt;这样的查询条件就无法使用。&lt;/p&gt;

&lt;h4 id=&#34;排序&#34;&gt;排序&lt;/h4&gt;

&lt;p&gt;索引的顺序先按第一个字段排序，如果第一个字段相等，按照第二个字段排序，依次类推后面的字段顺序。因此，&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;如果有以下索引&lt;code&gt;{a:1,b:1}&lt;/code&gt;，支持排序&lt;code&gt;{a:-1,b:-1}/{a:1:b:1}&lt;/code&gt;，不支持排序&lt;code&gt;{a:-1:b:1}/{a:1:b:-1}&lt;/code&gt;。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;只支持&lt;strong&gt;Prefixes&lt;/strong&gt;的排序。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;多值索引-multikey-index&#34;&gt;多值索引（multikey index）&lt;/h3&gt;

&lt;p&gt;字段的值是一个数组，就会自动把这个索引变成多值索引，支持范围查询。&lt;/p&gt;

&lt;h3 id=&#34;地理空间索引-geospatial-index&#34;&gt;地理空间索引（geospatial index）&lt;/h3&gt;

&lt;p&gt;包含两种索引：2d/2dsphere index&lt;/p&gt;

&lt;h3 id=&#34;文本索引-text-indexes&#34;&gt;文本索引（text indexes）&lt;/h3&gt;

&lt;p&gt;作用于值是字符串或者是字符串数组的字段，查询字段中是否包含查询字符串。&lt;/p&gt;

&lt;h3 id=&#34;哈希索引-hashed-indexes&#34;&gt;哈希索引（hashed indexes）&lt;/h3&gt;

&lt;p&gt;用于基于hash的sharding。&lt;/p&gt;

&lt;h3 id=&#34;交集索引-index-intersection&#34;&gt;交集索引（index intersection）&lt;/h3&gt;

&lt;p&gt;如果查询条件中出现使用了多个索引，包括&lt;strong&gt;Prefixes&lt;/strong&gt;索引。mongodb可能会使用多个索引进行查询，然后取交集。是否使用了这个索引，可以通过&lt;code&gt;explain&lt;/code&gt;来确定。&lt;/p&gt;

&lt;p&gt;当查询需要排序，同时排序的字段需要的索引和查询条件无法组成一个或者部分&lt;code&gt;query predicate&lt;/code&gt;，那就无法使用这个索引了。&lt;/p&gt;

&lt;p&gt;比如：有索引&lt;code&gt;{a:1}/{b:1,c:1}&lt;/code&gt;，查询&lt;code&gt;db.col.find({a:&#39;a&#39;}).sort({b:1})&lt;/code&gt;无法使用，虽然排序中包含字段&lt;code&gt;b&lt;/code&gt;，但是查询条件中无法使用这个索引；而查询&lt;code&gt;db.col.find({a:&#39;a&#39;,b:&#39;b&#39;}).sort({c:1})&lt;/code&gt;却可以使用两个索引，这是因为查询条件中有&lt;code&gt;{b:&#39;b&#39;}&lt;/code&gt;和排序字段&lt;code&gt;{c:1}&lt;/code&gt;，索引&lt;code&gt;{b:1,c:1}&lt;/code&gt;组成部分查询条件。&lt;/p&gt;

&lt;h2 id=&#34;索引的属性&#34;&gt;索引的属性&lt;/h2&gt;

&lt;h3 id=&#34;唯一性&#34;&gt;唯一性&lt;/h3&gt;

&lt;p&gt;可以指定一个索引唯一。&lt;/p&gt;

&lt;h3 id=&#34;部分索引-partial-indexes&#34;&gt;部分索引（partial indexes）&lt;/h3&gt;

&lt;p&gt;只索引满足条件的文档，它是稀疏索引的超集，相比稀疏索引采用部分索引。&lt;/p&gt;

&lt;h3 id=&#34;稀疏索引-sparse-indexes&#34;&gt;稀疏索引（sparse indexes）&lt;/h3&gt;

&lt;p&gt;只索引存在该字段值的文档。&lt;/p&gt;

&lt;h4 id=&#34;ttl-time-to-live-索引&#34;&gt;TTL（time to live）索引&lt;/h4&gt;

&lt;p&gt;过期索引，针对值为日期或者日期数组的字段。如果字段值超过了过期日期，就会自动删除。过期时间可以动态修改的，有两种方式指定过期行为：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;指定字段日期和过期时长。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;指定过期日期，同时过期时长为0。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;优化&#34;&gt;优化&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;如果查询的内容和条件都只引用索引时，那么只需要扫描索引数据，不需要查询文档内容。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;background构建，增量式构建索引。构建时，可以处理其他请求，但是构建索引的请求会被阻塞。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;限制&#34;&gt;限制&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;每个index entry的大小不能超过1024字节，超过这个大小的文档会无法插入。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;每个collection最多拥有64个索引。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;索引名字长度 最多128字符，名字规范：&lt;database name&gt;.&lt;collection name&gt;.$&lt;index name&gt; ，其中index name，默认是字段名字+类型，这个名字可以在创建索引的时候指定。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;复合索引最多允许使用31个字段。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;查询条件不能同时使用文本索引和地理空间索引。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;2dsphere index的值只能是几何数据。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;多值索引无法做cover query优化，比如：字段&lt;code&gt;{a:[{b:1},{b:2}]}&lt;/code&gt;。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;地理空间索引无法做cover query优化。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;构建索引的请求执行时构建会有一个内存限制，超过这个限制会使用临时文件。可以阀值可以修改。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;text/2d/geoHaystack索引无法使用collation。&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>接口在哪里定义？</title>
      <link>http://zjykzk.github.io/post/cs/design/interface-owner/</link>
      <pubDate>Sun, 15 Jul 2018 15:11:11 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/design/interface-owner/</guid>
      <description>&lt;p&gt;接口放在哪里决定了源代码依赖问题。因此，依赖是接口定义唯一考量，其他问题都可以归结为依赖问题，而定义的包永远是被依赖包。&lt;/p&gt;

&lt;p&gt;接口定义的位置有三种情况：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;使用者&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;实现者&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;单独一个第三方位置&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;放在使用者这边&lt;/strong&gt;，那么实现者依赖使用者的接口定义。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;好处&lt;/strong&gt;：可以并行开发，尤其是类似golang这样的语言，实现一接口不需要引用具体的接口定义，即使在必须引用的开发语言里面也只需要实现相关的接口，集成的时候加上是很简单的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;坏处&lt;/strong&gt;：在实现者依赖接口定义源代码的情况下，实现者代码要提出来重用，必须要得要包含使用者的接口定义&lt;/p&gt;

&lt;p&gt;这样的方式比较适合多个使用者，单个实现者的情况。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;放在实现者这边&lt;/strong&gt;，那么使用者依赖实现者的接口定义。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;好处&lt;/strong&gt;：实现者是一个独立的包，可以很方便的重用。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;坏处&lt;/strong&gt;：使用者开发的时候需要引用实现者的接口定义，增加并行开发的难度，这里可以自己mock接口，集成的时候改成实现者的接口即可。&lt;/p&gt;

&lt;p&gt;这样的方式适合单个使用者，多个实现者情况。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;单独放在第三方位置&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;好处&lt;/strong&gt;：定义完接口以后，使用者和实现者都可以并行开发，同时实现者包的重用和使用者解耦。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;坏处&lt;/strong&gt;：包的管理变得复杂，包含接口的包会变得很薄&lt;/p&gt;

&lt;p&gt;这样的方式适合多个使用者，多个实现者情况。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>常用面向对象设计原则</title>
      <link>http://zjykzk.github.io/post/cs/design/soild/</link>
      <pubDate>Wed, 04 Jul 2018 22:28:20 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/design/soild/</guid>
      <description>

&lt;h2 id=&#34;设计&#34;&gt;设计&lt;/h2&gt;

&lt;p&gt;软件的复杂来源于需求的易变，意味着软件本身容易修改。好设计的目的就是提供软件的可修改能力，也就是可维护性、扩展性。SOILD原则就是在设计过程中达到这个目标的一些原则。&lt;/p&gt;

&lt;h2 id=&#34;单一职责原则&#34;&gt;单一职责原则&lt;/h2&gt;

&lt;p&gt;又名SRP（Single Responsibility Principle）。针对一个函数、类、组件、架构的修改有且只有一个理由，而理由的来自于使用者。&lt;/p&gt;

&lt;p&gt;这样的好处是把拥有相同修改理由的函数、类、组件组织在一起，不同的分开，达到修改的时候不会影响其他代码，增强了可维护性。&lt;/p&gt;

&lt;p&gt;这是一个定义简单，实操不容易正确的原则。原因在于：&lt;br /&gt;
1. &lt;strong&gt;职责&lt;/strong&gt;无法度量。&lt;br /&gt;
2. 因为团队、项目背景等待原因，在具体实现的细节中很难做到SRP。&lt;/p&gt;

&lt;p&gt;因此，在设计的时候接口一定做到SRP，实现尽量SRP。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;组件层面的SRP，叫做Component common closure，架构层面的SRP叫做axis of change responsibility for creation of architecture boundary。&lt;/p&gt;

&lt;h2 id=&#34;开闭原则&#34;&gt;开闭原则&lt;/h2&gt;

&lt;p&gt;又名OCP（Open-Close Principle）。对扩展开发，对修改关闭。&lt;/p&gt;

&lt;p&gt;通过这样的方式达到添加一个功能时，尽可能少的修改现有源代码、模块、二进制文件，尽可能的通过添加代码来实现。这样减少原来的功能被破坏的概率，达到软件的可维护性、可扩展性、可复用性。因此，它是其他面向对象设计原则的核心。&lt;/p&gt;

&lt;p&gt;遵守OCP原则的手段是&lt;strong&gt;抽象&lt;/strong&gt;。一个功能的抽象，更依赖于使用者，而非实现者。只有使用者才明白需要抽象什么内容。抽象的难点是找到易变的部分，一个指导原则是“快速失败，下不为例”，有以下几条参考实践：&lt;br /&gt;
1. TDD，先写测试代码。&lt;br /&gt;
2. 更短的开发周期。&lt;br /&gt;
3. 先开发特性，后开发基础设施代码，并经常给使用者review。&lt;br /&gt;
4. 先开发重要功能。&lt;br /&gt;
5. 经常并尽早发布，尽可能让用户和使用者使用。&lt;/p&gt;

&lt;p&gt;抽象的对象一般是类、模块以及组件。几个比较的好的实践：&lt;br /&gt;
1. 在函数参数、类抽象中提供稳定的接口定义。&lt;br /&gt;
2. 通过元数据抽象逻辑，比如通过配置的形式表达逻辑。&lt;br /&gt;
3. 定义项目章程，建立团队文化，沉淀优秀的习惯，提高开发效率。&lt;br /&gt;
4. 在架构层面，分析功能变化的来源、时机以及原因，把功能划分为不同的组件，底层组件依赖高层组件，高层组件不会受到底层组件变化的影响，同时避免循环依赖。&lt;br /&gt;
5. 抽象的时候需要避免过度抽象，带来不必要的复杂度。&lt;/p&gt;

&lt;h2 id=&#34;里氏替换原则&#34;&gt;里氏替换原则&lt;/h2&gt;

&lt;p&gt;又名LSP（Liskov Substitutiion Principle）。基类能够被子类代替，并且保证程序行为不变。&lt;/p&gt;

&lt;p&gt;OCP的实现需要使用抽象和多态，静态语言中继承是多态的一个重要实现方式。LSP就是解决继承带来的一些问题，比如侵入性、耦合性、缺乏灵活性。遵守LSP能够更加容易遵守OCP，因为子类可以替换基类，达到不修改原来代码，通过扩展的方式，添加逻辑。提高程序的健壮性，版本升级的兼容性。&lt;/p&gt;

&lt;p&gt;继承中常说的IS-A，强调的是方法的行为，子类中的方法行为要和基类中的一致，而不是性质一致。这个行为需要从设计的使用者角度来判断模块。模块逻辑的一致性，说的就是这个行为需要一致。所以，IS-A语义是子类替换时，保证程序行为一致。&lt;/p&gt;

&lt;p&gt;虽然这里LSP强调代码中的继承，其实LSP也适用于其他约定的服务、组件，这些内容修改、替换以后都不应该影响原来程序的行为。&lt;/p&gt;

&lt;p&gt;几个比较好的实践：&lt;br /&gt;
1. 当子类中override的方法工作比较少时，可能违反LSP。&lt;br /&gt;
2. 采用DBC（design by contract）编程方法。约定方法的前置条件和后置条件，在LSP下，子类中的前置条件只能比基类的弱，而子类中的后置条件只能比基类的强。因为，如果子类中的前置条件强，那么替换以后原来基类的前置条件下的输入就没法满足了，同样如果子类的后置条件弱，那么方法的输出在一些情况下程序行为就会和原来的不一样。&lt;/p&gt;

&lt;h2 id=&#34;依赖反转原则&#34;&gt;依赖反转原则&lt;/h2&gt;

&lt;p&gt;又名DIP（Dependence Inversion Principle）。高层不依赖底层，依赖抽象，底层也只依赖抽象；抽象不依赖细节，细节依赖抽象。&lt;/p&gt;

&lt;p&gt;反转（inversion）包含两层含义：&lt;br /&gt;
1. 控制流和源代码依赖相反，a模块执行时会调用b模块函数，但是源代码层面来说b模块会依赖a模块。&lt;br /&gt;
2. 接口所有者，原先a模块使用b模块定义的接口，而现在接口放在了a模块中，从而从源代码层面来说b模块依赖a模块。&lt;/p&gt;

&lt;p&gt;为什么要依赖抽象？显然抽象比实现细节稳定。从编程语言角度上来说，接口变了实现不变，而实现变了，接口不一定变，显然接口更加稳定。因此，接口的稳定也十分重要。&lt;/p&gt;

&lt;p&gt;DIP能够减少类、模块之间的耦合，提供系统的稳定性，提高代码的复用性、可扩展性、可读性和可维护性。它是其他OO设计技巧的基础。&lt;/p&gt;

&lt;p&gt;建立依赖的方式：&lt;br /&gt;
1. 构造函数传递依赖对象。&lt;br /&gt;
2. setter方法传递对象。&lt;br /&gt;
3. 接口声明依赖对象，接口中的方法参数、返回值中引用其他接口。&lt;/p&gt;

&lt;p&gt;几个比较好的实践：&lt;br /&gt;
1. 每个类尽量有接口或者抽象类。&lt;br /&gt;
2. 变量的表面类型尽量是接口、抽象类型或者是不易变的类。&lt;br /&gt;
3. 任何类不从易变的具体类派生。在维护代码的时候这个实践经常会被破坏。&lt;br /&gt;
4. 尽量不要override基类的方法。&lt;br /&gt;
5. 创建对象时考虑使用工厂模式。&lt;/p&gt;

&lt;h2 id=&#34;接口分离原则&#34;&gt;接口分离原则&lt;/h2&gt;

&lt;p&gt;又名ISP（Interface Segregation Principles）。使用者不应该依赖它不使用的方法。所以，分离的使用者意味着分离的接口。&lt;/p&gt;

&lt;p&gt;当你依赖的接口包含不需要的方法时，加上依赖的传递性，从源代码角度看当接口的改变，你的代码可能会跟着改变（这是因为对动态语言来说不用修改原来的代码），从架构角度看由于组件依赖，当组件修改时，会导致组件的重新编译、发布。ISP的目的还是减少类、模块间的耦合，提供类、模块的内聚性，提高代码的可扩展性、可复用性。&lt;/p&gt;

&lt;p&gt;有两类接口：&lt;br /&gt;
1. class interface，在类层面履行接口，每个实现细节实现具体的接口，在golang中就是&lt;code&gt;interface&lt;/code&gt;定义的接口。&lt;br /&gt;
2. object interface，在对象层面履行接口，每个新建的对象拥有类的方法，在golang中就是&lt;code&gt;struct&lt;/code&gt;定义的方法。&lt;/p&gt;

&lt;p&gt;SRP也强调职责分离，虽然它的效果也会有ISP的效果，但是它是从业务逻辑的角度去归类职责并进行分离。而ISP是从接口的角度去分离接口，它是在SIP的基础上进一步的细分。&lt;/p&gt;

&lt;p&gt;几个比较好的实践：&lt;br /&gt;
1. 一个接口是只服务于一个模块或者业务逻辑。&lt;br /&gt;
2. 尽量减少公共的方法。&lt;br /&gt;
3. 保持接口的干净。如果有污染尽快修复。&lt;/p&gt;

&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;

&lt;p&gt;软件开发首要原则就是管理复杂度。显然，软件中的每个组成（函数、类、模块、组件）之间越独立（耦合性越低），整个软件的复杂度越低，软件就越容易维护。所以，软件设计原则中最重要的就是降低各个组成部分的耦合度。而，最重要的手段就是抽象。OOD的原则做的都是使用抽象这个利器来降低组成部分的耦合。他们从不同的角度来实现这个目标：业务逻辑角度（SRP），接口的角度（ISP），特定语言角度（LSP），软件扩展角度（OCP），组件依赖关系角度（DIP）。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>一致性hash算法</title>
      <link>http://zjykzk.github.io/post/cs/dist/cons-hash/</link>
      <pubDate>Sat, 28 Apr 2018 13:58:46 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/dist/cons-hash/</guid>
      <description>

&lt;h2 id=&#34;一致性hash&#34;&gt;一致性hash&lt;/h2&gt;

&lt;h3 id=&#34;目标&#34;&gt;目标&lt;/h3&gt;

&lt;p&gt;缓存的机器扩容、缩容时，尽量保持数据的命中率。常规的hash算法，&lt;code&gt;hash(key)mod N&lt;/code&gt; （N表示缓存结点），当N变化时同一个key查询的缓存结点都会变化，导致缓存没有命中，造成很大的数据库压力。&lt;/p&gt;

&lt;h3 id=&#34;原理&#34;&gt;原理&lt;/h3&gt;

&lt;p&gt;hash函数值大小32位，因此输出的范围是&lt;code&gt;0~2^32-1&lt;/code&gt;。把这个范围形成一个环，同时对数据进行hash计算以外，对缓存的机器也做hash计算。这些计算出来的值在这个环上都有对应的一个点。&lt;/p&gt;

&lt;p&gt;假设数据的hash值分别为&lt;code&gt;K1&lt;/code&gt;,&lt;code&gt;K2&lt;/code&gt;,&lt;code&gt;K3&lt;/code&gt;,&lt;code&gt;K4&lt;/code&gt;,&lt;code&gt;K5&lt;/code&gt;,&lt;code&gt;K6&lt;/code&gt;，以及缓存结点的hash值&lt;code&gt;H1&lt;/code&gt;,&lt;code&gt;H2&lt;/code&gt;,&lt;code&gt;H3&lt;/code&gt;,大小关系为&lt;code&gt;H1&amp;lt;K3&amp;lt;K4&amp;lt;K5&amp;lt;H2&amp;lt;K6&amp;lt;H3&amp;lt;K1&amp;lt;K2&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;每个数据所在的缓存结点是在这个环上顺时针方向遇到的第一个缓存结点既是。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://zjykzk.github.io/imgs/dist/ch1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;因此&lt;code&gt;K1&lt;/code&gt;,&lt;code&gt;K2&lt;/code&gt;落在&lt;code&gt;H1&lt;/code&gt;,&lt;code&gt;K3&lt;/code&gt;,&lt;code&gt;K4&lt;/code&gt;,&lt;code&gt;K5&lt;/code&gt;落在&lt;code&gt;H2&lt;/code&gt;,&lt;code&gt;K6&lt;/code&gt;落在&lt;code&gt;H3&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;添加一个新的缓存结点&lt;code&gt;H4&lt;/code&gt;，它的hash值落在&lt;code&gt;K4&lt;/code&gt;和&lt;code&gt;K5&lt;/code&gt;之间。按照规则，&lt;code&gt;K3&lt;/code&gt;,&lt;code&gt;K4&lt;/code&gt;将落在&lt;code&gt;H4&lt;/code&gt;，也就是说&lt;code&gt;K3&lt;/code&gt;,&lt;code&gt;K4&lt;/code&gt;将会失效而其他的数据不会影响。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://zjykzk.github.io/imgs/dist/ch2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;减少缓存结点&lt;code&gt;H3&lt;/code&gt;，&lt;code&gt;K6&lt;/code&gt;会受到影响，它将落在缓存结点&lt;code&gt;H1&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://zjykzk.github.io/imgs/dist/ch3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在次基础上可以抽象出一层缓存的虚拟缓存结点，这样的好处是可以事先确定缓存结点数量，让数据均匀的分布在每个虚拟缓存结点上面。每个物理缓存结点对应一个或者多个缓存结点。如下图中，有个4个虚拟缓存结点&lt;code&gt;VH1/VH2/VH3/VH4&lt;/code&gt;，两个物理缓存结点&lt;code&gt;H1/H2&lt;/code&gt;，分别对应&lt;code&gt;VH1/VH2和VH3/VH4&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://zjykzk.github.io/imgs/dist/ch4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>golang中的tls</title>
      <link>http://zjykzk.github.io/post/cs/golang/tls/</link>
      <pubDate>Tue, 27 Feb 2018 19:51:16 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/golang/tls/</guid>
      <description>&lt;p&gt;在golang中，为了性能的目的，当前执行的&lt;a href=&#34;https://github.com/golang/go/blob/release-branch.go1.8/src/runtime/runtime2.go#L332&#34;&gt;&lt;code&gt;g&lt;/code&gt;&lt;/a&gt;是保存在当前线程的TLS中的，而TLS的地址在结构体&lt;a href=&#34;https://github.com/golang/go/blob/release-branch.go1.8/src/runtime/runtime2.go#L412&#34;&gt;&lt;code&gt;m&lt;/code&gt;&lt;/a&gt;里面。问题是怎么放进去的呢？&lt;/p&gt;

&lt;p&gt;可以从程序的启动入手，顺藤摸瓜。&lt;/p&gt;

&lt;p&gt;编写一个打印&lt;code&gt;hello,world&lt;/code&gt;的程序&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// hello.go

package main

func main() {
        print(&amp;quot;hello, world&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;编译生成可执行文件&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go build -o hello hello.go
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;用gdb进行调试，找到程序的入口 &lt;a href=&#34;https://github.com/golang/go/blob/release-branch.go1.8/src/runtime/rt0_linux_amd64.s#L7&#34;&gt;&lt;code&gt;_rt0_amd64_linux&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gdb hello
(gdb) info files
...
Entry point: 0x448f20
...
(gdb) list *0x448f20
0x448f20 is in _rt0_amd64_linux (/home/zenk/tools/goroot/src/runtime/rt0_linux_amd64.s:8)
3       // license that can be found in the LICENSE file.
4
5       #include &amp;quot;textflag.h&amp;quot;
6
7       TEXT _rt0_amd64_linux(SB),NOSPLIT,$-8
8               LEAQ    8(SP), SI // argv
9               MOVQ    0(SP), DI // argc
10              MOVQ    $main(SB), AX
11              JMP     AX
12
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;发现&lt;code&gt;_rt0_amd64_linux&lt;/code&gt;调用了&lt;a href=&#34;https://github.com/golang/go/blob/release-branch.go1.8/src/runtime/rt0_linux_amd64.s#L72&#34;&gt;&lt;code&gt;main&lt;/code&gt;&lt;/a&gt;函数，后者调用了&lt;a href=&#34;https://github.com/golang/go/blob/release-branch.go1.8/src/runtime/asm_amd64.s#L10&#34;&gt;&lt;code&gt;runtime.rt0_go&lt;/code&gt;&lt;/a&gt;。而在函数&lt;code&gt;runtime.rt0_go&lt;/code&gt;中&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;127 	LEAQ	runtime·m0+m_tls(SB), DI
128 	CALL	runtime·settls(SB)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;把&lt;a href=&#34;https://github.com/golang/go/blob/release-branch.go1.8/src/runtime/proc.go#L79&#34;&gt;&lt;code&gt;m0.tls&lt;/code&gt;&lt;/a&gt;的地址放到寄存器&lt;code&gt;DI&lt;/code&gt;，并调用了函数&lt;code&gt;runtime.settls&lt;/code&gt;，查看&lt;a href=&#34;https://github.com/golang/go/blob/release-branch.go1.8/src/runtime/sys_linux_amd64.s#L496&#34;&gt;&lt;code&gt;runtime.settls&lt;/code&gt;&lt;/a&gt;核心代码&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;503 	ADDQ	$8, DI	// ELF wants to use -8(FS)
504 #endif
505 	MOVQ	DI, SI
506 	MOVQ	$0x1002, DI	// ARCH_SET_FS
507 	MOVQ	$158, AX	// arch_prctl
508 	SYSCALL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;可以看到，这里调用了系统调用&lt;a href=&#34;http://man7.org/linux/man-pages/man2/arch_prctl.2.html&#34;&gt;&lt;code&gt;arch_prctl&lt;/code&gt;&lt;/a&gt;，在linux下把&lt;code&gt;m0.tls+8&lt;/code&gt;的地址保存到&lt;code&gt;fs&lt;/code&gt;寄存器。到此，完成TLS的设置。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>vim常用操作</title>
      <link>http://zjykzk.github.io/post/cs/vim-tips/</link>
      <pubDate>Wed, 10 Jan 2018 18:16:35 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/vim-tips/</guid>
      <description>&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在命令模式使用函数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;:%s/ab(.*)c/\=submatch(1) . &#39;test&#39;/gc
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;窗口间切换&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;跳转至某个窗口：窗口number + c-w + w：
跳至当前位置的左边某个窗口：c-w &amp;lt;number&amp;gt;h
跳至当前位置的右边某个窗口：c-w &amp;lt;number&amp;gt;l
跳至当前位置的上边某个窗口：c-w &amp;lt;number&amp;gt;j
跳至当前位置的下边某个窗口：c-w &amp;lt;number&amp;gt;k
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;全文缩进&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gg=G
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;把数字替换成原来的数字减一&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;:%s/(\d+)/\=submatch(1)-1/gc
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;移动屏幕&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;H // 把当前行的位置移到最上面
M // 把当前行的位置移到屏幕中间
L // 把当前的位置移到屏幕底部
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;全局操作&lt;code&gt;g&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;:{range}g/patten/{range}/cmd // 后面的range是基于前面查询的结果
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;移动窗口&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CTRL-W [K/J/H/L/T] //  把窗口移到最上面、下面、左边、右边、新标签
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;跳到某个字符的左（右）边&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;t{char} // 跳转到左边
T{char} // 跳转到右边
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>jit的基本原理以及实现</title>
      <link>http://zjykzk.github.io/post/cs/jit/</link>
      <pubDate>Wed, 03 Jan 2018 15:12:25 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/jit/</guid>
      <description>

&lt;h2 id=&#34;基本原理&#34;&gt;基本原理&lt;/h2&gt;

&lt;p&gt;JIT（Just-In-Time）是指程序运行的过程中生成可执行的代码。这里有两个工作：&lt;br /&gt;
1. 生成可以执行的代码&lt;br /&gt;
2. 执行代码&lt;/p&gt;

&lt;h3 id=&#34;生成代码&#34;&gt;生成代码&lt;/h3&gt;

&lt;p&gt;生成的代码是平台相关，一般就是一些机器码。&lt;/p&gt;

&lt;h3 id=&#34;执行代码&#34;&gt;执行代码&lt;/h3&gt;

&lt;p&gt;生成的代码如果要被执行，必须要确保代码所在的内存拥有可执行的标志。在linux下面通过&lt;code&gt;mmap&lt;/code&gt;系统调用映射一块可执行的内存，然后把相关的代码复制到这块内存中。最后，把内存首地址转换成函数地址并进行调用。&lt;/p&gt;

&lt;h2 id=&#34;hello-world&#34;&gt;Hello，World&lt;/h2&gt;

&lt;p&gt;一个基于x86_64平台的JIT代码， 通过系统调用&lt;code&gt;write&lt;/code&gt;实现打印&lt;code&gt;hello,world！&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;基于x86-64平台的jit代码&#34;&gt;基于x86_64平台的JIT代码&lt;/h3&gt;

&lt;p&gt;linux下面系统调用通过软中断来实现，参数通过寄存器来传递。寄存器的使用情况如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;+----------+--------+--------+--------+--------+--------+--------+
| Syscall #| Param 1| Param 2| Param 3| Param 4| Param 5| Param 6|
+----------+--------+--------+--------+--------+--------+--------+
| rax      |  rdi   |  rsi   |   rdx  |   r10  |   r8   |   r9   |
+----------+--------+--------+--------+--------+--------+--------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;系统调用&lt;a href=&#34;http://man7.org/linux/man-pages/man2/write.2.html&#34;&gt;write(int fd, const void *buf, size_t count)&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;参数&lt;code&gt;fd&lt;/code&gt;:文件描述符号&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;参数&lt;code&gt;buf&lt;/code&gt;:输出的内存起始地址&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;参数&lt;code&gt;count&lt;/code&gt;:输出的字节数&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，x86_64平台下调用&lt;code&gt;write&lt;/code&gt;的机器码为&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0:  48 c7 c0 01 00 00 00    mov    rax,0x1
7:  48 c7 c7 01 00 00 00    mov    rdi,0x1
e:  48 c7 c2 0c 00 00 00    mov    rdx,0xc
15: 48 8d 35 03 00 00 00    lea    rsi,[rip+0x4]        # 0x1f
1c: 0f 05                   syscall
1e: c3 cc                   ret
1f: 48 65 6c 6c 6f 20 57 6f 72 6c 64 21   // Hello World!
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中：&lt;br /&gt;
1. &lt;code&gt;rax&lt;/code&gt;值为1，系统调用&lt;code&gt;write&lt;/code&gt;的编号&lt;br /&gt;
2. &lt;code&gt;rdi&lt;/code&gt;值为1，参数&lt;code&gt;fd&lt;/code&gt;的值，标准输出&lt;br /&gt;
3. &lt;code&gt;rsi&lt;/code&gt;值为&lt;code&gt;rip+4&lt;/code&gt;，参数&lt;code&gt;buf&lt;/code&gt;的值，通过相对地址得到&lt;br /&gt;
4. &lt;code&gt;rdx&lt;/code&gt;值为0xc（12），参数&lt;code&gt;count&lt;/code&gt;的值&lt;/p&gt;

&lt;h3 id=&#34;执行代码-1&#34;&gt;执行代码&lt;/h3&gt;

&lt;p&gt;通过系统调用&lt;a href=&#34;http://man7.org/linux/man-pages/man2/mmap.2.html&#34;&gt;void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset)&lt;/a&gt;创建内存映射，确保这块内存可以执行，通过参数&lt;code&gt;prot&lt;/code&gt;指定，其中&lt;code&gt;PROT_EXEC&lt;/code&gt;可执行，&lt;code&gt;PROT_READ&lt;/code&gt;可读，&lt;code&gt;PROD_WRITE&lt;/code&gt;可写。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;unsigned short code[] = {
    0x48c7, 0xc001, 0x0,          // mov %rax,$0x1
    0x48, 0xc7c7, 0x100, 0x0,     // mov %rdi,$0x1
    0x48c7, 0xc20c, 0x0,          // mov 0x12, %rdx
    0x48, 0x8d35, 0x400, 0x0,     // lea 0x4(%rip), %rsi
    0xf05,                        // syscall
    0xc3cc,                       // ret
    0x4865, 0x6c6c, 0x6f20,       // Hello_(whitespace)
    0x576f, 0x726c, 0x6421, 0xa,  // World!
};

#define PROTS PROT_READ|PROT_WRITE|PROT_EXEC
#define FLAGS MAP_PRIVATE|MAP_ANONYMOUS

void *m = mmap(NULL, sizeof(code), PROTS, FLAGS, -1, 0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;接下来，把机器码复制到刚刚映射的内存中，注意为了显示方便机器码保存在了&lt;code&gt;unsigned short&lt;/code&gt;数组中，加上x86_64平台字节顺序按照小端来存储，需要把机器码字节顺序调换。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for (int i = 0; i &amp;lt; sizeof(code)/sizeof(code[0]); i++) {
    *((unsigned short *)m+i) = (unsigned short)(((code[i]&amp;gt;&amp;gt;8) | (code[i]&amp;lt;&amp;lt;8)) &amp;amp; 0xffff);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最后，调用一个没有参数以及没有返回值的函数：&lt;code&gt;void (*)()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;((void (*)())m)();
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;完整代码&#34;&gt;完整代码&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;sys/mman.h&amp;gt;
#include &amp;lt;sys/types.h&amp;gt;
#define _GNU_SOURCE

int main(void) {
  unsigned short code[] = {
    0x48c7, 0xc001, 0x0,          // mov %rax,$0x1
    0x48, 0xc7c7, 0x100, 0x0,     // mov %rdi,$0x1
    0x48c7, 0xc20c, 0x0,          // mov 0x12, %rdx
    0x48, 0x8d35, 0x400, 0x0,     // lea 0x4(%rip), %rsi
    0xf05,                        // syscall
    0xc3cc,                       // ret
    0x4865, 0x6c6c, 0x6f20,       // Hello_(whitespace)
    0x576f, 0x726c, 0x6421, 0xa,  // World!
  };

#define PROTS PROT_READ|PROT_WRITE|PROT_EXEC
#define FLAGS MAP_PRIVATE|MAP_ANONYMOUS

  void *m = mmap(NULL, sizeof(code), PROTS, FLAGS, -1, 0);
  if (m == MAP_FAILED) {
      printf(&amp;quot;mmap error&amp;quot;);
      return -1;
  }

  for (int i = 0; i &amp;lt; sizeof(code)/sizeof(code[0]); i++) {
    *((unsigned short *)m+i) = (unsigned short)(((code[i]&amp;gt;&amp;gt;8) | (code[i]&amp;lt;&amp;lt;8)) &amp;amp; 0xffff);
  }

  ((void (*)())m)();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://medium.com/kokster/writing-a-jit-compiler-in-golang-964b61295f&#34;&gt;https://medium.com/kokster/writing-a-jit-compiler-in-golang-964b61295f&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>rocketmq store模块</title>
      <link>http://zjykzk.github.io/post/cs/rocketmq/store/</link>
      <pubDate>Fri, 08 Dec 2017 17:59:56 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/rocketmq/store/</guid>
      <description>

&lt;h2 id=&#34;功能&#34;&gt;功能&lt;/h2&gt;

&lt;p&gt;store模块是rocketmq的核心模块。主要功能有：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;消息存储&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;消息索引&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;消费队列&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;主从同步&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;延迟消息&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;清理过期的消息和消费队列&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;消息存储&#34;&gt;消息存储&lt;/h2&gt;

&lt;p&gt;负责消息存储，包括写消息，刷盘。&lt;/p&gt;

&lt;h3 id=&#34;消息文件&#34;&gt;消息文件&lt;/h3&gt;

&lt;p&gt;消息保存在默认值为&lt;code&gt;${user.home}\store\commitlog&lt;/code&gt;文件夹下，可以通过配置项&lt;code&gt;storePathCommitLog&lt;/code&gt;修改。所有的消息都写入一个逻辑文件，每个逻辑文件包含大小相等的物理文件。&lt;/p&gt;

&lt;h3 id=&#34;写消息&#34;&gt;写消息&lt;/h3&gt;

&lt;p&gt;写消息在不同的场景下面会有不同的逻辑。&lt;/p&gt;

&lt;h4 id=&#34;同步刷盘&#34;&gt;同步刷盘&lt;/h4&gt;

&lt;p&gt;每条消息要写到磁盘以后才算完成。&lt;/p&gt;

&lt;p&gt;在同步刷盘的场景下，会有一个定期检查消息是否已经写入磁盘的线程：&lt;code&gt;GroupCommitService&lt;/code&gt;，除了检查还会进行刷盘的操作 。写消息的时候会生成一个&lt;code&gt;GroupCommitRequest&lt;/code&gt;提交到&lt;code&gt;GroupCommitService&lt;/code&gt;，并等待被唤醒或者超时。当&lt;code&gt;GroupCommitService&lt;/code&gt;发现已经刷盘的最后一个消息的索引大于等于本消息的索引时就会唤醒&lt;code&gt;GroupCommitRequest&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;备注&lt;/strong&gt;：以上的场景还依赖于消息的属性&lt;code&gt;WAIT&lt;/code&gt;，只有该属性为空或者为&lt;code&gt;true&lt;/code&gt;才会执行同步刷盘逻辑，默认是空的。&lt;/p&gt;

&lt;h4 id=&#34;异步刷盘&#34;&gt;异步刷盘&lt;/h4&gt;

&lt;p&gt;在异步刷盘的场景下，会有一个把数据刷到磁盘的辅助线程：&lt;code&gt;FlushRealTimeService&lt;/code&gt;。写消息仅仅唤醒该线程就结束了写盘操作。&lt;/p&gt;

&lt;h4 id=&#34;主从同步&#34;&gt;主从同步&lt;/h4&gt;

&lt;p&gt;每条消息要等一个从broker同步完才算完成。&lt;/p&gt;

&lt;p&gt;在主从同步的场景下，会有一个定期检查消息是否已经被从broker同步的辅助线程：&lt;code&gt;GroupTransferService&lt;/code&gt;。写消息的时候会生成一个&lt;code&gt;GroupCommitRequest&lt;/code&gt;提交给&lt;code&gt;GroupTransferService&lt;/code&gt;，并等待被唤醒或者超时。当&lt;code&gt;GroupTransferService&lt;/code&gt;发现从broker已经同步的最后一个消息的索引大于本次消息的索引时就会唤醒&lt;code&gt;GroupCommitRequest&lt;/code&gt;。&lt;/p&gt;

&lt;h4 id=&#34;写buffer&#34;&gt;写buffer&lt;/h4&gt;

&lt;p&gt;使用了写buffer以后，写消息的全部逻辑就是把消息写入buffer。同时，系统会有一个线程&lt;code&gt;CommitRealTimeService&lt;/code&gt;定期把消息写入文件。&lt;/p&gt;

&lt;h3 id=&#34;核心代码&#34;&gt;核心代码&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;org.apache.rocketmq.store.CommitLog
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;消费队列&#34;&gt;消费队列&lt;/h2&gt;

&lt;p&gt;每个topic对应多个消费队列，这个是提高消费并发度的前提。&lt;/p&gt;

&lt;h3 id=&#34;结构&#34;&gt;结构&lt;/h3&gt;

&lt;p&gt;每个消费队列对应一个逻辑文件，文件中对应每个消息的内容大小是固定的20个字节，包含消息的偏移量，大小以及tag哈希值。&lt;/p&gt;

&lt;h4 id=&#34;文件目录&#34;&gt;文件目录&lt;/h4&gt;

&lt;p&gt;数据保存在目录&lt;code&gt;${rootpath}/consumequeue&lt;/code&gt;下面，&lt;code&gt;rootpath&lt;/code&gt; 通过配置项&lt;code&gt;storePathRootDir&lt;/code&gt;指定，默认的是&lt;code&gt;${user.home}/store&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;${rootpath}/consumequeue
└── 0%default                     // topic
    ├── 0                         // queue 0
    │   └── 00000000000000000000
    ├── 1                         // queue 1
    │   └── 00000000000000000000
    ├── 2                         // queue 2
    │   └── 00000000000000000000
    └── 3                         // queue 3
        └── 00000000000000000000
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;队列元素&#34;&gt;队列元素&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;|&amp;lt;----- 8 byte -----&amp;gt;|&amp;lt;- 4 byte -&amp;gt;|&amp;lt;------ 8 byte ------&amp;gt;|
+--------------------+------------+----------------------+
|   commitlog offset |   size     | message tag hash code|
+--------------------+------------+----------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;执行&#34;&gt;执行&lt;/h3&gt;

&lt;p&gt;通过线程&lt;code&gt;ReputMessageService&lt;/code&gt;的分派消息的逻辑执行。&lt;/p&gt;

&lt;h3 id=&#34;写盘&#34;&gt;写盘&lt;/h3&gt;

&lt;p&gt;系统每隔1000ms（可配置）进行一次消费队列的写盘操作。&lt;/p&gt;

&lt;h4 id=&#34;核心代码-1&#34;&gt;核心代码&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;org.apache.rocketmq.store.DefaultMessageStore.FlushConsumeQueueService
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;清理消息&#34;&gt;清理消息&lt;/h2&gt;

&lt;p&gt;系统每隔10s（可以配置）执行尝试删除过期的消息。&lt;/p&gt;

&lt;h3 id=&#34;清理条件&#34;&gt;清理条件&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;清理时间到达，默认是凌晨4点。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;消息所在的磁盘使用率或者其他数据所在磁盘使用率操作告警阀值和强制删除阀值。&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;保存消息的目录通过配置项 &lt;code&gt;storePathCommitLog&lt;/code&gt; 指定，默认是 &lt;code&gt;$HOME/store/commitlog&lt;/code&gt;。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;保存其他数据的目录通过配置项 &lt;code&gt;storePathRootDir&lt;/code&gt; 指定，默认是 &lt;code&gt;$HOME/store&lt;/code&gt;。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;告警的磁盘使用率阀值通过系统变量 &lt;code&gt;rocketmq.broker.diskSpaceWarningLevelRatio&lt;/code&gt;指定，默认是 0.9。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;强制删除的磁盘使用率阀值通过系统变量 &lt;code&gt;rocketmq.broker.diskSpaceCleanForciblyRatio&lt;/code&gt;指定，默认是 0.75。&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;手动触发清理，这里提供了一个接口暴露给外面调用，调用以后会在连续执行20次删除。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;清理逻辑&#34;&gt;清理逻辑&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;正常清理过期的消息，过期时间可以通过配置项 &lt;code&gt;fileReservedTime&lt;/code&gt; 指定，默认是72小时。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;清理上次没有清理成功的消息，这是因为消息被清理时，其他地方正在使用。每隔一段时间执行一次，同时如果距离上次被清理时间超过了一段时间会被强制清理。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;通过配置项 &lt;code&gt;redeleteHangedFileInterval&lt;/code&gt;指定执行周期，默认120s。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;通过配置项 &lt;code&gt;destroyMapedFileIntervalForcibly&lt;/code&gt;指定强制清理的时间，默认120s。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;核心代码-2&#34;&gt;核心代码&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;org.apache.rocketmq.store.DefaultMessageStore.CleanCommitLogService
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;清理消费队列以及索引&#34;&gt;清理消费队列以及索引&lt;/h2&gt;

&lt;p&gt;随着消息的清理，包含已经清理掉消息的消费队列以及索引就变得没有用处了，所以系统每隔100ms（可以配置）执行清理消费队列和索引。&lt;/p&gt;

&lt;h3 id=&#34;清理逻辑-1&#34;&gt;清理逻辑&lt;/h3&gt;

&lt;p&gt;获取当前消息的最小偏移量，这个偏移量随着消息的清理会不停的变化。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;消费队列：如果队列的最大消息偏移量都比当前最小的消息偏移量小，那么就可以清理本队列。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;消息索引：如果索引中最大的消息偏移量都比当前最小的消息偏移量小，那么就可以清理本索引。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;核心代码-3&#34;&gt;核心代码&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;org.apache.rocketmq.store.DefaultMessageStore.CleanConsumeQueueService
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;消息索引&#34;&gt;消息索引&lt;/h2&gt;

&lt;p&gt;消息索引是方便用户查询消息的一个结构。系统可以通过配置项&lt;code&gt;messageIndexEnable&lt;/code&gt;开关消息索引，默认是打开的。索引允许重复构建，通过配置项&lt;code&gt;duplicationEnable&lt;/code&gt;指定。系统启动的时候，如果允许重复索引会重头构建，不然就从当前文件大小开始。&lt;/p&gt;

&lt;h3 id=&#34;索引内容&#34;&gt;索引内容&lt;/h3&gt;

&lt;p&gt;索引的key包含消息的两个属性：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;KEYS&lt;/code&gt;，支持多个值，每个值之间通过空格分割。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;UNIQ_KEY&lt;/code&gt;。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;索引的内容是消息的偏移量和时间（秒的精度）。&lt;/p&gt;

&lt;h3 id=&#34;结构-1&#34;&gt;结构&lt;/h3&gt;

&lt;h4 id=&#34;目录结构&#34;&gt;目录结构&lt;/h4&gt;

&lt;p&gt;数据保存在目录&lt;code&gt;${rootpath}/index&lt;/code&gt;下面，&lt;code&gt;rootpath&lt;/code&gt; 通过配置项&lt;code&gt;storePathRootDir&lt;/code&gt;指定，默认的是&lt;code&gt;${user.home}/store&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;index/
└── 20171225143756745
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;文件内容&#34;&gt;文件内容&lt;/h4&gt;

&lt;p&gt;每个文件内容分成3部分，header, slot table和index linked list。组织如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;|&amp;lt;-- 40 byte --&amp;gt;|&amp;lt;---   500w   ---&amp;gt;|&amp;lt;---   2000w   ---&amp;gt;|
+---------------+------------------+-------------------+
|    header     |   slot table     | index linked list |
+---------------+------------------+-------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;header&#34;&gt;header&lt;/h5&gt;

&lt;pre&gt;&lt;code&gt;+---------------------+--0
| beginTimestampIndex | ----&amp;gt; 第一条消息的保存时间
+---------------------+--8
| endTimestampIndex   | ----&amp;gt; 最后一条消息的保存时间
+---------------------+--16
| beginPhyoffsetIndex | ----&amp;gt; 第一条消息的在commitlog中的偏移量
+---------------------+--24
| endPhyoffsetIndex   | ----&amp;gt; 最后一条消息的在commitlog中的偏移量
+---------------------+--32
| hashSlotcountIndex  | ----&amp;gt; 哈希槽数量，保存添加到本槽列表的最新索引位置
+---------------------+--36
| indexCountIndex     | ----&amp;gt; 索引数量，具体索引数据
+---------------------+--40
&lt;/code&gt;&lt;/pre&gt;

&lt;h5 id=&#34;slot-table-和-index-linked-list&#34;&gt;slot table 和 index linked list&lt;/h5&gt;

&lt;p&gt;&lt;strong&gt;slot table&lt;/strong&gt;总共有500w个位置，每个位置保存的是在这个slot上的索引列表中最新的那个索引。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;index linked list&lt;/strong&gt;保存每个消息的索引数据&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;   
   -  +-----+ &amp;lt;==== [slot table]
   ^  |  10 |
   |  +-----+
   |  | 200 |
   |  +-----+     +-----------+-------------+  +-----------+-------------+&amp;lt;=[index linked list]
   |  |  18 | --&amp;gt; | index data| next index  |=&amp;gt;| index data| next index  |
 500w +-----+     +-----------+-------------+  +-----------+-------------+
   |  | ... |     /                         \
   |  +-----+    /                           \------------------------------------\
   |  | 90  |    |&amp;lt;--4 byte--&amp;gt;|&amp;lt;--- 8 byte    ---&amp;gt;|&amp;lt;--4 byte--&amp;gt;|&amp;lt;-----4 byte-----&amp;gt;|
   |  +-----+    +------------+-------------------|------------+------------------+ &amp;lt;= [index]
   v  | 100 |    | key hash   | commit log offset | timestamp  | next index offset|
   -  +-----+    +------------+-------------------|------------+------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;执行-1&#34;&gt;执行&lt;/h3&gt;

&lt;p&gt;通过线程&lt;code&gt;ReputMessageService&lt;/code&gt;的分派消息的逻辑执行。&lt;/p&gt;

&lt;h3 id=&#34;核心代码-4&#34;&gt;核心代码&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;org.apache.rocketmq.store.index
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;预分配mappedfile&#34;&gt;预分配MappedFile&lt;/h2&gt;

&lt;p&gt;写消息写到内存映射的文件，每次去新建一个文件同时会做内存映射操作，新建过程当中根据配置会执行比较耗时的预热操作。为了加快这个操作。系统通过一个线程预分配需要的&lt;code&gt;MappedFile&lt;/code&gt;。具体逻辑就是在获取新的文件的时候发送两个请求，分别对应当前的需要的文件以及这个文件写满以后需要的下一个文件，然后等待直到预分配线程分配完当前需要的文件，或者超时。&lt;/p&gt;

&lt;h3 id=&#34;核心代码-5&#34;&gt;核心代码&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;org.apache.rocketmq.store.AllocateMappedFileService
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;消息后续逻辑&#34;&gt;消息后续逻辑&lt;/h2&gt;

&lt;p&gt;当消息写入完成以后，系统有一个线程对消息可以做其他一些逻辑。比如：构建索引，消费队列，通知long pull的客户端请求。线程会维护一个消息索引，根据这个索引跟当前最大已经写入的消息的最大偏移量进行比较得到是否有消息需要处理。&lt;/p&gt;

&lt;p&gt;当系统重启的时候，会根据&lt;code&gt;duplicationEnable&lt;/code&gt;来决定是否从头开始处理消息还是只处理新来的消息。在&lt;code&gt;duplicationEnable&lt;/code&gt;是&lt;code&gt;true&lt;/code&gt;的情况下，还需要设置&lt;code&gt;CommitLog.confirmOffset&lt;/code&gt;才能从头开始处理消息，因为默认情况下系统启动以后&lt;code&gt;CommitLog.confirmOffset&lt;/code&gt;和&lt;code&gt;ReputMessageService.reputFromOffset&lt;/code&gt;是相等的，详见代码&lt;code&gt;ReputMessageService.doReput&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;具体逻辑&#34;&gt;具体逻辑&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;分派消息：构建消费队列，消息索引。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;同时long pull的客户端请求。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;核心代码-6&#34;&gt;核心代码&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;org.apache.rocketmq.store.DefaultMessageStore.ReputMessageService
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ha&#34;&gt;HA&lt;/h2&gt;

&lt;p&gt;RocketMQ的HA是最朴素的一主多从同步，主broker挂了从broker可以读数据，但是不能写，也不会自动主从切换。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://zjykzk.github.io/imgs/rocketmq/ha.png&#34; alt=&#34;ha&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;消息同步逻辑&#34;&gt;消息同步逻辑&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;启动的时候，MASTER会启动监听线程&lt;code&gt;AcceptSocketService&lt;/code&gt;，SLAVE会启动同步线程 &lt;code&gt;HAClient&lt;/code&gt;。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;建立连接&lt;code&gt;HAConnection&lt;/code&gt;之后，MASTER会为连接建立两个线程&lt;code&gt;WriteSocketService&lt;/code&gt;和&lt;code&gt;ReadSocketService&lt;/code&gt;分别负责这条连接的写和读。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;SLAVE向MASTER报告，当前同步的位置，具体是到目前为止同步到的偏移量。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;MASTER根据SLAVE报告的偏移量，发送消息数据。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;WriteSocketService&lt;/strong&gt;线程&lt;/p&gt;

&lt;p&gt;主结点向从结点推送消息线程。线程会记录当前同步的位置确保同步的数据不会重复。当线程启动的时候会等待从结点上报同步进度，如果上报的结果是0，从当前新消息文件中的第一个消息偏移量开始同步（不理解* V *）。消息写完主结点之后，会通知本线程进行写消息。另外，写完消息以后会主动向从结点发送已经同步的位置，像是一个保活机制。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ReadSocketService&lt;/strong&gt;线程&lt;/p&gt;

&lt;p&gt;接收从结点的同步进度。它的任务就是接收从结点同步进度，然后通知等待从结点写完的消息。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;HAClient&lt;/strong&gt;线程&lt;/p&gt;

&lt;p&gt;从结点和主结点同步线程。主要工作&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;和主结点建立同步连接。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;周期性的向主结点发送同步进度。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;接收主结点推送过来的数据，并把数据写入磁盘。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;检查是否有数据同步过来，有的话也会向主结点发送同步进度。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;写buffer的影响&#34;&gt;写buffer的影响&lt;/h4&gt;

&lt;p&gt;当开启写buffer的时候，主从同步的逻辑中使用到的当前消息的最大索引计算逻辑是不一样的。在这种情况下，系统会有一个线程&lt;code&gt;CommitRealTimeService&lt;/code&gt;负责把写buffer中的数据写入文件。只有写入以后数据，才会被同步到从broker。也就是说主从同步的实时性还会受到这个线程的影响。&lt;/p&gt;

&lt;h3 id=&#34;主从同步发送消息过程&#34;&gt;主从同步发送消息过程&lt;/h3&gt;

&lt;p&gt;当我们使用主从同步模式的时候，消息要等到主、从都写完才能返回。在这个过程中，除了主从同步逻辑以外还有消息等待从结点写完成的逻辑。这个逻辑是通过&lt;code&gt;GroupTransferService&lt;/code&gt;完成的。大致流程如下：消息写完主结点后向&lt;code&gt;GroupTransferService&lt;/code&gt;发送等待从结点写完请求，&lt;code&gt;GroupTransferService&lt;/code&gt;只做一件事情，就是不断对比当前从结点同步进度与当前接收到的消息物理偏移量，如果从结点的同步进度大，说明消息已经写入从结点，随即通知消息已经写完。另外，从结点的同步进度是通过&lt;code&gt;ReadSocketService&lt;/code&gt;接收到从结点主动发过来的；当消息写完主结点之后会通知主结点往从结点写消息服务&lt;code&gt;WriteSocketService&lt;/code&gt;。&lt;/p&gt;

&lt;h3 id=&#34;核心代码-7&#34;&gt;核心代码&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;org.apache.rocketmq.store.ha.HAService
org.apache.rocketmq.store.ha.HAConnection
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;定时任务&#34;&gt;定时任务&lt;/h2&gt;

&lt;p&gt;实现了定时调度某个消息的功能。用户通过给消息设置&lt;code&gt;DELAY&lt;/code&gt;属性值来实现。&lt;/p&gt;

&lt;p&gt;系统包含了一个名字为&lt;code&gt;SCHEDULE_TOPIC_XXXX&lt;/code&gt;的topic，当消息指定了&lt;code&gt;DELALY&lt;/code&gt;属性时，消息就会被发送到topic &lt;code&gt;SCHEDULE_TOPIC_XXXX&lt;/code&gt; 中，同时会保存原来的topic、消费队列、以及其他属性值。这些值都作为消息的属性来保存。&lt;/p&gt;

&lt;p&gt;系统通过配置项&lt;code&gt;messageDelayLevel&lt;/code&gt;预定义可以延迟多长时间，同时每个延迟的级别对应着的消费队列。&lt;/p&gt;

&lt;p&gt;系统通过一个定时器，周期性从每个延迟级别对应的消费队列中拿取消息，并检查是否到期，如果到期就会把消息放入到原来的topic和队列中，同时会把先前用于保存原来消息的属性值删除，并设置投递时间。&lt;/p&gt;

&lt;h3 id=&#34;核心代码-8&#34;&gt;核心代码&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;org.apache.rocketmq.store.schedule.ScheduleMessageService
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;统计&#34;&gt;统计&lt;/h2&gt;

&lt;p&gt;消息的统计。包含：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;发送消息的总数&lt;code&gt;putMessageTimesTotal&lt;/code&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;发送消息时，不同响应时间级别的消息数量&lt;code&gt;putMessageDistributeTime&lt;/code&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;发送消息请求的最长响应时间&lt;code&gt;putMessageEntireTimeMax&lt;/code&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;发送消息的总大小&lt;code&gt;putMessageSizeTotal&lt;/code&gt;、平均大小&lt;code&gt;putMessageAverageSize&lt;/code&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;发消息的TPS&lt;code&gt;putTps&lt;/code&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;拉取消息请求的最长响应时间&lt;code&gt;getMessageEntireTimeMax&lt;/code&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;拉取消息请求命中TPS&lt;code&gt;getFoundTps&lt;/code&gt;、没有命中TPS &lt;code&gt;getMissTps&lt;/code&gt;以及总的请求TPS&lt;code&gt;getTotalTps&lt;/code&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;拉取消息的TPS，拉取消息请求，并返回消息的TPS &lt;code&gt;getTransferedTps&lt;/code&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;核心代码-9&#34;&gt;核心代码&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;org.apache.rocketmq.store.StoreStatsService
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;写buffer-1&#34;&gt;写buffer&lt;/h2&gt;

&lt;p&gt;如果开启了这个功能，系统启动时会向系统申请多块写buffer。每块buffer都会被锁在内存中。这个buffer只会被commitlog使用,写消息的时候写到这些buffer。&lt;/p&gt;

&lt;h3 id=&#34;核心代码-10&#34;&gt;核心代码&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;org.apache.rocketmq.store.TransientStorePool
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;内存映射的文件管理&#34;&gt;内存映射的文件管理&lt;/h2&gt;

&lt;p&gt;rocketmq中的索引、消费队列、消息这些数据都通过内存映射进行读写。&lt;/p&gt;

&lt;h3 id=&#34;映射文件&#34;&gt;映射文件&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;逻辑文件：数据按照顺序写入，由类&lt;code&gt;org.apache.rocketmq.store.MappedFileQueue&lt;/code&gt; 表示&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;物理文件：具体写数据的文件，由类&lt;code&gt;org.apache.rocketmq.store.MappedFile&lt;/code&gt; 表示&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;它们之间的关系：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;|&amp;lt;-                                  MappedFileQueue                                        -&amp;gt;|
+-------------------+--------------------+-------------+-------------------+------------------+
|000000000000000000 | 000000000000000100 |   ...       |000000000000010000 |000000000000020000|
+-------------------+--------------------+-------------+-------------------+------------------+
|&amp;lt;- MappedFile-0  -&amp;gt;|&amp;lt;-  MappedFile-1  -&amp;gt;|   ...       |&amp;lt;- MappedFile-n-1-&amp;gt;|&amp;lt;- MappedFile-n -&amp;gt;|
+-------------------+--------------------+-------------+-------------------+------------------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;一个 &lt;code&gt;MappedFileQueue&lt;/code&gt; 由多个 &lt;code&gt;MappedFile&lt;/code&gt; 组成，每个 &lt;code&gt;MappedFile&lt;/code&gt; 文件大小相等，文件名是32个字符，并且表示当前文件中第一个记录在 &lt;code&gt;MappedFileQueue&lt;/code&gt;所代表的逻辑文件中的序号。&lt;/p&gt;

&lt;h3 id=&#34;引用计数&#34;&gt;引用计数&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;MappedFile&lt;/code&gt;在一个多线程环境里面，在使用的时候有可能已经被执行了删除操作，通过引用计数的方式进行安全管理&lt;code&gt;MappedFile&lt;/code&gt;的生命周期。&lt;/p&gt;

&lt;h3 id=&#34;优化&#34;&gt;优化&lt;/h3&gt;

&lt;h4 id=&#34;预热&#34;&gt;预热&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;新建&lt;code&gt;MappedFile&lt;/code&gt;时通过先把文件映射的内存都写一遍，内核为文件分配物理页。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;mlock&lt;/code&gt;锁住文件映射的物理内存，确保这部分内存不被交换出去。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;madvise&lt;/code&gt;通知内核这部分数据将来会读到。&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&#34;写buffer-2&#34;&gt;写buffer&lt;/h4&gt;

&lt;p&gt;建立一个buffer池，这些buffer是堆外内存。buffer所占用的内存是不会被交换出去的，同时也会通知内核这部分数据将来会读到。&lt;code&gt;MappedFile&lt;/code&gt;新建的时候可以通过这个池子获得buffer作为写的buffer。&lt;/p&gt;

&lt;h3 id=&#34;核心代码-11&#34;&gt;核心代码&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;org.apache.rocketmq.store.MappedFileQueue
org.apache.rocketmq.store.MappedFile
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;备注&#34;&gt;备注&lt;/h2&gt;

&lt;h3 id=&#34;代码版本&#34;&gt;代码版本&lt;/h3&gt;

&lt;p&gt;4.1.0&lt;/p&gt;

&lt;h3 id=&#34;参考文档&#34;&gt;参考文档&lt;/h3&gt;

&lt;p&gt;RocketMQ design&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>记一次mongo数据库优化经历</title>
      <link>http://zjykzk.github.io/post/cs/first-optimal/</link>
      <pubDate>Tue, 24 Oct 2017 18:46:11 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/first-optimal/</guid>
      <description>

&lt;h1 id=&#34;缘起&#34;&gt;缘起&lt;/h1&gt;

&lt;p&gt;最近，做一个项目：封装一个MQ，提供发送、拉取、查询的基本功能，需要保证一条消息只被消费一次。写完了基本功能以后，开始做benchmark。结果超级糟糕：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;发送线程数量&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;消费线程数量&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;发送TPS&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;消费TPS&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;200-400&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;20-60&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;而且，随着消费线程的数量增加发送&amp;amp;消费的TPS都下降。&lt;/p&gt;

&lt;h1 id=&#34;排查&#34;&gt;排查&lt;/h1&gt;

&lt;h2 id=&#34;接口&#34;&gt;接口&lt;/h2&gt;

&lt;p&gt;一次发送涉及的数据库操作：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;一次topic查询&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;一次跟MQ之间的RPC&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;一次写统计数据&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;一次消费涉及的数据库操作：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;两次cas操作&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;两次写统计操作&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;系统状态&#34;&gt;系统状态&lt;/h2&gt;

&lt;h3 id=&#34;磁盘io&#34;&gt;磁盘IO&lt;/h3&gt;

&lt;p&gt;通过命令 &lt;code&gt;iotop&lt;/code&gt; 发现：mongodb写磁盘速度最大2M/s。&lt;/p&gt;

&lt;h3 id=&#34;网络&#34;&gt;网络&lt;/h3&gt;

&lt;p&gt;通过命令 &lt;code&gt;nethogs&lt;/code&gt; 发现：mongodb的通信速度最大200+KB/s。&lt;/p&gt;

&lt;h3 id=&#34;系统总体情况&#34;&gt;系统总体情况&lt;/h3&gt;

&lt;p&gt;通过命令&lt;code&gt;vmstat&lt;/code&gt;发现：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;系统和用户的CPU使用率都超低，两者加起来不到5%，系统的中断和上下文切换非常高，特别是上下文切换，达到了十几万/s&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;从缓存写到磁盘的io比较高好几百/s&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;内存使用率非常低&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;结论&#34;&gt;结论&lt;/h3&gt;

&lt;p&gt;问题一定是使用mongodb上面。&lt;/p&gt;

&lt;h2 id=&#34;排查-1&#34;&gt;排查&lt;/h2&gt;

&lt;h3 id=&#34;profile程序&#34;&gt;profile程序&lt;/h3&gt;

&lt;p&gt;通过golang自带的profile功能，在程序里面添加profile代码，通过&lt;code&gt;go tool pprof&lt;/code&gt;对程序做profile，用 &lt;code&gt;go-torch&lt;/code&gt;生成火焰图。发现果不其然，一个请求过程中，数据操作耗时占整体的40%以上。&lt;/p&gt;

&lt;p&gt;发送消息火焰图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://zjykzk.github.io/imgs/create.job.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;拉取消息火焰图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://zjykzk.github.io/imgs/pull.job.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;确认消息火焰图&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://zjykzk.github.io/imgs/finish.job.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通过看程序以及对需求的分析，程序可以做优化：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;统计数据可以不用每次都去写数据库，把它放在内存或者写本地磁盘，定期刷到数据库&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;去重以后的消息，可以放在内存，减少拉取消息时候一次cas操作&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;mongodb&#34;&gt;mongodb&lt;/h3&gt;

&lt;p&gt;通过命令 &lt;code&gt;mongostat&lt;/code&gt; 查看mongodb的运行状态，发现随着消费线程并发的提高锁的百分比越来越高最后超过的90%。查看mongodb的版本是2.4.9，它用的数据库锁。换个mongodb版本，避免锁的开销，通过了解公司线上使用的版本3.0.15，并使用wireTiger存储引擎。果断按照这个环境进行benchmark，结果仍然不尽任意。查看&lt;strong&gt;profiler&lt;/strong&gt;，一个类似mysql的慢查询的命令。通过以下命令加上专家的讲解，从&lt;strong&gt;信息 nscannedObjects : 71040&lt;/strong&gt;，发现扫描对象比较多，从代码确认是缺少了一个索引。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; db.setProfilingLevel(2);
{&amp;quot;was&amp;quot; : 0 , &amp;quot;slowms&amp;quot; : 100, &amp;quot;ok&amp;quot; : 1}       // &amp;quot;was&amp;quot; 表示旧的设置
&amp;gt; db.system.profile.find().sort({millis:-1}) // 列出耗时的操作，按照操作耗时排序，这条语句会列出扫描的对象数量，锁等关键信息
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在程序里面加上索引，再次benchmark达到预期。&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;本次调优最大问题是思维盲区，由于自己对mongodb不熟悉，就没有想到去profile mongodb，把精力放在了优化代码层面的数据库操作，中间还做过把消息放在缓存中虽然达到预期，但是有数据不一致的问题。其实，方法没对，&lt;strong&gt;优化的首要原则是做profile，profile一切。&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>map 内部实现</title>
      <link>http://zjykzk.github.io/post/cs/golang/map/</link>
      <pubDate>Thu, 15 Jun 2017 19:13:25 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/golang/map/</guid>
      <description>

&lt;h1 id=&#34;类型&#34;&gt;类型&lt;/h1&gt;

&lt;p&gt;golang中的map是一个 &lt;strong&gt;指针&lt;/strong&gt;。当执行语句 &lt;code&gt;make(map[string]string)&lt;/code&gt; 的时候，其实是调用了 &lt;code&gt;makemap&lt;/code&gt; 函数：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// file: runtime/hashmap.go:L222
func makemap(t *maptype, hint64, h *hmap, bucket unsafe.Pointer) *hmap
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;显然，&lt;code&gt;makemap&lt;/code&gt; 返回的是指针。&lt;/p&gt;

&lt;h1 id=&#34;数据结构&#34;&gt;数据结构&lt;/h1&gt;

&lt;h2 id=&#34;hashmap&#34;&gt;hashmap&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// hash map
type hmap struct {
    // 元素的个数 == len()返回的值，必须放在第一个位置因为 len函数需要使用
    count     int

    // map标记:
    // 1. key和value是否包指针
    // 2. 是否正在扩容
    // 3. 是否是同样大小的扩容
    // 4. 是否正在 `range`方式访问当前的buckets
    // 5. 是否有 `range`方式访问旧的bucket
    flags     uint8
    B         uint8  // log_2(B) == bucket数量
    noverflow uint16 // overflow bucket的数量，是个近似值
    hash0     uint32 // hash种子

    buckets    unsafe.Pointer // bucket slice指针，如果count == 0，这里的值为 nil
    oldbuckets unsafe.Pointer // bucket slice指针，仅当在扩容的时候不为nil
    nevacuate  uintptr        // 扩容时已经移到新的map中的bucket数量

    // 当key和value的类型不包含指针的时候，key和value就会做inline处理(怎么处理的)
    // 保证overflow的bucket活着，不被gc回收
    overflow *[2]*[]*bmap
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bucket&#34;&gt;bucket&lt;/h2&gt;

&lt;p&gt;每个bucket固定包含8个key和value。实现上面是一个固定的大小连续内存块，分成四部分：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;每个条目的状态&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;8个key值&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;8个value值&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;指向下个bucket的指针&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;数据结构定义如下：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// bucket
type bmap struct {
        // 每个条目的状态，tophash[0]表示当前bucket中的条目是否已经完全移到新的bucket中去了
        tophash [bucketCnt]uint8
        // keys
        // values
        // Followed by an overflow pointer.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;条目状态&#34;&gt;条目状态&lt;/h3&gt;

&lt;p&gt;. &lt;code&gt;0&lt;/code&gt; 空，可以被使用&lt;/p&gt;

&lt;p&gt;. &lt;code&gt;1&lt;/code&gt; 空，bucket中的内容已经被移到了新的bucket中&lt;/p&gt;

&lt;p&gt;. &lt;code&gt;2&lt;/code&gt; 该条目已经被移到了新的bucket，该bucket的位置在处在前半部分&lt;/p&gt;

&lt;p&gt;. &lt;code&gt;3&lt;/code&gt; 该条目已经被移到了新的bucket，该bucket的位置在处在后半部分&lt;/p&gt;

&lt;p&gt;. 其他大于等于&lt;code&gt;4&lt;/code&gt; 的值，来自key的hash值的最高8位，如果高8位值小于4，则加4&lt;/p&gt;

&lt;h4 id=&#34;第一个条目状态&#34;&gt;第一个条目状态&lt;/h4&gt;

&lt;p&gt;bucket的第一个条目&lt;code&gt;tophash[0]&lt;/code&gt; 用来标识bucket中的条目是否已经全部被移到了新的bucket中去了， &lt;code&gt;1-3&lt;/code&gt; 表示已经移动完。&lt;/p&gt;

&lt;h3 id=&#34;内存布局&#34;&gt;内存布局&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;   ----+-----------------+ -.
   ^   |     bucket0     |  |------&amp;gt; +------------+
   |   +-----------------+ -&#39;        | tophash0-7 |
2^h.B  |     .......     |           +------------+
   |   +-----------------+           |   key0-7   |
   v   | bucket2^h.B - 1 |           +------------+
   ----+-----------------+           |  value0-7  |
                                     +------------+ -.
                                     |overflow_ptr|  |-----&amp;gt; new bucket address
                                     +------------+ -&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;选择这样的布局的好处：由于对齐的原因，&lt;em&gt;key0/value0/key1/value1&amp;hellip;&lt;/em&gt; 这样的形式可能需要更多的补齐空间，比如 &lt;code&gt;map[int64]int8&lt;/code&gt; ，1字节的value后面需要补齐7个字节才能保证下一个key是 &lt;code&gt;int64&lt;/code&gt; 对齐的。&lt;/p&gt;

&lt;h2 id=&#34;装载因子&#34;&gt;装载因子&lt;/h2&gt;

&lt;p&gt;装载因子决定map的资源使用率以及性能高低，在实现map时，考虑四个方面：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;%overflow：拥有overflow的bucket的百分比&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;bytes/entry: 每个key/value的额外开销&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;hitprobe: 查找存在的key时需要检查的条目数量&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;missprobe: 查找不存在的key是需要检查的条目数量&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;其测试数据如下：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;装载因子&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;%overflow&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;bytes/entry&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;hitprobe&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;missprobe&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;6.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;20.90&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10.79&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4.25&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;hash函数&#34;&gt;hash函数&lt;/h1&gt;

&lt;p&gt;map中的key对应着一个hash函数，用于定位bucket。在golang的hash函数是固定的，用户无法修改。golang中的预定义基本类型，像 &lt;code&gt;int32/int64/string/interface&lt;/code&gt; 等等都有一个hash函数与之对应，代码在runtime/alg.go中。对于struct/数组/slice，如果它每个字段或者元素都是有hash函数，那么该类型就有hash函数，hash值由每个字段的hash值来定义，代码在reflect/type.go函数&lt;code&gt;StructOf&lt;/code&gt;中。&lt;/p&gt;

&lt;p&gt;注：&lt;code&gt;map&lt;/code&gt;是不能作为key的。&lt;/p&gt;

&lt;h1 id=&#34;扩容&#34;&gt;扩容&lt;/h1&gt;

&lt;p&gt;当进行添加元素的操作时，如果超过装载因子，或者overflow的bucket数量超出阈值，就会触发扩容的操作。如果是因为overflow的bucket数量过多引起的，map的容量不会扩大，不然就扩大为原来的大小的两倍。&lt;/p&gt;

&lt;p&gt;在实现扩容的时候，会先为需要的bucket分配新内存，然后把旧的bucket保存起来，再把旧的内容移到新的bucket中去。&lt;/p&gt;

&lt;h1 id=&#34;线程安全&#34;&gt;线程安全&lt;/h1&gt;

&lt;p&gt;map是线程不安全的。但是在实现中有很多关于并发访问的代码，比如&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;在迭代的时候会做是否正在扩容&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;添加数据的时候是否有其他数据正在写，有的话会panic&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;既然不是线程安全，为啥要做这样的检查，不检查的话可以简化代码提高性能。检查的好处就是告知提醒用户并发访问了map，但是这个检查也不是百分之一百的检测到所有的并发访问。&lt;/p&gt;

&lt;h1 id=&#34;键值nan&#34;&gt;键值NaN&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;NaN&lt;/code&gt; 的hash值是随机(&lt;a href=&#34;https://research.swtch.com/randhash&#34;&gt;原因&lt;/a&gt;)，也就是说每次计算hash值都有可能是不一样的。这个跟python/java等其他语言有比较大的差别。&lt;/p&gt;

&lt;p&gt;正是因为这样有了以下几个有趣的事情：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;当 &lt;code&gt;NaN&lt;/code&gt; 作为key的时候，为了保持hash值的不变性，利用 &lt;code&gt;tophash&lt;/code&gt; 的最低位来判断是放在扩容以后bucket的上半部份还是下半部分&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;用 &lt;code&gt;NaN&lt;/code&gt; 做key取数据时永远也取不到，用 &lt;code&gt;for&lt;/code&gt; 迭代map是唯一一种访问 key为&lt;code&gt;NaN&lt;/code&gt; 的内容的方式&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;迭代&#34;&gt;迭代&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;for&lt;/code&gt; 语句迭代map，在会调用函数 &lt;code&gt;mapiterinit&lt;/code&gt; 做初始化工作：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;随机挑选一个起始位置开始迭代：a. bucket随机选一个，b. bucket中的起始条目也是随机的&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;初始化overflow，目的是为了防止那些内联的数据被gc，导致迭代失败&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;每次获取一个元素的时候调用函数&lt;code&gt;mapiternext&lt;/code&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>补码</title>
      <link>http://zjykzk.github.io/post/cs/complement/</link>
      <pubDate>Tue, 30 May 2017 23:18:02 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/complement/</guid>
      <description>

&lt;h2 id=&#34;加法&#34;&gt;加法&lt;/h2&gt;

&lt;p&gt;2个十进制数字的非正式算法：两个数字中相同位置的数相加，如果结果超过10产生进位，该进位在下一位数相加时加上。直到两个数字的所有位数都加完为止。&lt;/p&gt;

&lt;p&gt;考虑十进制的2位数加法，例如：16 + 26。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    1 6
  + 2 6
 -------
    4 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上例中的加法过程是：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;6+6&lt;/code&gt; 得2，产生进位&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;1 + 2 + 1&lt;/code&gt; 的4，其中最后加1是&lt;code&gt;1&lt;/code&gt;步骤的几位，最终结果是 &lt;code&gt;42&lt;/code&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;减法&#34;&gt;减法&lt;/h2&gt;

&lt;p&gt;2个10进制数字的非正式算法：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;如果被减数大于等于减数，两个数字中相同位置的数相减，如果被减数小于减数，从高位借一位，轮到高位计算时要多减去一个1。直到两个数字的所有位都减完为止。&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;如果被减数小于减数，交互减数与被减数的位置进行 &lt;code&gt;1&lt;/code&gt; 操作，把结果加一个负号&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;考虑十进制的2位数减法，例如：16 - 25。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    1 6
  + 2 5
 -------
    - 9
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;上例中的加法过程是：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;16&lt;/code&gt; 比&lt;code&gt;25&lt;/code&gt;小，交换两个数的位置&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;5&lt;/code&gt;比 &lt;code&gt;6&lt;/code&gt; 小产生借位， &lt;code&gt;15-6&lt;/code&gt; 得到 &lt;code&gt;9&lt;/code&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;2-1-1&lt;/code&gt; 得到0，最后一个 &lt;code&gt;1&lt;/code&gt;是借位&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;加上负号，最终的结果是 &lt;code&gt;-9&lt;/code&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;补码&#34;&gt;补码&lt;/h2&gt;

&lt;p&gt;加法需要记录进位，而减法需要记录借位，比较大小，记录符号。这样减法的复杂度就要比较加法高。&lt;/p&gt;

&lt;h3 id=&#34;减法变加法&#34;&gt;减法变加法&lt;/h3&gt;

&lt;p&gt;注意到&lt;code&gt;16-25=16+(-25)&lt;/code&gt;，如果&lt;code&gt;-25&lt;/code&gt;能够表示成一个正数，那么减法就变成了加法。&lt;/p&gt;

&lt;p&gt;2位10进制的整数范围0-99，取一半用来做正数和零，一半做负数，分布如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;0 - 0
1 - 1
...
49 - 49
50 - -50
51 - -49
...
99 - -1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;按照这个分布，&lt;code&gt;-25&lt;/code&gt;对应着&lt;code&gt;75&lt;/code&gt;，从而得到&lt;code&gt;16-25=16+75=91&lt;/code&gt;，再根据上面的正负数的分布&lt;code&gt;91&lt;/code&gt;就是&lt;code&gt;-9&lt;/code&gt;，完全与&lt;code&gt;16-25=-9&lt;/code&gt;吻合。&lt;/p&gt;

&lt;p&gt;另外，如果两个数和超过100，只需要减去100就是对应的结果。&lt;/p&gt;

&lt;p&gt;这种用正数表示负数的编码方式叫做补码。由于每个负数正好是100减去表示这个负数的正数，所以叫10的补码。而在二进制情况下，就叫2的补码。因为，二进制下10表示十进制的2.&lt;/p&gt;

&lt;h3 id=&#34;二进制版本&#34;&gt;二进制版本&lt;/h3&gt;

&lt;p&gt;一个6位数的二进制版本，正负数编码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;000000 - 000000
000001 - 000001
...
011111 - 011111
100000 - -100000
...
111111 - -000001
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;16&lt;/code&gt;的二进制&lt;code&gt;010000&lt;/code&gt;，&lt;code&gt;-25&lt;/code&gt;的二进制&lt;code&gt;100110&lt;/code&gt;，&lt;code&gt;16-15=&amp;gt;010000+100110=110110=&amp;gt;-9&lt;/code&gt;。注意到&lt;code&gt;25&lt;/code&gt;的二进制是&lt;code&gt;011001&lt;/code&gt;，而&lt;code&gt;-25&lt;/code&gt;的二进制&lt;code&gt;100110=1000000-011011=111111-011001+000001&lt;/code&gt;，恰好是对&lt;code&gt;011001&lt;/code&gt;取反加1。&lt;/p&gt;

&lt;p&gt;同时，二进制转化成十进制：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;111111 = -(1000000 - 111111)
       = -(2^6 - 2^5 - 2^4 - 2^3 - 2^2 - 2^1 - 2^0)
       = -(2^5 - 2^4 - 2^3 - 2^2 - 2^1 - 2^0)
       = -2^5 + 2^4 + 2^3 + 2^2 + 2^1 + 2^0
011111 = 2^4 + 2^3 + 2^2 + 2^1 + 2^0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最高位的转化取负数，其他会取正数，然后求和正好是十进制的数。&lt;/p&gt;

&lt;p&gt;这个结果对计算机来说非常有价值，因为计算机组件有一些逻辑门构成，而逻辑门只能处理真假两个值，这正好可以用01来表示，取反，加1都能很方便的用逻辑门来实现，达到了加法和减法统一，简化逻辑电路的设计。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GO 内存模型</title>
      <link>http://zjykzk.github.io/post/cs/golang/go-memory-model/</link>
      <pubDate>Tue, 28 Mar 2017 11:22:09 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/golang/go-memory-model/</guid>
      <description>

&lt;p&gt;内存模型定义了一系列的条件，在这些条件下，多个goroutine对一个变量进行读写，保证一个goroutine读取到的值是是另外一个goroutine写入的某个值。&lt;/p&gt;

&lt;h2 id=&#34;happens-before&#34;&gt;Happens Before&lt;/h2&gt;

&lt;p&gt;编译器会对程序做优化，比如指令重排。在go语言中规定，在同一个goroutine里面，程序表达的顺序就是读写的顺序。但是，多个goroutine执行同样的代码时，就会出现读写顺序不一样的情况。例如，代码：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;int a = 0;
int b = 1;
print(a);
print(b);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在编译器的优化下，代码的执行顺序有可能变成下面这样的情况：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;int a = 0;
print(a);
int b = 1;
print(b);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但是，多个goroutine执行时，就无法保证打印*a*的时候，*b*的值一定是1.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;happens before&lt;/strong&gt;定义了内存操作的顺序，它是一种偏序。&lt;em&gt;e1&lt;/em&gt; happens before &lt;em&gt;e2&lt;/em&gt;, &lt;em&gt;e2&lt;/em&gt; happens after &lt;em&gt;e1&lt;/em&gt; 。如果 &lt;em&gt;e1&lt;/em&gt; 既不happens before &lt;em&gt;e2&lt;/em&gt; 也不happens after &lt;em&gt;e2&lt;/em&gt; ，那么 &lt;em&gt;e1&lt;/em&gt; 和 &lt;em&gt;e2&lt;/em&gt; 是并发执行的。它有传递的性质（自反性，对称性就不考虑了）。这个关系就决定了共享变量在某个上下文下面读写顺序，那么它的具体值变化也就确定了。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;在一个goroutine中，happens before的顺序就是代码表达的顺序。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;共享变量 &lt;em&gt;v&lt;/em&gt; 的读操作 &lt;em&gt;r&lt;/em&gt; ，能够读到是另一个对变量 &lt;em&gt;v&lt;/em&gt; 写操作 &lt;em&gt;w&lt;/em&gt; 写入的值的条件是：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;em&gt;w&lt;/em&gt; happens before &lt;em&gt;r&lt;/em&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;没有其他的对变量 &lt;em&gt;v&lt;/em&gt; 写操作happens before &lt;em&gt;r&lt;/em&gt; 并且happens after &lt;em&gt;w&lt;/em&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这两个条件并不能保证有一个与 &lt;em&gt;r&amp;amp;w&lt;/em&gt; 没有任何happens before关系的对共享变量 &lt;em&gt;v&lt;/em&gt; 写操作 &lt;em&gt;w&amp;rsquo;&lt;/em&gt; 的存在，导致 &lt;em&gt;r&lt;/em&gt; 读到的是 &lt;em&gt;w&amp;rsquo;&lt;/em&gt; 的结果。所以，保证 &lt;em&gt;r&lt;/em&gt; 的结果是 &lt;em&gt;w&lt;/em&gt; 的值的条件是：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;em&gt;w&lt;/em&gt; happens before &lt;em&gt;r&lt;/em&gt;&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;在 &lt;em&gt;w&lt;/em&gt; 和 &lt;em&gt;r&lt;/em&gt; 之间没有任何写操作，也就是说其他的写操作要么happens before &lt;em&gt;w&lt;/em&gt; ，要么happens after &lt;em&gt;r&lt;/em&gt;&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在只有一个goroutine中1和2是等价的。 &lt;em&gt;r&lt;/em&gt; 的结果一定是最近一次 &lt;em&gt;w&lt;/em&gt; 的结果。&lt;strong&gt;如果多个goroutine访问共享变量，就会产生竞争，必须要通过同步机制建立happens before关系才能确定共享变量的值&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;另外，1) 变量自动的初始化为其类型对应的0时，相当于是一个写操作，也会产生竞争；2) 对多个机器字进行读写的时候，哪个字先读写是不确定的。&lt;/p&gt;

&lt;h2 id=&#34;同步机制&#34;&gt;同步机制&lt;/h2&gt;

&lt;h3 id=&#34;初始化&#34;&gt;初始化&lt;/h3&gt;

&lt;p&gt;程序的初始化是通过一个goroutine执行的，这个goroutine会生成一个新的goroutine，因此会有竞争存在。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;包 &lt;em&gt;p&lt;/em&gt; 依赖 *q*，&lt;em&gt;q&lt;/em&gt; 的 &lt;em&gt;init&lt;/em&gt; 函数happens before包 &lt;em&gt;p&lt;/em&gt; 的任何操作&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;所有 &lt;em&gt;init&lt;/em&gt; 函数执行结束happens before &lt;em&gt;main.main&lt;/em&gt; 函数&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;goroutine-创建&#34;&gt;Goroutine 创建&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;go&lt;/em&gt; 语句happens before新创建的goroutine的运行。以下代码中，&lt;strong&gt;&lt;em&gt;1&lt;/em&gt;&lt;/strong&gt; happens before &lt;strong&gt;&lt;em&gt;2&lt;/em&gt;&lt;/strong&gt;，&lt;strong&gt;&lt;em&gt;2&lt;/em&gt;&lt;/strong&gt; happens before 函数&lt;strong&gt;&lt;em&gt;f&lt;/em&gt;&lt;/strong&gt;的执行，在将来的某个时刻所以打印 &lt;code&gt;hello, world&lt;/code&gt;（可能是在hello函数返回之后）。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var a string

func f() {
	print(a)
}

func hello() {
	a = &amp;quot;hello, world&amp;quot; // 1
	go f()             // 2
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;goroutine-销毁&#34;&gt;Goroutine 销毁&lt;/h3&gt;

&lt;p&gt;goroutine的退出跟其他的操作没有任何的happens before操作。以下代码无法保证&lt;strong&gt;&lt;em&gt;print(a)&lt;/em&gt;&lt;/strong&gt;的结果就是 &lt;code&gt;hello, world&lt;/code&gt;。事实上，编译器完全有可能把 &lt;em&gt;go&lt;/em&gt; 语句完全的删除掉。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var a string

func hello() {
	go func() { a = &amp;quot;hello&amp;quot; }()
	print(a)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;channel通信&#34;&gt;Channel通信&lt;/h3&gt;

&lt;p&gt;channel在golang里面是同步的一个重要手段。channel上面的每个发送操作，都唯一对应着一个channel上面的接受操作，显然发送／接受操作在不同的goroutine下面才需要讨论。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在一个channel上面的发送操作的完成happens before想对应的接受操作的完成。&lt;/strong&gt;以下代码中，按照本规则 &lt;em&gt;1&lt;/em&gt; happens before &lt;em&gt;2&lt;/em&gt; ，另外，因为 &lt;em&gt;2&lt;/em&gt; 和 &lt;em&gt;3&lt;/em&gt; 在同一个goroutine中执行， &lt;em&gt;2&lt;/em&gt; happens before &lt;em&gt;3&lt;/em&gt; ，所以能够打印出 &lt;code&gt;hello, world&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var c = make(chan int, 10)
var a string

func f() {
	a = &amp;quot;hello, world&amp;quot;
	c &amp;lt;- 0       // 1
}

func main() {
	go f()
	&amp;lt;-c          // 2
	print(a)     // 3
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;channel的关闭操作happens before因为关闭channel读到的0值。&lt;/strong&gt;上面例子中，用 &lt;em&gt;close( c)&lt;/em&gt; 代替 &lt;em&gt;ch &amp;lt;- 0&lt;/em&gt; 同样能够保证 &lt;em&gt;1&lt;/em&gt;  happens before &lt;em&gt;2&lt;/em&gt;  。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;没有缓冲的channel上面的接受操作happens before发送操作。也就是说，发送操作只有在channel上面进行的接受操作结束以后才返回。&lt;/strong&gt;以下代码中，根据本规则 &lt;em&gt;1&lt;/em&gt; happens before &lt;em&gt;2&lt;/em&gt; 。另外，因为 &lt;em&gt;2&lt;/em&gt; 和 &lt;em&gt;3&lt;/em&gt; 在同一个goroutine中执行， &lt;em&gt;2&lt;/em&gt; happens before &lt;em&gt;3&lt;/em&gt; ，所以能够打印出 &lt;code&gt;hello, world&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var c = make(chan int)
var a string

func f() {
	a = &amp;quot;hello, world&amp;quot;
	&amp;lt;-c	                 // 1
}

func main() {
	go f()
	c &amp;lt;- 0               // 2
	print(a)             // 3
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;如果一个channel有 &lt;em&gt;C&lt;/em&gt; 容量的缓冲，第 &lt;em&gt;k&lt;/em&gt; 个接受操作happens before第 &lt;em&gt;k+C&lt;/em&gt; 个发送操作。&lt;/strong&gt;根据这个规则可以用带缓冲的channel来模拟信号量。以下程序就保证了，同时最多只有3个goroutine同时执行 &lt;em&gt;w&lt;/em&gt; 函数。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var limit = make(chan int, 3)

func main() {
	for _, w := range work {
		go func(w func()) {
			limit &amp;lt;- 1
			w()
			&amp;lt;-limit
		}(w)
	}
	select{}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;locks&#34;&gt;Locks&lt;/h3&gt;

&lt;p&gt;包 &lt;em&gt;sync&lt;/em&gt; 实现了两类锁分别是： &lt;em&gt;sync.Mutex&lt;/em&gt; 和 &lt;em&gt;sync.RWMutex。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;给定类型为 &lt;em&gt;sync.Mutex&lt;/em&gt; 或者是 &lt;em&gt;sync.RWMutex&lt;/em&gt; 的变量 &lt;em&gt;l&lt;/em&gt; ,以及满足 &lt;em&gt;n&amp;lt;m&lt;/em&gt; 条件的整数。调用 &lt;em&gt;n&lt;/em&gt; 次 &lt;em&gt;l.Unlock()&lt;/em&gt;  happens before 调用 &lt;em&gt;m&lt;/em&gt; 次 &lt;em&gt;l.Lock()&lt;/em&gt; （返回）。&lt;/strong&gt;以下代码中，根据本规则 &lt;em&gt;1&lt;/em&gt; happens before &lt;em&gt;2&lt;/em&gt; ，另外，因为 &lt;em&gt;2&lt;/em&gt; 和 &lt;em&gt;3&lt;/em&gt; 在同一个goroutine中执行， &lt;em&gt;2&lt;/em&gt; happens before &lt;em&gt;3&lt;/em&gt; ，所以能够打印出 &lt;code&gt;hello, world&lt;/code&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;var l sync.Mutex
var a string

func f() {
	a = &amp;quot;hello, world&amp;quot;
	l.Unlock()       // 1
}

func main() {
	l.Lock()
	go f()
	l.Lock()         // 2
	print(a)         // 3
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;对于 &lt;em&gt;sync.RWMutex&lt;/em&gt; 类型的变量l，存在一个整数 &lt;em&gt;n&lt;/em&gt; ， &lt;em&gt;l.RLock&lt;/em&gt; 的调用happens after(返回)调用 &lt;em&gt;n&lt;/em&gt; 次 &lt;em&gt;l.Unlock&lt;/em&gt; ，与这个 &lt;em&gt;l.RLock&lt;/em&gt; 想对应的 &lt;em&gt;l.RUnlock&lt;/em&gt; happens before 第 &lt;em&gt;n+1&lt;/em&gt; 的 &lt;em&gt;l.Lock&lt;/em&gt; 。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;once&#34;&gt;Once&lt;/h3&gt;

&lt;p&gt;Once提供了保证某段代码只执行一次的机制。对某个函数 &lt;em&gt;f&lt;/em&gt; ， &lt;em&gt;once.Do(f)&lt;/em&gt; 调用保证了 &lt;em&gt;f&lt;/em&gt; 只被执行一次，如果有多个goroutine执行 &lt;em&gt;once.Do(f)&lt;/em&gt; ，其中一个执行了，其他就等待直到f执行完毕。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;调用 &lt;em&gt;once.Do(f)&lt;/em&gt; 中 &lt;em&gt;f&lt;/em&gt; (返回)happens before 其他 &lt;em&gt;once.Do(f)&lt;/em&gt; 调用完成。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;为了更有效率的执行程序，编译器，CPU都会一某种方式进行优化。当程序是并发执行的时候，内存的数据就变得无法根据程序代码判断内存中的值。内存模型的作用就是在程序的层面规定内存的操作顺序，以达到确定内存值的目的。而happens before是一个定义这个操作顺序的规范。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>字符串</title>
      <link>http://zjykzk.github.io/post/cs/str/</link>
      <pubDate>Thu, 19 Jan 2017 14:05:14 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/str/</guid>
      <description>

&lt;h1 id=&#34;为什么要字符&#34;&gt;为什么要字符&lt;/h1&gt;

&lt;p&gt;人类发明了文字，同时想用计算机来处理文字。由此，就产生了字符。每个字符代码一个文字的图形。&lt;/p&gt;

&lt;h1 id=&#34;字符串的表示&#34;&gt;字符串的表示&lt;/h1&gt;

&lt;p&gt;在计算机内部，只有01的信息。因此，为了能让计算机能够认识字符串，每个字符就的被映射成01数据。这个映射功能就叫编码。&lt;/p&gt;

&lt;h2 id=&#34;ascii&#34;&gt;ASCII&lt;/h2&gt;

&lt;p&gt;ASCII是美国19世纪60年代发明的一种编码，总共规定了128个字符，每个字符有1个字节大小。范围从0-127，比如&lt;code&gt;A&lt;/code&gt;的编码是&lt;code&gt;01000001&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;unicode&#34;&gt;Unicode&lt;/h2&gt;

&lt;p&gt;世界语言文字异常丰富，每个国家都有自己独特的语言文字。ASCII的编码无法编码所有的文字，因此产生了很多编码，比如中文的BIG5，GB2312等等。这些编码无法兼容，比如&lt;code&gt;中&lt;/code&gt;在GB2312编码是&lt;code&gt;1101011011010000&lt;/code&gt;，BIG5的编码是&lt;code&gt;1010010010100100&lt;/code&gt;。因此，Unicode就出现了。Unicode规定了每个字符的唯一编号，目前已经有100多万个字符。需要注意的是Unicode只规定了字符的编号，没有规定二进制的表示。&lt;/p&gt;

&lt;h2 id=&#34;utf8编码&#34;&gt;Utf8编码&lt;/h2&gt;

&lt;p&gt;utf8是Ken Thompson于1992年创建，现在已经标准化为RFC 3629。是目前使用最为广泛的unicode编码方式，其他的有utf-16，utf-32。它的特点是变长的，使用1-4个字节表示一个字符，不同的符号有不同的长度。&lt;/p&gt;

&lt;p&gt;utf8编码规则：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  1. 一个字节的编码，最高位为0，其他的位表示unicode编号
  2. n个字节的编码（n&amp;gt;1），第一个字节的n位都是1，第n+1位是0，后面的每个字节的最高两位都是10，其余的位用来表示unicode编号
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下表表示了utf8的编码，z表示用于编码的bit&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;unicode范围&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;utf8编码&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;十六进制表示&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;二进制表示&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;000000 - 00007F&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0zzzzzzz&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;000080 - 0007FF&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;110zzzzz 10zzzzzz&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;000800 - 00D7FF/00E000 - 00FFFF&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1110zzzz 10zzzzzz 10zzzzzz&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;010000 - 10FFFF&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11110zzz 10zzzzzz 10zzzzzz 10zzzzzz&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;环境中的编码&#34;&gt;环境中的编码&lt;/h1&gt;

&lt;p&gt;一个程序读取字符的输入的时候，读取的是二进制的数据。如果程序需要理解这个字符串是什么意思，必须了解字符的编码。同理，程序输出字符串的时候必须告知字符串的编码，不然使用者就无法理解程序的输出。程序中遇到乱码的问题，都是因为一个程序输出的字符串的编码和另一个程序接受字符串时使用的编码不一致导致的。因此，在解决编码的问题的思路就是搞清楚涉及到了哪几个环境。&lt;/p&gt;

&lt;p&gt;比如：一个程序打印一个字符串到终端。程序的编码是utf8，终端显示的编码是gbk。这样就会造成乱码。&lt;/p&gt;

&lt;h1 id=&#34;不同语言的字符串的支持&#34;&gt;不同语言的字符串的支持&lt;/h1&gt;

&lt;h2 id=&#34;python-中的字符串&#34;&gt;python 中的字符串&lt;/h2&gt;

&lt;h3 id=&#34;python-2&#34;&gt;python 2&lt;/h3&gt;

&lt;h4 id=&#34;字符类型&#34;&gt;字符类型&lt;/h4&gt;

&lt;p&gt;分为byte字符串(str)和unicode(unicode)，前者的内容是字节，后者的内容是unicode中的编号。默认的是byte字符串。&lt;/p&gt;

&lt;h4 id=&#34;重要方法&#34;&gt;重要方法&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# &amp;lt;type &#39;str&#39;&amp;gt; to &amp;lt;type &#39;unicode&#39;&amp;gt;
# 如果 s 是&#39;unicode&#39;类型，python会先通过encode函数把s转换成&#39;str&#39;类型
# encode函数的encoding是sys.getdefaultencoding()的值
s.decode(encoding)

# &amp;lt;type &#39;unicode&#39;&amp;gt; to &amp;lt;type &#39;str&#39;&amp;gt;
# 如果u是&#39;str&#39;类型，python会通过decode函数把u转换成&#39;unicode&#39;类型
# decode函数的encoding是sys.getdefaultencoding()的值
u.encode(encoding)

# 获取系统默认的编码
sys.getdefaultencoding()

# 修改系统的默认编码
sys.setdefaultencoding(encoding)

# 修改代码
import sys
reload(sys) # 因为python初始化的时候会把setdefaultencoding方法给删除掉
sys.setdefaultencoding(&#39;utf8&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;codecs&#34;&gt;codecs&lt;/h4&gt;

&lt;p&gt;指定encoding参数生成file-object-like对象，利用：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;函数 &lt;code&gt;read&lt;/code&gt; 读取byte字符串，按照encoding的编码返回unicode&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;write&lt;/code&gt; 输入unicode，按照encoding的编码转换成byte字符串写入文件&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;python-3&#34;&gt;python 3&lt;/h3&gt;

&lt;p&gt;显然，python2中的字符串处理方式会变得复杂，因此在python3中字符串统一都是unicode。&lt;/p&gt;

&lt;h2 id=&#34;go中的字符串&#34;&gt;go中的字符串&lt;/h2&gt;

&lt;p&gt;go中有两种类型支持字符串分别是：&lt;code&gt;string&lt;/code&gt; 和 &lt;code&gt;rune&lt;/code&gt; 。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;string表示字节slice（分片）&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;rune表示unicode的编码（code point）&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;go对utf8有天然的支持。go的源代码是utf8编码，&lt;code&gt;for ... range&lt;/code&gt; 循环字符串的时候也是按照utf8编码来处理每个字符，而不是字节。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>prometheus</title>
      <link>http://zjykzk.github.io/post/cs/prometheus/</link>
      <pubDate>Sun, 09 Oct 2016 14:45:21 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/prometheus/</guid>
      <description>

&lt;h2 id=&#34;架构&#34;&gt;架构&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://zjykzk.github.io/imgs/promutheus.arch.svg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;基本概念&#34;&gt;基本概念&lt;/h2&gt;

&lt;h3 id=&#34;数据模型&#34;&gt;数据模型&lt;/h3&gt;

&lt;p&gt;prometheus把数据当作时间序列进行存储。&lt;br /&gt;
每个时间序列通过 &lt;strong&gt;metric name&lt;/strong&gt;和 &lt;strong&gt;key-value pairs&lt;/strong&gt;(也叫做 &lt;strong&gt;label&lt;/strong&gt;)标识。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;metric name&lt;/strong&gt;表示需要进行测量的系统指标。&lt;br /&gt;
它允许包含ASCII字母，数字，下划线和分号。&lt;br /&gt;
正则表示为：[a-zA-Z&lt;em&gt;:][a-zA-Z0-9&lt;/em&gt;:]*。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;label&lt;/strong&gt;表示一个系统指标的维度，可以按照这个维度进行查询统计。&lt;br /&gt;
Label名字允许包含ASCII字母，数字以及下划线。&lt;br /&gt;
正则表示为：[a-zA-Z&lt;em&gt;][a-zA-Z0-9&lt;/em&gt;]*。同时，“__”开头的名字系统保留的。&lt;br /&gt;
Label值允许任意的Unicode字符&lt;/p&gt;

&lt;h3 id=&#34;度量类型&#34;&gt;度量类型&lt;/h3&gt;

&lt;h4 id=&#34;counter&#34;&gt;Counter&lt;/h4&gt;

&lt;p&gt;累计统计度量的单个值。适用于只增不减度量，比如累计请求数量。&lt;/p&gt;

&lt;h4 id=&#34;gauge&#34;&gt;Gauge&lt;/h4&gt;

&lt;p&gt;统计度量的单个值。适用于可以增减的度量，比如当前的内存使用情况。&lt;/p&gt;

&lt;h4 id=&#34;histogram&#34;&gt;Histogram&lt;/h4&gt;

&lt;p&gt;统计度量事件发生的次数以及度量值的和。还支持统计小于某个阀值的度量事件发生的次数。&lt;/p&gt;

&lt;p&gt;这个度量类型有三个时间序列统计：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;lt;base_name&amp;gt;_bucket{le=&amp;laquo;upper inclusive bound&amp;raquo;}：小于某个阀值的度量事件发生的次数&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&amp;lt;base_name&amp;gt;_sum：度量值的和&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&amp;lt;base_name&amp;gt;_count：度量事件发生的次数&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;summary&#34;&gt;Summary&lt;/h4&gt;

&lt;p&gt;统计度量时间发生的次数以及度量值的和。还支持统计某个百分比内的度量事件发生的次数。&lt;/p&gt;

&lt;p&gt;这个度量类型有三个时间序列统计：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;lt;base_name&amp;gt;{quantile=&amp;raquo;&amp;lt;p&amp;gt;&amp;laquo;}：度量值在前百分之p的度量事件发生的次数&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&amp;lt;base_name&amp;gt;_sum：度量值的和&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;&amp;lt;base_name&amp;gt;_count：度量事件发生的次数&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;job-instance&#34;&gt;Job &amp;amp; Instance&lt;/h3&gt;

&lt;p&gt;在prometheus里面对监控的对象分成Job和Instance。Instance代表一个监控的实例。比如&lt;br /&gt;
一个支付进程。Job代表一个监控的逻辑单位。&lt;br /&gt;
比如支付服务，它在多台机器上面部署着，每台机器对应一个Instance。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;job: payment-server&lt;br /&gt;

&lt;ul&gt;
&lt;li&gt;instance 1: 1.2.3.4:5678&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;instance 2: 1.2.3.5:5689&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;instance 3: 1.2.3.6:5689&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;自动生成的label和时间序列&#34;&gt;自动生成的label和时间序列&lt;/h4&gt;

&lt;p&gt;当prometheus抓取一个目标的时候，会自动生成时间序列以及label，用来标识抓取的目标状态。&lt;/p&gt;

&lt;p&gt;label:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;job: 配置好的job名字&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;instance:&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;格式的url&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;时间序列：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;up{job=&amp;raquo;&amp;lt;job-name&amp;gt;&amp;laquo;, instance=&amp;raquo;&amp;lt;host:port&amp;gt;&amp;laquo;}：1 表示监控目标活着，0表示挂了&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;scrape_duration_seconds{job=&amp;raquo;&amp;lt;job-name&amp;gt;&amp;laquo;, instance=&amp;raquo;&amp;lt;host:port&amp;gt;&amp;laquo;}：抓取日志的时间&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>增加bug的编程实践</title>
      <link>http://zjykzk.github.io/post/cs/bug-op/</link>
      <pubDate>Sat, 04 Jun 2016 11:12:13 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/bug-op/</guid>
      <description>

&lt;h2 id=&#34;思路不清晰&#34;&gt;思路不清晰&lt;/h2&gt;

&lt;p&gt;思路没有完全确定情况下写代码。造成不确定的情况有多方面：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. 求快，把相似的需求当做一样的需求
2. 缺少设计，大体明白实现方案，就开始编码
3. 知识不充分，集中在前端的css、布局
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;怎么办？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;快是可以做到，心里不要慌就是。&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. 需求分析到位
2. 仔细查看现有的代码
3. 遗留代码多问老员工
4. 放下别人对你问代码时的负面情绪
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;破窗原理&#34;&gt;破窗原理&lt;/h2&gt;

&lt;p&gt;在一个代码质量差的项目里面，就很容易被一种“别人也是这样，我也就这样得了”，尤其是在你不熟悉代码的情况下。&lt;strong&gt;短期内，代码是写给自己的，维护的人是自己，长期内是给别人的，对自己好就是对别人好，还有需要执行力。&lt;/strong&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>flume</title>
      <link>http://zjykzk.github.io/post/cs/flume/</link>
      <pubDate>Sun, 27 Mar 2016 22:17:17 +0800</pubDate>
      <author>zhangkai.zju@gmail.com (zenk)</author>
      <guid>http://zjykzk.github.io/post/cs/flume/</guid>
      <description>

&lt;h1 id=&#34;架构&#34;&gt;架构&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;http://zjykzk.github.io/imgs/flume.dot.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;概念&#34;&gt;概念&lt;/h1&gt;

&lt;h2 id=&#34;source&#34;&gt;source&lt;/h2&gt;

&lt;p&gt;数据的生成源。比如：读取一个本地文件，MQ等等。一个数据单元被封装成一个&lt;strong&gt;event&lt;/strong&gt;。&lt;/p&gt;

&lt;h3 id=&#34;event&#34;&gt;event&lt;/h3&gt;

&lt;p&gt;数据单元，从&lt;strong&gt;source&lt;/strong&gt;产生，直到被序列化到存储中。&lt;strong&gt;event&lt;/strong&gt;包含*header*，*body*两个部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;header: 一个map数据，可以被&lt;strong&gt;interceptor&lt;/strong&gt;引用&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;body: 一个字节序列，具体日志数据&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;interceptor&#34;&gt;interceptor&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;source&lt;/strong&gt;读取一个&lt;strong&gt;event&lt;/strong&gt;在放到&lt;strong&gt;channel&lt;/strong&gt;中之前，&lt;strong&gt;event&lt;/strong&gt;可以被添加数据。比如说：采集机器的主机名称，时间戳。&lt;/p&gt;

&lt;h2 id=&#34;channel&#34;&gt;channel&lt;/h2&gt;

&lt;p&gt;数据队列，高可用的保障。&lt;strong&gt;source&lt;/strong&gt;产生的数据先放到这里，&lt;strong&gt;sink&lt;/strong&gt;接着从这里取出来放到存储当中。&lt;/p&gt;

&lt;h3 id=&#34;channel-selector&#34;&gt;channel selector&lt;/h3&gt;

&lt;p&gt;两个作用：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;复制：把一个&lt;strong&gt;event&lt;/strong&gt;写到一个或者多个&lt;strong&gt;channel&lt;/strong&gt;中&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;路由：根据&lt;strong&gt;event&lt;/strong&gt;中的某个属性值，把数据写到指定的&lt;strong&gt;channel&lt;/strong&gt;中&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;sink&#34;&gt;sink&lt;/h2&gt;

&lt;p&gt;负责把&lt;strong&gt;channel&lt;/strong&gt;中的数据写入目标存储。&lt;/p&gt;

&lt;h3 id=&#34;sink-processor&#34;&gt;sink processor&lt;/h3&gt;

&lt;p&gt;选择&lt;strong&gt;sink&lt;/strong&gt;，在这里可以完成负载均衡和容错处理。&lt;/p&gt;

&lt;h3 id=&#34;event-serializer&#34;&gt;event serializer&lt;/h3&gt;

&lt;p&gt;把&lt;strong&gt;event&lt;/strong&gt;中的数据，转换成存储需要的格式。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
