<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cs on 老K随笔</title>
    <link>http://zjykzk.github.io/categories/cs/</link>
    <description>Recent content in Cs on 老K随笔</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>(c) 2025 zenk.</copyright>
    <lastBuildDate>Mon, 01 Jul 2024 18:13:21 +0800</lastBuildDate>
    <atom:link href="http://zjykzk.github.io/categories/cs/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>TDD底层逻辑</title>
      <link>http://zjykzk.github.io/posts/cs/engineering/tdd/</link>
      <pubDate>Mon, 01 Jul 2024 18:13:21 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/engineering/tdd/</guid>
      <description>&lt;h1 id=&#34;一些开发常见问题&#34;&gt;一些开发常见问题&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;当前架构无法满足新需求，不敢修改或者新增抽象。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;一段代码变得很长，难以理解，不敢修改代码。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;开发过程中通过『跑下看看』、『打断点』的方式来测试、定位问题，效率低下（隐式QA）。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;有功能忘记写了。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;以上的问题概括起来说，代码和架构不容易维护和扩展、开发效率低。TDD作为极限编程（XP）的核心实践之一，能够比较好的解决了这些问题。&lt;/p&gt;&#xA;&lt;h1 id=&#34;测试驱动开发tdd&#34;&gt;测试驱动开发（TDD）&lt;/h1&gt;&#xA;&lt;p&gt;从上一节TDD可以解决的问题视角可以看出，TDD不是『如何写测试的技术』、『怎么消除QA』、『增加开发人员』的编码技巧。它是把测试作为里程碑的开发流程，把无计划的测试变成自动化测试提升开发效率，结合重构技巧保证代码和架构的可维护性和扩展性。&lt;/p&gt;&#xA;&lt;h2 id=&#34;测试也就是t字母&#34;&gt;测试（也就是T字母）&lt;/h2&gt;&#xA;&lt;p&gt;首先，不是传统的单元测试，也就是不涉及被测试进程之外组件的测试，而是单元级别的&lt;strong&gt;功能测试&lt;/strong&gt;。所以，也可能是传统的集成测试，但是绝对不是端到端测试；）。&lt;/p&gt;&#xA;&lt;p&gt;『功能』是指用户视角的需求拆分以后的功能，是从业务视角出发，而不是代码中的某个类、函数等。比如，『账号密码的登入』这么一个需求可以拆分成两个功能，以及对应的测试：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;账号密码正确登入成功。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;账号或者密码错误登入失败。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;但是，TDD不教你怎么写测试，写测试是TDD的必要技能，常见包括：状态验证、行为验证、怎么识别有效无效测试、怎么使用mock&amp;amp;stub等等，好测试的核心是：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;发现问题：覆盖足够多的代码，尤其是核心代码&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;稳定：代码重构的时候不会误报（错误的失败），不用修改&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;快速执行&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;容易维护：容易执行、容易理解。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;驱动也就是第一个d字母&#34;&gt;驱动（也就是第一个D字母）&lt;/h2&gt;&#xA;&lt;h3 id=&#34;驱动的是架构&#34;&gt;驱动的是『架构』&lt;/h3&gt;&#xA;&lt;p&gt;软件开发工程师开发软件首要的是：理解需求，明白架构。&lt;/p&gt;&#xA;&lt;p&gt;『理解需求』TDD无法驱动，但是能够验证是否做到了：写出测试，说明理解需求。&lt;/p&gt;&#xA;&lt;p&gt;理解需求并完成分解可以成&lt;em&gt;测试的TODO项&lt;/em&gt;之后，进入执行『红-绿-重构循环』这一TDD的核心三步骤：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;红绿来自jUnit这个测试框架，失败的UT显示红色，成功的UT显示绿色。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;红：针对单元功能编写一个失败的小测试，无法编译的也没关系；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;绿：让这个测试快速通过，任何手段都可以，甚至是错误的实现；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;重构：消除上一步中产生的坏味道。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;『红』锚定了需要实现的需求，『绿』在&lt;strong&gt;当前架构下面（如果有）的合适组件&lt;/strong&gt;下面实现刚刚锚定的需求，『重构』消除上一步中产生的各种坏味道，比如消除重复（合并组件），降低耦合（重新划分组件的职责）等等。&lt;/p&gt;&#xA;&lt;p&gt;从『驱动』视角可以看出，他并不是教你怎么编码的技术，而是一个架构技术，是以逐步演进的方式驱动架构，是一种实效主义编码架构风格（不做PPT架构师；））。&lt;/p&gt;&#xA;&lt;h3 id=&#34;极限&#34;&gt;极限&lt;/h3&gt;&#xA;&lt;p&gt;如果不会写某个测试对应的实现，TDD能驱动吗？不能！TDD无法驱动小于单元功能测试对应的需求，也无法驱动内部实现。但是，作为架构技术TDD能让你知道实现应该放在哪里，可以继续迭代其他需求，同样保持着一个有序可度量的研发节奏。至于这个需求怎么做可以找人帮忙做。&lt;/p&gt;&#xA;&lt;h2 id=&#34;执行&#34;&gt;执行&lt;/h2&gt;&#xA;&lt;h3 id=&#34;基本原则&#34;&gt;基本原则&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;当且仅当存在失败的自动化测试时，才开始编写生产代码；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;消除坏味道。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;开发咒语&#34;&gt;开发咒语&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;红：针对单元功能编写一个失败的小测试，无法编译的也没关系；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;绿：让这个测试快速通过，任何手段都可以，甚至是错误的实现；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;重构：消除上一步中产生的坏味道。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;任务分解法写出测试&#34;&gt;任务分解法（写出测试）&lt;/h3&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;来自徐昊&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;首先将需求分解为功能点，也就是将需求转化为一系列可验证的里程碑点；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;如果已经存在架构或架构愿景，则依据架构中定义的组件与交互，将功能点分解为不同的功能上下文；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;如果尚不存在架构愿景，则可以将功能点作为功能上下文；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;将功能点按照功能上下文，分解为任务项。也就是进一步将可验证的里程碑点，分解为功能上下文中可验证的任务项；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;将任务项转化为自动化测试，进入红 / 绿 / 重构循环，驱动功能上下文内的功能实现；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;如果重构涉及功能上下文的重新划分，即提取 / 合并组件，即视作对于架构的重构与梳理。需调整后续功能点中对于功能上下文以及任务项的划分。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;如此往复，直到所有功能完成。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/tdd.jpeg&#34; alt=&#34;tdd progres&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;如何学习&#34;&gt;如何学习&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;练，属于不可言说知识，以上内容都看懂了也不会；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;锻炼分析能力，它是支撑拆解任务基础；&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;使用具有重构能力的IDE，不然变成重写。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>简单设计的4个原则</title>
      <link>http://zjykzk.github.io/posts/cs/design/4rules-of-simple-design/</link>
      <pubDate>Tue, 03 May 2022 23:34:49 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/design/4rules-of-simple-design/</guid>
      <description>&lt;h3 id=&#34;什么是简单设计&#34;&gt;什么是简单设计？&lt;/h3&gt;&#xA;&lt;p&gt;首先，简单设计强调更好的设计**，而不是一个好的设计。突出了，它是一个动态的过程，强调设计随着软件开发的进展会随时调整。确保当下的设计能做到的最好设计。&lt;/p&gt;&#xA;&lt;p&gt;另外，在软件开发中有两个常识：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;需求是总是会变的。&lt;/li&gt;&#xA;&lt;li&gt;我们不能够精确预测哪些需求将会变化。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;因此，更好的设计是方便修改的设计；更好的设计是不去计划设计哪些地方将来会修改，而是采取&lt;strong&gt;简单设计的原则&lt;/strong&gt;，让代码更加容易修改。那么，容易修改代码是怎么样的？&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;有足够测试，这是不会改坏的信心的来源。&lt;/li&gt;&#xA;&lt;li&gt;容易找到修改的地方。&lt;/li&gt;&#xA;&lt;li&gt;修改的地方少。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;简单设计的4个原则&#34;&gt;简单设计的4个原则&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;通过测试。&lt;/li&gt;&#xA;&lt;li&gt;清晰的表达意图。&lt;/li&gt;&#xA;&lt;li&gt;尽可能少的重复。&lt;/li&gt;&#xA;&lt;li&gt;更少的代码元素。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h4 id=&#34;通过测试&#34;&gt;通过测试&lt;/h4&gt;&#xA;&lt;p&gt;作为保证代码正确性的一个手段，这是一个显而易见的问题。另外，这里还需要说明的额外的几点是：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;测试运行的速度越快越好，越快说明你的反馈速度越快，效率越高。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;测试的名称和被测试的代码保持一种对称性，名称应该反应被测试的代码语义。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;struct World {&#xA;&#x9;cells []Cell&#xA;}&#xA;&#xA;func (w *World) isEmpty() bool {&#xA;&#x9;return len(w.cells) == 0&#xA;}&#xA;&#xA;func Test_new_world_is_empty(t *testing.T) {&#xA;&#x9;w := &amp;amp;World{}&#xA;&#xA;&#x9;// BAD&#xA;&#x9;assert.Nil(t, w.cells)&#xA;&#xA;&#x9;// GOOD&#xA;&#x9;assert.True(t, w.isEmpty())&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;不应该依赖之前的测试。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;func Test_world_is_not_empty_after_a_tick(t *testing.T) {&#xA;&#x9;w := &amp;amp;World{}&#xA;&#x9;newWorld = w.tick()&#xA;&#x9;assert.False(t, newWorld.isEmpty())&#xA;}&#xA;&#xA;// 这里的w := &amp;amp;World{}依赖的测试Test_new_world_is_empty。这样会有两个问题：&#xA;// 1. 如果&amp;amp;World{}的语义改了以后就会导致测试失败。&#xA;// 2. 表达不够清晰，哪里规定了&amp;amp;World{}就是空的呢。&#xA;//&#xA;// 比较好的做法是定一个返回empty world。&#xA;func newEmptyWorld() *World {&#xA;&#x9;return &amp;amp;World{}&#xA;}&#xA;&#xA;func Test_world_is_not_empty_after_a_tick(t *testing.T) {&#xA;&#x9;w := newEmptyWorld()&#xA;&#x9;newWorld = w.tick()&#xA;&#x9;assert.False(t, newWorld.isEmpty())&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;测试应该关注行为不是状态。&lt;/p&gt;</description>
    </item>
    <item>
      <title>虚拟内存技术</title>
      <link>http://zjykzk.github.io/posts/cs/os/vm/</link>
      <pubDate>Wed, 16 Dec 2020 16:58:31 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/os/vm/</guid>
      <description>&lt;h2 id=&#34;缘起&#34;&gt;缘起&lt;/h2&gt;&#xA;&lt;p&gt;最开始，操作系统的内存管理非常简陋。只是简单把物理内存分为两部分：低地址部分，64K分给操作系统，高地址部分分给用户程序。而且每次只执行一个程序。执行完后要重新装载程序，再执行其他程序。接着，由于那是机器非常昂贵，人们希望能够&lt;strong&gt;充分利用机器资源&lt;/strong&gt;。出现了&lt;strong&gt;多任务&lt;/strong&gt;的操作系统。这时操作系统能够支持一次自动执行多个任务，在某些程序执行IO的时候，CPU能够执行其他程序，这样就提升了机器资源的利用率。后来，又有了希望能够和程序&lt;strong&gt;及时交互&lt;/strong&gt;。这样就能方便知道程序执行的状态了，这个对程序员来说太重要了。不然，每次都要等程序执行完才能知道结果。于是有了&lt;strong&gt;分时&lt;/strong&gt;的操作系统，也就是每个进程执行一小部分时间。但是，这里就出现了安全问题，一个进程随意的读写另外一个进程的数据，甚至是操作系统的数据！由此，内存的虚拟化就出现了，它为每个程序提供一个统一抽象的&lt;strong&gt;地址空间&lt;/strong&gt;，程序看到的地址又叫&lt;strong&gt;虚拟地址&lt;/strong&gt;。它的目标包括：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;透明。对程序透明，每个程序只需要认知地址空间就行，不需要考虑自己的数据、代码是放在物理内存的哪个位置。&lt;/li&gt;&#xA;&lt;li&gt;高效。包括空间和时间两方面。&lt;/li&gt;&#xA;&lt;li&gt;安全。进程隔离，保证不能任意访问其他进程的数据。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;地址转换&#34;&gt;地址转换&lt;/h2&gt;&#xA;&lt;p&gt;简单来说，把进程的虚拟地址转换成物理地址。同时程序的每次内存访问都在操作系统的控制之下，确保安全。另外，通过硬件的支持保障性能以及地址转换对用户透明。&lt;strong&gt;它是内存虚拟化的核心机制，我们遇到的很多技术细节都是为了解决这个问题。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;策略&#34;&gt;策略&lt;/h3&gt;&#xA;&lt;h4 id=&#34;动态重定位&#34;&gt;动态重定位&lt;/h4&gt;&#xA;&lt;p&gt;这里包括软件实现的静态重定位(static relocation)和基于硬件的动态重定位(dynamic relocation)。&lt;/p&gt;&#xA;&lt;p&gt;软件的实现通过一个叫loader的软件，把应用程序中的引用的地址都加上一个偏移地址就变成物理地址了。显然，这里最大的问题是不安全。&lt;/p&gt;&#xA;&lt;p&gt;硬件就不一样了，它有两个寄存器一个基地址寄存器，一个地址范围限制寄存器。当访问一个内存的时候，先把地址加上基地址寄存器中的值，这个结果就是物理地址了。同时还会对比物理地址和地址范围寄存器比较，如果超过就触发异常。这个硬件一般叫做内存管理单元（&lt;strong&gt;MMU&lt;/strong&gt;）。&lt;/p&gt;&#xA;&lt;p&gt;因此，硬件需要提供以下几个功能：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;特权模式。因为硬件有MMU的操作指令，这些指令只有操作系统才能使用，用户程序是不能直接使用的。&lt;/li&gt;&#xA;&lt;li&gt;基地址寄存器和地址范围寄存器。用于虚拟地址到物理地址的转换以及地址合法性的检查。&lt;/li&gt;&#xA;&lt;li&gt;地址转换以及检查地址是否在范围内的能力。&lt;/li&gt;&#xA;&lt;li&gt;更新基地址寄存器和地址范围寄存器指令。操作系统运行一个进程时，需要把进程的基地址和地址范围设置到到相应的寄存器。&lt;/li&gt;&#xA;&lt;li&gt;提供特权指令注册异常处理程序。操作系统告诉硬件具体异常的处理程序地址。&lt;/li&gt;&#xA;&lt;li&gt;触发异常的能力。非法访问内存地址时触发异常。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;同时，操作系统需要提供以下几个功能：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;内存管理。为新进程分配内存，回收执行结束的进程使用的内存，通常是一个free list来管理。&lt;/li&gt;&#xA;&lt;li&gt;基地址和地址范围管理。进程切换时设置当前执行的进程的基地址和地址范围到相应的寄存器。&lt;/li&gt;&#xA;&lt;li&gt;异常处理能力。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;操作系统和硬件的交互，主要包含在启动和执行程序的时候。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;启动&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;操作系统（kernel mode）                     硬件&#xA;================================+=================================&#xA; 初始化异常表&#xA;&#xA;                                       保存系统调用地址&#xA;                                       定时处理程序地址&#xA;                                       非法内存访问处理程序地址&#xA;                                       非法指令异常处理程序&#xA; 启动定时器中断&#xA;                                       开启定时器&#xA; 初始化进程表&#xA; 初始内存空闲列表&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;程序执行&lt;/strong&gt;：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;操作系统（kernel mode）                           硬件                        程序（user mode）&#xA;================================+=======================================+=====================&#xA; 启动进程A：&#xA;  进程表中添加进程&#xA;  分配进程需要的内存&#xA;  设置基地址和地址范围寄存器&#xA;  执行进程A的代码&#xA;                                       恢复进程A的寄存器，进入user mode&#xA;                                       跳转到进程A的起始指令&#xA;                                                                              获取指令&#xA;                                       转换指令的物理地址，获取指令内容&#xA;                                                                              执行指令&#xA;                                       如果是保存或者获取数据，检查内存&#xA;                                       地址是否合法&#xA;                                                                              继续执行。。。&#xA;                                       定时器时间到了，进入kernel mode&#xA;                                       执行定时器处理程序&#xA; 停止执行进程A，保存进程A的上&#xA; 下文到进程控制块：&#xA;  当前执行的指令地址以及基地址&#xA;  寄存器和地址范围寄存器的值&#xA;  加载进程B的寄存器以及指令地址&#xA;  执行进程B的代码&#xA;                                       恢复进程B的寄存器，进入user mode&#xA;                                       跳转到进程B的指令&#xA;                                                                              访问非法地址&#xA;                                       地址越界，触发异常进入kernel mode&#xA; 执行非法访问地址异常代码，终止&#xA; 进程B，回收进程B的内存，释放&#xA; 进程表中有关进程B的内存&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;分段&#34;&gt;分段&lt;/h4&gt;&#xA;&lt;p&gt;把整个地址空间映射到物理空间如下图（假设地址空间大小是16K）：&lt;/p&gt;</description>
    </item>
    <item>
      <title>二阶段提交和三阶段提交</title>
      <link>http://zjykzk.github.io/posts/cs/dist/2_3pc/</link>
      <pubDate>Fri, 17 Apr 2020 15:12:22 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/dist/2_3pc/</guid>
      <description>&lt;h2 id=&#34;缘起&#34;&gt;缘起&lt;/h2&gt;&#xA;&lt;p&gt;事务是一段访问或者更新数据的程序。它的特点是ACID。本地事务只涉及到一个数据库能够保证事务ACID了。当涉及到多个不同数据库（广义的数据库，他们可以是MQ，甚至缓存）操作时，为了保证每个数据库的操作要么都成功或者都失败，就需要额外的技术来处理。这是因为单个数据库操作会失败，同时&lt;strong&gt;通信失败&lt;/strong&gt;会导致整个事务无法感知这个失败。二阶段提交（2PC）或者三阶段提交（3PC）就是用来解决这个问题。&lt;/p&gt;&#xA;&lt;p&gt;一般来说这个有两个角色一个是事务协调者，简称&lt;strong&gt;TC&lt;/strong&gt;，一个是事务参，简称&lt;strong&gt;TP&lt;/strong&gt;。下文用简称来说明。&lt;/p&gt;&#xA;&lt;h2 id=&#34;2pc&#34;&gt;2PC&lt;/h2&gt;&#xA;&lt;h3 id=&#34;准备完毕状态&#34;&gt;准备完毕状态&lt;/h3&gt;&#xA;&lt;p&gt;当TP把事务中修改的结果持久化到存储以后，它才能算是准备完毕。&lt;/p&gt;&#xA;&lt;p&gt;在所有的TP准备完毕之前，不能有任何一个TP提交事务。不然就会破坏事务的原子性。比如：TP1提交了，TP2还没准备完毕，这个时候TP2crash了，因为TP2并没有保存事务相关的after-images，就没法恢复。这时就出现了TP1成功，但是TP2没有执行的情况。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;2PC本质：在提交之前确保所有的TP都已经准备完毕。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h3 id=&#34;协议&#34;&gt;协议&lt;/h3&gt;&#xA;&lt;p&gt;2pc包含两个阶段。准备阶段和提交（终止）阶段，TC和TP的通信如下。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;                       TC                              TP&#xA;                     +----+  REQUEST-TO-PREPARE      +----+&#xA;                     |    | -----------------------&amp;gt; |    |&#xA;                     |    |         PREPARE          |    |&#xA;                     |    | &amp;lt;----------------------- |    |&#xA;                     |    |           NO             |    |&#xA;                     |    |                          |    |&#xA;                     |    |         COMMIT           |    |&#xA;                     |    | -----------------------&amp;gt; |    |&#xA;                     |    |          ABORT           |    |&#xA;                     |    |          DONE            |    |&#xA;                     |    | &amp;lt;----------------------- |    |&#xA;                     +----+                          +----+&#xA;                                    Messages&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;2pc&lt;em&gt;本质是任何TP提交之前，所有的TP都必须已经准备好。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;第一阶段&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;TC向每个TP发送REQUEST-TO-PREPARE消息。&lt;/li&gt;&#xA;&lt;li&gt;TC等待每个TP的投票。&lt;/li&gt;&#xA;&lt;li&gt;TP收到REQUEST-TO-PREPARE返回消息：&#xA;&lt;ol&gt;&#xA;&lt;li&gt;TP确认可以提交事务，返回PREPARE消息。&lt;/li&gt;&#xA;&lt;li&gt;TP准备资源失败，返回NO消息。&lt;/li&gt;&#xA;&lt;li&gt;因为系统负载原因或者系统挂掉了，一直没有投票&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;第二阶段&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>mysql连接中的serverTimezone参数解析</title>
      <link>http://zjykzk.github.io/posts/cs/db/mysql-servertimezone/</link>
      <pubDate>Wed, 12 Feb 2020 10:41:51 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/db/mysql-servertimezone/</guid>
      <description>&lt;p&gt;在mysql连接的选项中参数&lt;code&gt;serverTimezone&lt;/code&gt;用来指定服务器的时区.它的作用主要用于当我们传递时间类型的参数以及获取时间类型的数值时,转换成程序运行所在环境的时区所对应的时间.注意:如果传递字符串是没问题的,因为jdbc会把参数都转成字符串类型的sql传递到服务区上去.&lt;/p&gt;&#xA;&lt;p&gt;如果不指定的情况下,会通过连接获取mysq服务器上面的时区.先获取变量&lt;code&gt;time_zone&lt;/code&gt;值,如果是&lt;code&gt;SYSTEM&lt;/code&gt;,就获取&lt;code&gt;system_time_zone&lt;/code&gt;的值.参考代码:&lt;code&gt;com.mysql.cj.protocol.a.NativeProtocol.configureTimezone&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;因此,关于&lt;code&gt;system_time_zone&lt;/code&gt;值的设置的目的是为了解决你写入和读取的时间值一致性.如果你是读别人写的数据,那么需要把它设置成写入的时候指定的时区.&lt;/p&gt;</description>
    </item>
    <item>
      <title>bolt源码分析</title>
      <link>http://zjykzk.github.io/posts/cs/db/bolt/</link>
      <pubDate>Sun, 19 Jan 2020 11:39:24 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/db/bolt/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/boltdb/bolt&#34;&gt;bolt&lt;/a&gt;数据库是golang开发的简单的kv数据库。代码十分精简，总共3000+行，学习数据库一个比较好的起点。&lt;/p&gt;&#xA;&lt;h2 id=&#34;数据结构&#34;&gt;数据结构&lt;/h2&gt;&#xA;&lt;p&gt;bolt使用的数据结构按照数据保存的位置划分两类：内存和磁盘。&lt;/p&gt;&#xA;&lt;p&gt;内存中的数据结构核心是B+树，它根据key组织在一起。B+树中的每个结点，对应数据结构&lt;a href=&#34;#node&#34;&gt;node&lt;/a&gt;，其中的内部信息通过数据结构&lt;a href=&#34;#inode&#34;&gt;inode&lt;/a&gt;来描述。内存中其他主要数据结构还包括&lt;a href=&#34;#meta&#34;&gt;meta&lt;/a&gt;和&lt;a href=&#34;#freelist&#34;&gt;freelist&lt;/a&gt;。&lt;/p&gt;&#xA;&lt;p&gt;描述磁盘中的数据结构是&lt;a href=&#34;#page&#34;&gt;page&lt;/a&gt;，它的数据来自于&lt;a href=&#34;#node&#34;&gt;node&lt;/a&gt;、&lt;a href=&#34;#meta&#34;&gt;meta&lt;/a&gt;或者&lt;a href=&#34;#freelist&#34;&gt;freelist&lt;/a&gt;。对应者一块内存，大小为os的page size的倍数。&lt;/p&gt;&#xA;&lt;h3 id=&#34;node&#34;&gt;node&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;type node struct {&#xA;  bucket     *Bucket      // 这个结点所在的的bucket&#xA;  isLeaf     bool         // 是否是叶子结点&#xA;  unbalanced bool         // 是否平衡，删除的时候做标记&#xA;  spilled    bool         // 是否已经分裂&#xA;  key        []byte       // 对应着第一个inode中的key&#xA;  pgid       pgid         // 所在页的id&#xA;  parent     *node        // 父结点&#xA;  children   nodes        // 子结点&#xA;  inodes     inodes       // 结点中key或者key&amp;amp;value，如果是分支结点只有key，叶子结点还有value&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;inode&#34;&gt;inode&lt;/h4&gt;&#xA;&lt;p&gt;通过&lt;a href=&#34;#branchPageElement&#34;&gt;branchPageElement&lt;/a&gt;或者&lt;a href=&#34;#leafPageElement&#34;&gt;leafPageElement&lt;/a&gt;来获取数据。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;type inode struct {&#xA;  flags uint32            // 标记，用来区分支结点和叶子结点&#xA;  pgid  pgid              // 所在页的id&#xA;  key   []byte&#xA;  value []byte&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;page&#34;&gt;page&lt;/h3&gt;&#xA;&lt;p&gt;代表一个页或者连续的几个页。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;type page struct {&#xA;  id       pgid           // 64位的id&#xA;  flags    uint16         // 页的标记，表示存储的数据类型，包括分支、叶子，元数据和描述空闲页的数据&#xA;  count    uint16         // 包含数据的元素个数&#xA;  overflow uint32         // 后面还有的页数&#xA;  ptr      uintptr        // 只是一个标记字段，标记数据的起始位置&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;bucketpageelement&#34;&gt;bucketPageElement&lt;/h4&gt;&#xA;&lt;p&gt;B+树中分支结点保存的数据元信息。&lt;/p&gt;</description>
    </item>
    <item>
      <title>如何学习一门编程语言</title>
      <link>http://zjykzk.github.io/posts/cs/language/learn/</link>
      <pubDate>Tue, 04 Jun 2019 16:50:10 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/language/learn/</guid>
      <description>&lt;h3 id=&#34;类型系统&#34;&gt;类型系统&lt;/h3&gt;&#xA;&lt;p&gt;常用的数据类型，包括：数值、字符串、数组、函数。以及自定义类型，比如说java中的class，C++中的泛型，C中的struct等等。很多语言也把函数当作基本类型，典型的如动态类型语言语言，静态类型如golang。&lt;/p&gt;&#xA;&lt;h3 id=&#34;语法&#34;&gt;语法&lt;/h3&gt;&#xA;&lt;p&gt;主要分表达式、语句。&lt;/p&gt;&#xA;&lt;p&gt;表达式主要表达计算，计算出一个值，用于下面逻辑。这个计算可能是数学运算，也可能是数据引用。&lt;/p&gt;&#xA;&lt;p&gt;语句主要表达逻辑，比如控制语句中的if/else，for循环等等。&lt;/p&gt;&#xA;&lt;h3 id=&#34;算法与数据结构&#34;&gt;算法与数据结构&lt;/h3&gt;&#xA;&lt;p&gt;语言会提供常用个数据结构和算法，通常是一sdk的形式提供。一般越底层的语言提供的越少（对比C和JAVA）。&lt;/p&gt;&#xA;&lt;p&gt;最常用的算法就是排序了。其他还有：查找、随机数、压缩。&lt;/p&gt;&#xA;&lt;p&gt;数据结构一般有数组、向量、列表、队列、堆、栈、哈希表等等。&lt;/p&gt;&#xA;&lt;h3 id=&#34;编程范式支持&#34;&gt;编程范式支持&lt;/h3&gt;&#xA;&lt;p&gt;常规的编程范式包括：命令式、函数式、面向对象。&lt;/p&gt;&#xA;&lt;h3 id=&#34;抽象方式&#34;&gt;抽象方式&lt;/h3&gt;&#xA;&lt;p&gt;常规的抽象方式：函数、泛型、接口、类、结构体。&lt;/p&gt;&#xA;&lt;h3 id=&#34;领域支持&#34;&gt;领域支持&lt;/h3&gt;&#xA;&lt;p&gt;最常见的领域要数包管理、错误处理、并发和网络了。一般会对他们做一个特别的支持，比如golang对并发。&lt;/p&gt;&#xA;&lt;h3 id=&#34;源代码&#34;&gt;源代码&lt;/h3&gt;&#xA;&lt;p&gt;如果要深入语言的话，源代码的阅读是必不可少的。主要包括sdk和优秀框架。&lt;/p&gt;&#xA;&lt;p&gt;sdk方面。一般需要熟悉最常用的，比如列表、哈希、并发相关数据结构和算法。&lt;/p&gt;&#xA;&lt;p&gt;优秀框架。一门语言总会有很多优秀的框架，比较有代表性的方面包含：网络框架、并发框架、日志框架、测试框架、错误处理框架以及web框架。&lt;/p&gt;&#xA;&lt;h3 id=&#34;语言特性&#34;&gt;语言特性&lt;/h3&gt;&#xA;&lt;p&gt;这是比较&lt;strong&gt;重要&lt;/strong&gt;的一点，是该语言区别其他的语言的地方，也是学习这门语言的原因。比如golang的并发（goroutine&amp;amp;channel）、C对硬件的封装、python的简洁与表达能力等等。&lt;/p&gt;</description>
    </item>
    <item>
      <title>sync.Map实现分析</title>
      <link>http://zjykzk.github.io/posts/cs/golang/sync/</link>
      <pubDate>Wed, 29 May 2019 14:44:31 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/golang/sync/</guid>
      <description>&lt;p&gt;golang的SDK中提供线程安全的map实现&lt;code&gt;sync.Map&lt;/code&gt;。它是针对&lt;code&gt;RWMutex+map&lt;/code&gt;的实现方案中存在cache line的false share提出来的。主要适用于两个场景：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;针对一个key一次写多次读。&lt;/li&gt;&#xA;&lt;li&gt;多个goroutine并发读写修改的key是没有交集。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;在这两种情况下，相比一个&lt;code&gt;Mutex&lt;/code&gt;或者&lt;code&gt;RWMutex&lt;/code&gt;加上普通的map，锁的竞争要少的多。那为什么呢？&lt;/p&gt;&#xA;&lt;h3 id=&#34;数据结构&#34;&gt;数据结构&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;type Map struct {&#xA;  mu Mutex&#xA;&#xA;  // read contains the portion of the map&amp;#39;s contents that are safe for&#xA;  // concurrent access (with or without mu held).&#xA;  //&#xA;  // The read field itself is always safe to load, but must only be stored with&#xA;  // mu held.&#xA;  //&#xA;  // Entries stored in read may be updated concurrently without mu, but updating&#xA;  // a previously-expunged entry requires that the entry be copied to the dirty&#xA;  // map and unexpunged with mu held.&#xA;  read atomic.Value // readOnly&#xA;&#xA;  // dirty contains the portion of the map&amp;#39;s contents that require mu to be&#xA;  // held. To ensure that the dirty map can be promoted to the read map quickly,&#xA;  // it also includes all of the non-expunged entries in the read map.&#xA;  //&#xA;  // Expunged entries are not stored in the dirty map. An expunged entry in the&#xA;  // clean map must be unexpunged and added to the dirty map before a new value&#xA;  // can be stored to it.&#xA;  //&#xA;  // If the dirty map is nil, the next write to the map will initialize it by&#xA;  // making a shallow copy of the clean map, omitting stale entries.&#xA;  dirty map[interface{}]*entry&#xA;&#xA;  // misses counts the number of loads since the read map was last updated that&#xA;  // needed to lock mu to determine whether the key was present.&#xA;  //&#xA;  // Once enough misses have occurred to cover the cost of copying the dirty&#xA;  // map, the dirty map will be promoted to the read map (in the unamended&#xA;  // state) and the next store to the map will make a new dirty copy.&#xA;  misses int&#xA;}&#xA;&#xA;// readOnly is an immutable struct stored atomically in the Map.read field.&#xA;type readOnly struct {&#xA;  m       map[interface{}]*entry&#xA;  amended bool // true if the dirty map contains some key not in m.&#xA;}&#xA;&#xA;// An entry is a slot in the map corresponding to a particular key.&#xA;type entry struct {&#xA;  // p points to the interface{} value stored for the entry.&#xA;  //&#xA;  // If p == nil, the entry has been deleted and m.dirty == nil.&#xA;  //&#xA;  // If p == expunged, the entry has been deleted, m.dirty != nil, and the entry&#xA;  // is missing from m.dirty.&#xA;  //&#xA;  // Otherwise, the entry is valid and recorded in m.read.m[key] and, if m.dirty&#xA;  // != nil, in m.dirty[key].&#xA;  //&#xA;  // An entry can be deleted by atomic replacement with nil: when m.dirty is&#xA;  // next created, it will atomically replace nil with expunged and leave&#xA;  // m.dirty[key] unset.&#xA;  //&#xA;  // An entry&amp;#39;s associated value can be updated by atomic replacement, provided&#xA;  // p != expunged. If p == expunged, an entry&amp;#39;s associated value can be updated&#xA;  // only after first setting m.dirty[key] = e so that lookups using the dirty&#xA;  // map find the entry.&#xA;  p unsafe.Pointer // *interface{}&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;Map.read&lt;/code&gt;包含了部分数据，读写请求优先考虑&lt;code&gt;read&lt;/code&gt;，针对它的操作都是CAS，无锁的。&lt;/p&gt;</description>
    </item>
    <item>
      <title>网关</title>
      <link>http://zjykzk.github.io/posts/cs/network/gate/</link>
      <pubDate>Tue, 30 Apr 2019 19:18:23 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/network/gate/</guid>
      <description>&lt;p&gt;解决跨网段访问。&lt;/p&gt;&#xA;&lt;p&gt;发包的目的地址和本机地址不在同一个网段的时候就会把包发给网关。网关把MAC头和IP头拿下来，根据IP地址和路由规则决定发往哪个结点。&lt;/p&gt;&#xA;&lt;p&gt;网关一般是路由器。&lt;/p&gt;&#xA;&lt;h4 id=&#34;路由方式&#34;&gt;路由方式&lt;/h4&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;     192.168.1.1/24|====| 192.168.56.1/24    192.168.56.2/24 |====| 192.168.4.1/24&#xA;       +----------&amp;gt;| G1 |-----------------------------------&amp;gt;| G2 |--------+&#xA;       |           |====|                                    |====|        |&#xA;       |                                                                   V&#xA;    |--+--|                                                             |--+--|&#xA;    |  A  | 192.168.1.101/24                                            |  B  | 192.168.4.101/24&#xA;    |--+--|                                                             |--+--|&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;静态路由&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;路由器配置跳转规则。它不修改IP地址，只修改MAC地址。这种类型的网关叫转发网关。&lt;/p&gt;&#xA;&lt;p&gt;A向B发消息的链路为：&lt;/p&gt;&#xA;&lt;p&gt;A-&amp;gt;G1-&amp;gt;G2-&amp;gt;B.&lt;/p&gt;&#xA;&lt;p&gt;A-&amp;gt;G1的地址内容：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;MAC源地址：A的MAC地址。&#xA;MAC目的地址：G1中192.168.1.1网口的MAC地址。&#xA;IP源地址：192.168.1.101。&#xA;IP目的地址：192.168.4.101。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;G1-&amp;gt;G2的地址内容：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;MAC源地址：G1中192.168.56.1网口的地址。&#xA;MAC目的地址：G2中192.168.56.2网口的地址。&#xA;IP源地址：192.168.1.101。&#xA;IP目的地址：192.168.4.101。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;G2-&amp;gt;B的地址内容：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;MAC源地址：G2中192.168.4.1网口的地址。&#xA;MAC目的地址：B的MAC地址。&#xA;IP源地址：192.168.1.101。&#xA;IP目的地址：192.168.4.101。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;问题：&lt;/p&gt;&#xA;&lt;p&gt;不同局域网内的ip地址会冲突。比如，你需要访问的地址和你局域网内的地址是一样的。怎么办，看看动态路由！&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;动态路由&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;路由器同样需要配置跳转规则。为了解决静态路由的问题，需要内网机器一个不会冲突的ip地址，这个地址保证了在外面不会冲突外，为了区分局域网地址，这个地址叫外网地址。这样访问另外一台内网机器的时候，ip地址是外网地址。它需要它会同时修改IP地址和MAC地址，这样才能把数据发回来。这种类型的网关叫NAT网关。&lt;/p&gt;&#xA;&lt;p&gt;A向B发消息的链路为：&lt;/p&gt;&#xA;&lt;p&gt;A-&amp;gt;G1-&amp;gt;G2-&amp;gt;B.&lt;/p&gt;&#xA;&lt;p&gt;A-&amp;gt;G1的地址内容：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;MAC源地址：A的MAC地址。&#xA;MAC目的地址：G1中192.168.1.1网口的MAC地址。&#xA;IP源地址：192.168.1.101。&#xA;IP目的地址：192.168.56.2。&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;G1-&amp;gt;G2的地址内容：&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;MAC源地址：G1中192.168.56.1网口的地址。&#xA;MAC目的地址：G2中192.168.56.2网口的地址。&#xA;IP源地址：192.168.56.1。&#xA;IP目的地址：192.168.56.2。&lt;/p&gt;</description>
    </item>
    <item>
      <title>技术选型</title>
      <link>http://zjykzk.github.io/posts/cs/select-tech/</link>
      <pubDate>Fri, 19 Apr 2019 16:19:31 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/select-tech/</guid>
      <description>&lt;h2 id=&#34;因数&#34;&gt;因数&lt;/h2&gt;&#xA;&lt;h3 id=&#34;项目因数&#34;&gt;项目因数&lt;/h3&gt;&#xA;&lt;h4 id=&#34;规模&#34;&gt;规模&lt;/h4&gt;&#xA;&lt;p&gt;小：可以选用新技术&#xA;大：使用成熟技术&lt;/p&gt;&#xA;&lt;h4 id=&#34;时间&#34;&gt;时间&lt;/h4&gt;&#xA;&lt;p&gt;紧：买商用的&#xA;宽裕：自己搞&lt;/p&gt;&#xA;&lt;h4 id=&#34;成本&#34;&gt;成本&lt;/h4&gt;&#xA;&lt;p&gt;有钱：买现成的&#xA;没钱：自己撸&lt;/p&gt;&#xA;&lt;h4 id=&#34;非功能性需求&#34;&gt;非功能性需求&lt;/h4&gt;&#xA;&lt;p&gt;高并发、低延迟、高可用、数据一致性、安全性。&lt;/p&gt;&#xA;&lt;h3 id=&#34;团队因数&#34;&gt;团队因数&lt;/h3&gt;&#xA;&lt;h4 id=&#34;当前团队成员的技术栈&#34;&gt;当前团队成员的技术栈&lt;/h4&gt;&#xA;&lt;p&gt;选大家都熟悉的：方便开发，排查问题。&lt;/p&gt;&#xA;&lt;p&gt;领导需要前瞻性。&lt;/p&gt;&#xA;&lt;h4 id=&#34;分析和实验&#34;&gt;分析和实验&lt;/h4&gt;&#xA;&lt;p&gt;征求团队意见，大家讨论分析实验。&lt;/p&gt;&#xA;&lt;h3 id=&#34;版权因数&#34;&gt;版权因数&lt;/h3&gt;&#xA;&lt;p&gt;选择合适的开源协议的软件：GPL/BSD/LGPL。考虑因数：商用、闭源、修改。&lt;/p&gt;&#xA;&lt;h3 id=&#34;技术因数&#34;&gt;技术因数&lt;/h3&gt;&#xA;&lt;h4 id=&#34;标准功能&#34;&gt;标准功能&lt;/h4&gt;&#xA;&lt;p&gt;我们需要的功能，比如说我们需要一个MQ，标准功能就是发拉消息，pub/sub。&lt;/p&gt;&#xA;&lt;h4 id=&#34;非标准功能&#34;&gt;非标准功能&lt;/h4&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;特性&lt;/th&gt;&#xA;          &lt;th&gt;描述&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;可伸缩性&lt;/td&gt;&#xA;          &lt;td&gt;产品在性能上必须能容易且有效地伸缩以满足业务需求增长的需求。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;灵活性&lt;/td&gt;&#xA;          &lt;td&gt;产品必须易于适应新的需求。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;可操作性&lt;/td&gt;&#xA;          &lt;td&gt;产品必须被设计成易于与共享的数据和广泛可得的系统通讯。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;可扩展性&lt;/td&gt;&#xA;          &lt;td&gt;产品功能必须在供应商很少介入的情况下能够定制和快速地增强。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;可使用性&lt;/td&gt;&#xA;          &lt;td&gt;只需很少的培训就能使让顾客使用产品和他的任何特性，产品应该被设计成其目标使用者的技术水平很匹配。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;高效率&lt;/td&gt;&#xA;          &lt;td&gt;产品应能在各种性能水平上工作，能够应付应用对效率的要求。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;可靠性&lt;/td&gt;&#xA;          &lt;td&gt;产品必须有被证实可在预定环境中工作的功能与特性。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;可管理性&lt;/td&gt;&#xA;          &lt;td&gt;产品必须能被配置、部署、监控和优化以确保其在预定的环境中工作良好&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;安全&lt;/td&gt;&#xA;          &lt;td&gt;产品必须保护信息和事务的完整性&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;高可用&lt;/td&gt;&#xA;          &lt;td&gt;通常来描述一个系统经过专门的设计，从而减少停工时间，而保持其服务的高度可用性。&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;技术标准&lt;/p&gt;&#xA;&lt;p&gt;通讯协议，API标准，实现语言和兼容语言，是否可以扩展。&lt;/p&gt;&#xA;&lt;h3 id=&#34;技术支持&#34;&gt;技术支持&lt;/h3&gt;&#xA;&lt;p&gt;厂商、社区支持粒度活跃度、服务质量及成本和厂商服务质量。&lt;/p&gt;&#xA;&lt;h3 id=&#34;其他&#34;&gt;其他&lt;/h3&gt;&#xA;&lt;p&gt;文档质量，开发效率，学习曲线，项目健康程度，是否容易招人，社区热度，书籍热度。项目相关的需求，比如Web项目框架，还需要考虑是否支持国际化，自动化验证，测试方便程度，扩张性。&lt;/p&gt;&#xA;&lt;h2 id=&#34;步骤&#34;&gt;步骤&lt;/h2&gt;&#xA;&lt;p&gt;必要因数：必须满足的，比如团队技术栈和版权因数&#xA;可量化因数：非功能特性、技术标准&lt;/p&gt;&#xA;&lt;h3 id=&#34;可量化因数及权重&#34;&gt;可量化因数及权重&lt;/h3&gt;&#xA;&lt;h4 id=&#34;选出可量化因数&#34;&gt;选出可量化因数&lt;/h4&gt;&#xA;&lt;p&gt;选出哪些可以量化因数，有奇数位专家投票选出，超过半数确定。&lt;/p&gt;&#xA;&lt;p&gt;两轮：&#xA;第一轮从所有因数中投票&#xA;第二轮从没有超过半数的因数中重新投票&lt;/p&gt;&#xA;&lt;h5 id=&#34;算出可量化因数的权重&#34;&gt;算出可量化因数的权重&lt;/h5&gt;&#xA;&lt;p&gt;每个专家对上面选出的因数分配权重，总和位100%。然后，对每项因数获得权重求平均值，得到可量化因数的权重。&lt;/p&gt;&#xA;&lt;h3 id=&#34;候选技术&#34;&gt;候选技术&lt;/h3&gt;&#xA;&lt;p&gt;大范围的选择可以使用的技术，两个角度：&lt;/p&gt;</description>
    </item>
    <item>
      <title>RocketMQ HA实现</title>
      <link>http://zjykzk.github.io/posts/cs/rocketmq/ha/</link>
      <pubDate>Fri, 25 Jan 2019 15:35:52 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/rocketmq/ha/</guid>
      <description>&lt;h2 id=&#34;ha原理&#34;&gt;HA原理&lt;/h2&gt;&#xA;&lt;p&gt;RocketMQ支持主结点的数据同步到从结点。同步的数据依赖于当前从结点的状态。从结点连接到主结点的时候会上报自己的当前commitlog的最大偏移量。主结点收到以后会根据这个值计算出传输的起始位置，如果上报的commitlog的最大偏移量：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;等于0，主结点会从当前最大偏移量减去一个log文件大小那个位置开始传输。如果小于0，那么从0开始传输。&lt;/li&gt;&#xA;&lt;li&gt;大于0，从该值开始传输。&lt;/li&gt;&#xA;&lt;li&gt;小于0，这种情况不存在。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;所以，这里我们可以知道如果从结点已经就有数据情况，如果数据不是从主结点同步过来的，那么同步之后就会有问题了。比如说：从结点已经有10000条数据，同时某个topic，暂时就叫&lt;strong&gt;OLD_TOPIC&lt;/strong&gt;的&lt;em&gt;消费队列0&lt;/em&gt;长度1000。这个时候，主结点就会从第10000条数据开始同步，可能会发送几种情况：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;主结点没有10000数据，那么就不会同步数据，造成从结点上面数据丢失。&lt;/li&gt;&#xA;&lt;li&gt;主结点有超过10000数据，但是它的&lt;strong&gt;OLD_TOPIC&lt;/strong&gt;的&lt;em&gt;消费队列0&lt;/em&gt;的长度小于1000，那么同步过来的数据就会覆盖原来的数据。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;所以，从结点的初始状态需要从0开始或者本来就是和主同步过的状态。因此，在删除topic的时候从结点要保证删除干净，不然从结点就会脏数据，影响消费。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;为什么这样同步不会有问题呢？&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;那是因为同步的数据里面包含了具体消费队列ID，队列中的偏移量以及消息的偏移量，所以同步的时候能够写到同一个位置。&lt;/p&gt;&#xA;&lt;h2 id=&#34;主结点同步逻辑&#34;&gt;主结点同步逻辑&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/rocketmq/ha-master.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;发送一条消息的时候，在开启&lt;strong&gt;SYNC_MASTER&lt;/strong&gt;情况下，需要四个线程合作才能完成消息的发送。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;SendMessageProcessor&lt;/strong&gt;负责处理接收发送消息的请求并落盘（异步或者同步），接着向&lt;strong&gt;GroupTransferService&lt;/strong&gt;发送等待同步完成的请求，然后等待知道超时或者&lt;strong&gt;GroupTransferService&lt;/strong&gt;通知同步完成。同时，还会同时&lt;strong&gt;WriteSocketService&lt;/strong&gt;有数据可以写了。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;WriteSocketService&lt;/strong&gt;负责根据从结点上报的位置（变量&lt;code&gt;slaveRequestOffset&lt;/code&gt;），不断的向从结点传输数据。同时会维护和从结点的一个心跳，如果一段时间没有通不过数据，就会发送一个消息头，包含当前同步的起始位置。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;GroupTransferService&lt;/strong&gt;不断的轮询比较当前已经被从结点同步的最大偏移（变量&lt;code&gt;push2SlaveMaxOffset&lt;/code&gt;）和&lt;strong&gt;SendMessageProcessor&lt;/strong&gt;发送过来的请求中包含的偏移量，如果大于或者等于就会通知&lt;strong&gt;SendMessageProcessor&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;ReadSocketService&lt;/strong&gt;负责读取从结点上报上来的同步偏移量。更新变量&lt;code&gt;push2SlaveMaxOffset&lt;/code&gt;和&lt;code&gt;slaveRequestOffset&lt;/code&gt;并通知&lt;strong&gt;GroupTransferService&lt;/strong&gt;。从而，它也会影响&lt;strong&gt;WriteSocketService&lt;/strong&gt;的行为。同时，它还维护着和从结点连接的过期工作，如果超过指定时间没有收到消息就会断开连接，同时会停止&lt;strong&gt;WriteSocketService&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;从结点同步逻辑&#34;&gt;从结点同步逻辑&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/rocketmq/ha-slave.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;从结点的同步逻辑相对简单主要做几件事情：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;管理和主结点的连接，如果超过一段时间没有收到主点结点的数据，就会断开连接。这个时间戳保存在变量&lt;code&gt;lastWriteTimestamp&lt;/code&gt;中，刚刚连接上主结点和从主结点读到数据都会更新该变量。&lt;/li&gt;&#xA;&lt;li&gt;上报当前commitlog的最大偏移量，该行为会发生三个地方：a.写完一个消息；b.处理完当前收到的所有数据；c.一段时间内没有收到主结点的数据。&lt;/li&gt;&#xA;&lt;li&gt;维护收到的数据。这里有两个接收数据的buffer，主要方便处理当一个buffer的空间用完以后处理剩余的消息。一个buffer的情况下，先拷贝到一个临时byte数据，然后再拷贝回去，需要两次内存拷贝。如果两个buffer只需要一次拷贝。&lt;/li&gt;&#xA;&lt;li&gt;写消息。把从主结点同步过来的数据写到磁盘。收到数据的时候会判断主结点发过来的偏移量是否等于自己当前的偏移量如果不一样就会断开和主结点的连接。&lt;/li&gt;&#xA;&lt;li&gt;任何从连接中读数据的时候如果有错误就会断开连接。&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>RocketMQ push模式的实现细节</title>
      <link>http://zjykzk.github.io/posts/cs/rocketmq/push-consumer/</link>
      <pubDate>Wed, 16 Jan 2019 16:54:09 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/rocketmq/push-consumer/</guid>
      <description>&lt;p&gt;Rocketmq使用常轮询的方式实现了push功能。主要包括几个组件：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;DefaultMQPushConsumerImpl：拉消息的类型。&lt;/li&gt;&#xA;&lt;li&gt;ProcessQueue：保存拉出来的消息。&lt;/li&gt;&#xA;&lt;li&gt;PullMessageService：执行拉消息服务。&lt;/li&gt;&#xA;&lt;li&gt;ConsumeMessageService：消费消息服务。&lt;/li&gt;&#xA;&lt;li&gt;ReblanceService：负载均衡服务。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;类关系&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/rocketmq/push-consumer-class.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;（真想吐槽！）&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;执行过程&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/rocketmq/push-consumer-active.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;defaultmqpushconsumerimpl&#34;&gt;DefaultMQPushConsumerImpl&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;DefaultMQPushConsumerImpl&lt;/code&gt;实现了消费者的接口。同时是个启动者，通过它直接或间接启动了拉消息服务，消费消息服务。&lt;/p&gt;&#xA;&lt;p&gt;其中提供了一个重要的接口&lt;code&gt;pullMessage&lt;/code&gt;。该接口的流程如下：&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/rocketmq/push-consumer-pull.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;在拉消息过程中，做了流控，防止拉的太快，消费的太慢。主要从三个方面检测：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;从某个消费队列拉取的等待消费的消息数量。如果超过阀值，延迟50ms后再次拉取消息。阀值默认是1000。如果设置了topic级别的阀值（默认没有限制），在队列负载均衡以后会重新计算，具体为topic级别的阀值除以当前负责的消费队列数量。主要配置变量：&lt;code&gt;DefaultMQPushConsumerImpl.pullThresholdForQueue&lt;/code&gt;和&lt;code&gt;DefaultMQPushConsumerImpl.pullThresholdForTopic&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;从某个消费队列拉取的等待消费的消息大小（只考虑body）。同样，超过阀值就会延迟50ms后再次拉取消息。阀值默认是100M。如果topic设置了级别（默认没有限制），队列负载均衡以后会重新计算队列的限制，具体为topic级别的阀值除以当前负责的消费队列数量。主要配置变量：&lt;code&gt;DefaultMQPushConsumerImpl.pullThresholdSizeForQueue&lt;/code&gt;和&lt;code&gt;DefaultMQPushConsumerImpl.pullThresholdSizeForTopic&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;在并发消费模式下，从某个消费队列拉取的等待消费的消息中，在消费队列中的最大位置和最小位置之间差别。如果超过阀值，也会延迟50ms后再拉取消息。默认是2000，这里可能会存在误判。因为，有条件拉取消息的时候，是有可能出现同一个消费队列中拉到的两个消息在队列中的位置距离很远。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;几个考虑：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;code&gt;NO_NEW_MSG/NO_MATCHED_MSG&lt;/code&gt;情况下，&lt;code&gt;correctTagsOffset&lt;/code&gt;的逻辑为什么需要考虑有没有消息？如果还有消息说明本地还没有消息没被消费，此时更新的offset是服务端返回的，存在比没有被消费的消息偏移量大的情况。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;code&gt;OFFSET_ILLEAGL&lt;/code&gt;的情况下为什么要过10s以后才去更新offsetstore，保存offset，在reblance中移除process queue？出现这个问题是因为&lt;code&gt;NO_MATCHED_LOGIC_QUEUE/NO_MESSAGE_IN_QUEUE/OFFSET_OVERFLOW_BADLY/OFFSET_TOO_SMALL&lt;/code&gt;这四种情况，而这些情况可能发生在服务端在恢复数据的时候，因此考虑是暂停消费这个队列。如果drop之后不延迟，就会有可能又去拉取消息了。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;processqueue&#34;&gt;ProcessQueue&lt;/h2&gt;&#xA;&lt;p&gt;保存push的消费者拉到的消息。同时，有序消费模式还记录了情况下正在消费的消息。&lt;/p&gt;&#xA;&lt;h2 id=&#34;pullmessageservice&#34;&gt;PullMessageService&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;PullMessageService&lt;/code&gt;只负责拉取消息，它会调用&lt;code&gt;DefaultMQPushConsumerImpl.pullMessage&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;当&lt;code&gt;ReblanceService&lt;/code&gt;执行负载均衡的时候如果发现被分配了新的消息队列就会最终调用&lt;code&gt;PullMessage.executePullRequestImmediately&lt;/code&gt;执行拉取消息。代码执行路径：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ReblanceService.run&#xA;-&amp;gt;MQClientInstance.doReblance&#xA;-&amp;gt;MQConsumerInnter.doReblance[DefaultMQPushConsumerImpl.doReblance]&#xA;-&amp;gt;ReblanceImpl.doReblance&#xA;-&amp;gt;ReblanceImpl.dispatchPullRequest[ReblancePushImpl.dispatchPullRequest]&#xA;-&amp;gt;DefaultMQPushConsumerImpl.executePullRequestImmediately&#xA;-&amp;gt;PullMessage.executePullRequestImmediately&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;另外，在&lt;code&gt;DefaultMQPushConsumerImpl.pullMessage&lt;/code&gt;执行时，也会根据条件调用&lt;code&gt;PullMessageService.executePullRequestImmediately&lt;/code&gt;、&lt;code&gt;PullMessageService.executeTaskLater&lt;/code&gt;或者&lt;code&gt;PullMessageService.executePullRequestLater&lt;/code&gt;触发拉取消息。&lt;/p&gt;&#xA;&lt;h2 id=&#34;consumemessageservice&#34;&gt;ConsumeMessageService&lt;/h2&gt;&#xA;&lt;p&gt;消费服务分并发消费和顺序消费，主要区别在于提交消费任务逻辑，消费逻辑和处理消费结果的逻辑，以及对message queue的处理逻辑。另外，顺序消费是指在同一个消费队列里面的消息顺序消费。&lt;/p&gt;&#xA;&lt;h3 id=&#34;提交消费任务&#34;&gt;提交消费任务&lt;/h3&gt;&#xA;&lt;p&gt;并发消费：把消息分成多个批次并发处理，一批多少个消息是自定义的，默认是1。如果提交异常，则延迟5s后提交。&lt;/p&gt;&#xA;&lt;p&gt;顺序消费：依赖于process queue是否正在被消费，这样避免同时消费多个不同的消息，不然就没法保证有序了。&lt;/p&gt;&#xA;&lt;h3 id=&#34;消费逻辑&#34;&gt;消费逻辑&lt;/h3&gt;&#xA;&lt;p&gt;下图中左边是&lt;em&gt;并发消费&lt;/em&gt;，右边是&lt;em&gt;顺序消费&lt;/em&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/rocketmq/push-consumer-consume.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;消费消息的时候，在可能停顿的执行点上面都加上了process queue是否已经drop的检查。&lt;/p&gt;&#xA;&lt;p&gt;因为提交任务的方式不一样导致了不同模式下面消费逻辑的差别。&lt;/p&gt;&#xA;&lt;p&gt;并发消费：只考虑当前的消息即可。&lt;/p&gt;&#xA;&lt;p&gt;顺序消费：从process queue中取消息。消费的时候需要确保：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;每个消费队列某一时候只有一个消费请求被执行。&lt;/li&gt;&#xA;&lt;li&gt;每个消费队列某一时刻只有一个地方在执行用户的消费逻辑。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;以上两个条件中只要一个条件不满足，就没法保证消息顺序消费。另外，第一个逻辑需要的锁，是因为消费慢，同时队列被分配别的消费者，在消费结束之前又分配回来了，就有可能导致1条件不满足，所以需要加锁。在代码层面第一个逻辑需要的锁已经确保了第二个逻辑。消费之前需要锁的原因是为了避免，用户还在消费的时候向broker解锁。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;锁的逻辑&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;只有message queue被锁住了才能消费。客户端向服务端发送锁的请求成功以后才算锁成功。同时锁会有一个过期时间。在客户端这边定时向broker发送锁的请求，所得粒度是group+clientID，过期时间是30s。在服务端这边，锁了的过期时间是60s，这个时间以后能够接收其他锁的请求。&lt;/p&gt;&#xA;&lt;p&gt;在负载均衡的时候，检查一个消费队列发现不属于自己或者长时间没有拉的时候就会把这个消费队列移除掉。移除的逻辑比较有意思，为了确保这个消费队列正在被消费不会被移除，这里使用了一个消费锁。移除的时候尝试获得这个锁，如果超过1s还没有获得就会等待下一次负载均衡的检查，如果获得了锁就会延迟20s再向broker发送解锁请求。这里的延迟，有个效果就是可能这时候已经向broker发送了拉消息的请求，如果在它返回之前又把队列分配给自己了，那么就有可能两个触发一个拉消息的请求，这个时候就会同时有两个拉消息的请求，那么拉出来重复的消息。&lt;/p&gt;&#xA;&lt;h3 id=&#34;处理消费结果&#34;&gt;处理消费结果&lt;/h3&gt;&#xA;&lt;p&gt;下图中左边是并发消费，右边是顺序消费。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/rocketmq/push-consumer-result.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;处理消费结果的逻辑主要是处理消费失败的消息。&lt;/p&gt;&#xA;&lt;p&gt;并发消费：如果是在广播模式下，直接丢弃了。如果是在集群模式下面会尝试把消息发回broker，如果发送失败的话，就会把这些发送失败的消息延迟提交消费。&lt;/p&gt;&#xA;&lt;p&gt;顺序模式：如果是&lt;code&gt;ROLLBACK&lt;/code&gt;，把消息放回，再次消费。如果是&lt;code&gt;SUSPEND_CURRENT_QUEUE_A_MOMENT&lt;/code&gt;则会判断是否需要停止一段时间再消费。通过检查消费次数，当超过预定的值（默认是没有限制）就会把消息发回broker。如果消息都已经发回broker，就提交消息接下去消费，否则就停一会，把当前的消息延迟提交消费。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;处理message queue&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;并发消费：定时清理长时间没法消费的消息，默认是15分钟。&lt;/p&gt;&#xA;&lt;p&gt;顺序消费：在集群模式下面，定时向broker锁住message queue，锁的粒度是group+clientID。&lt;/p&gt;</description>
    </item>
    <item>
      <title>RocketMQ offset管理</title>
      <link>http://zjykzk.github.io/posts/cs/rocketmq/offset/</link>
      <pubDate>Fri, 28 Dec 2018 16:03:51 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/rocketmq/offset/</guid>
      <description>&lt;h2 id=&#34;作用&#34;&gt;作用&lt;/h2&gt;&#xA;&lt;p&gt;记录每个消费队列的消费进度。以topic，group为单位。&lt;/p&gt;&#xA;&lt;h2 id=&#34;类型&#34;&gt;类型&lt;/h2&gt;&#xA;&lt;p&gt;根据保存的位置可以分为本地和远程两种类型。本地类型就是以文本文件的形式保存在客户端，内容是非正式的json数据，而远程类型是指数据保存在broker服务器上面，内容同样是非正式的json数据。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;代码&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;本地类型：&lt;code&gt;org.apache.rocketmq.client.consumer.store.LocalFileOffsetStore&lt;/code&gt;。&#xA;远程类型：&lt;code&gt;org.apache.rocketmq.client.consumer.store.RemoteBrokerOffsetStore&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;使用&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;默认情况，当消费模式是&lt;em&gt;广播&lt;/em&gt;的时候使用&lt;em&gt;本地类型&lt;/em&gt;，因为每个消费者管理自己的进度，而且是所有消费队列的进度，各个消费者之间也不会有消费进度的交集。当消费模式是&lt;em&gt;集群&lt;/em&gt;的时候使用&lt;em&gt;远程类型&lt;/em&gt;，因为消息被多个消费者消费，每个消费者只负责消费其中部分消费队列，在添加、删除消费者的时候，原来消费者负责的消费队列会动态变化，因此需要集中管理消费进度，不然就冲突了。&lt;/p&gt;&#xA;&lt;p&gt;但是，代码中依然提供了接口，让用户自己指定类型，比如可以保存数据到monogodb。&lt;/p&gt;&#xA;&lt;h2 id=&#34;存储&#34;&gt;存储&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;本地类型&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;数据保存在&lt;code&gt;$storeDir/.rocketmq_offsets/$clientID/$group/offsets.json&lt;/code&gt;中，里面的数据是非标准json数据，用的是阿里的fastjson这个库。其中&lt;code&gt;$storeDir&lt;/code&gt;是可以通过系统变量&lt;code&gt;rocketmq.client.localOffsetStoreDir&lt;/code&gt;配置，如果没有指定参数就使用HOME目录。&lt;code&gt;$clientID&lt;/code&gt;和&lt;code&gt;$group&lt;/code&gt;分别表示消费者的id和分组。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// example&#xA;{&amp;#34;offsetTable&amp;#34;:{{&amp;#34;brokerName&amp;#34;:&amp;#34;topic&amp;#34;,&amp;#34;queueId&amp;#34;:1,&amp;#34;topic&amp;#34;:&amp;#34;broker&amp;#34;}:0}}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;远程类型&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;数据保存在&lt;code&gt;$rootPath/config/consumerOffset.json&lt;/code&gt;文件中，里面的数据是非标准json数据，用的是阿里的fastjson这个库。&lt;code&gt;offsetTable&lt;/code&gt;中的key格式是&lt;code&gt;topic@group&lt;/code&gt;，value格式&lt;code&gt;queueID:offset&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// example&#xA;{&#xA;    &amp;#34;offsetTable&amp;#34;:{&#xA;        &amp;#34;test@benchmark_consumer_61&amp;#34;:{&#xA;            0:5280,1:5312,2:5312,3:5312&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;接口&#34;&gt;接口&lt;/h2&gt;&#xA;&lt;p&gt;通过接口类型&lt;code&gt;org.apache.rocketmq.client.consumer.store.OffsetStore&lt;/code&gt;抽象了消费进度的相关操作。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;load&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;在消费者启动的时候，需要把消费进度载入内存。只有本地类型会载入数据。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;updateOffset&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;更新消费队列的进度。可以选择在比当前消费进度大的时候才更新，这个目的主要用于push模式下面消息是并发消费的，这样每批消息完成以后更新进度是并发，可能会导致进度低的晚于进度高的更新，这个模式就是为了避免这个情况。代码在类&lt;code&gt;ConsumeMessageConcurrentlyService&lt;/code&gt;中。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;readOffset&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;读取消费队列的消费进度，数据存在内存和存储（本地或者broker服务）中，提供了三种读取的方式：1.内存；2.存储；3.先内存，如果没有后存储。在两个地方的实现中，从存储中读到数据以后会更新到内存。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;persistAll&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;持久化指定的多个消费队列的消费进度。本地类型的实现中只会持久化内存中的消费进度。远程类型除此之外，还会把指定的消费队列以外的那些队列从内存中移除。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;persist&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;持久化指定的单个消费队列的消费进度。只有远程类型实现了该接口。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;removeOffset&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;移除某个消费队列的消费进度。只有远程类型实现了该接口。&lt;/p&gt;&#xA;&lt;p&gt;&lt;code&gt;updateConsumeOffsetToBroker&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;更新消费队列到broker服务，只有远程类型实现了该接口。（这个设计好尴尬，本地类型需要么。。。）&lt;/p&gt;&#xA;&lt;h2 id=&#34;管理&#34;&gt;管理&lt;/h2&gt;&#xA;&lt;p&gt;&lt;code&gt;org.apache.rocketmq.client.impl.consumer.RebalanceImpl.updateProcessQueueTableInRebalance&lt;/code&gt;做消费的负载均衡时，会对消费进度做管理。这个过程通过对比新分配的消费队列（简称新队列）和&lt;code&gt;org.apache.rocketmq.client.impl.consumer.RebalanceImpl.processQueueTable&lt;/code&gt;维护的消费队列（简称旧队列），有几种情况：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果旧队列的消费队列不在新队列中，那么就会先持久化该队列的消费进度，再做删除操作。&lt;em&gt;push模式同时优势有序的集群消费还需要做外的事情。&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;如果如果旧队列的消费队列在新队列中，&lt;em&gt;push模式下检查是否过期，过期的化先持久化，再删除进度。&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;如果新队列的消费队列不在旧队列中，删除消费进度。本地模式不会做删除操作，远程模式会把内存中的消费进度删除掉。同时，push模式下面会从存储中拉取消费进度并保存到内存。&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>为什么main函数是终结者</title>
      <link>http://zjykzk.github.io/posts/cs/golang/how-main-goroutine-is-terminator/</link>
      <pubDate>Fri, 16 Nov 2018 14:13:32 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/golang/how-main-goroutine-is-terminator/</guid>
      <description>&lt;p&gt;来一个&lt;code&gt;hello, world!&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;package main&#xA;&#xA;func main() {&#xA;    println(&amp;#34;hello, world!&amp;#34;)&#xA;} // line 5&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;编译调试。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# go build -o debug_main main.go // 编译&#xA;# gdb debug_main                 // 开始调试&#xA;(gdb) b 5 // 在第5行打断点&#xA;(gdb) r   // 执行，这时代码停在第5行，还在main函数中，其实在二进制文件里面它符号是main_main&#xA;(gdb) s   // 单步往下走，进入runtime.main代码&#xA;runtime.main () at /home/zenk/tools/goroot/src/runtime/proc.go:207&#xA;207             if atomic.Load(&amp;amp;runningPanicDefers) != 0 {&#xA;(gdb) bt  // 查看调用栈&#xA;#0  runtime.main () at /home/zenk/tools/goroot/src/runtime/proc.go:207&#xA;#1  0x0000000000446891 in runtime.goexit () at /home/zenk/tools/goroot/src/runtime/asm_amd64.s:2361&#xA;#2  0x0000000000000000 in ?? ()&#xA;(gdb) s&#xA;216             if atomic.Load(&amp;amp;panicking) != 0 {&#xA;(gdb) s&#xA;220             exit(0)&#xA;(gdb) s&#xA;runtime.exit () at /home/zenk/tools/goroot/src/runtime/sys_linux_amd64.s:52&#xA;52              MOVL    code+0(FP), DI&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;从上面的结果可以知道，自己写的&lt;code&gt;main&lt;/code&gt;函数被编译成&lt;code&gt;main_main&lt;/code&gt;，然后被&lt;code&gt;runtime.main&lt;/code&gt;所调用。通过查看&lt;code&gt;runtime.main&lt;/code&gt;可以看到以下代码，说明它执行结束以后会调用&lt;code&gt;exit(0)&lt;/code&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>高可用</title>
      <link>http://zjykzk.github.io/posts/cs/dist/ha/</link>
      <pubDate>Fri, 02 Nov 2018 15:38:24 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/dist/ha/</guid>
      <description>&lt;h2 id=&#34;什么是高可用&#34;&gt;什么是高可用&lt;/h2&gt;&#xA;&lt;p&gt;平时经常提到一个服务可用性4个9，5个9，其实说的就是高可用。一个服务服务的时间越久可用性越高。因此，在设计时候需要考虑各种失败的情况，尽量减少服务不可用的时间。&lt;/p&gt;&#xA;&lt;h2 id=&#34;实现高可用原则&#34;&gt;实现高可用原则&lt;/h2&gt;&#xA;&lt;p&gt;实现高可用的大法就是&lt;strong&gt;多副本&lt;/strong&gt;，或者叫&lt;strong&gt;冗余&lt;/strong&gt;，或者叫&lt;strong&gt;集群&lt;/strong&gt;。一个服务有多个结点，一个结点挂了，其他结点照样能够提供服务。另外，还需要一个&lt;strong&gt;故障转移&lt;/strong&gt;大法，不然请求都打向那个挂的结点，照样是失败。最后，还需要&lt;strong&gt;伸缩&lt;/strong&gt;大法，能够动态调整资源应付请求量的变化。&lt;/p&gt;&#xA;&lt;h2 id=&#34;伸缩方案&#34;&gt;伸缩方案&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;DNS&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;使用方使用服务域名，动态添加删除DNS绑定的IP。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;服务发现机制&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;提供服务注册中心，服务提供者向注册中心注册服务地址，服务使用者从注册中心同步服务地址。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;配置文件&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;服务使用方通过配置控制可以使用的服务，并提供动态加载功能。&lt;/p&gt;&#xA;&lt;h2 id=&#34;常见服务的多副本实践&#34;&gt;常见服务的多副本实践&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;接入层&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;比如向nginx、apache这样的反向代理服务。通过keeplived+virtual ip实现故障转移，通过DNS实现可伸缩性。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;业务层&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;实现业务逻辑的服务。通过使用方探测服务是否可用实现故障转移，通过服务发现机制或者配置文件的方式实现可伸缩。这一层的服务要求是无状态的，不然伸缩的时候会对用户造成影响。比如，保存了用户session，如果删除一个服务，势必会导致用户重新登入。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;缓存层&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;高可用，有两种方案：1. 多个缓存服务，使用方多写多读方式做到故障转移； 2. 主从同步，主服务挂了从服务接管。缓存的目的是为了减少数据库的压力，因此这里缓存的细粒度化，可以使得缓存服务器挂了以后只会有一小部分数据失效，从而保护数据库。&lt;/p&gt;&#xA;&lt;p&gt;伸缩性，通过一致性hash实现。还需要考虑数据一致性问题，不同的一致性要求扩展的姿势不一样，尤其是强一致性情况下需要考虑：1. 读到过期数据，因为客户端更新配置有时间间隔，在这个间隔中会读到过期数据； 2. 读到脏数据：扩容然后缩容，就会出现扩容后结点缓存了新内容，新结点被缩容以后请求又回到了老结点。&lt;/p&gt;&#xA;&lt;p&gt;常用的缓存服务：memcached、redis。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;数据库层&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;高可用，主主方案，需要确保数据双向复制，使用方探测做故障转移；主从；主备。通过分表、分库（水平、垂直拆分）、定期滚动实现扩展性。&lt;/p&gt;&#xA;&lt;h2 id=&#34;影响可用性的几个地方&#34;&gt;影响可用性的几个地方&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;发布&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;灰度发布，同时支持回滚。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;服务&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;数量上N+2，N表示需要正常服务的数量，多出两个的原因是考虑热备容灾下，如果发布会失败就会失去热备容灾的功能。而发布失败概率不小。&lt;/p&gt;&#xA;&lt;p&gt;互备的服务必须对等，避免一大一小，或者互相依赖。&lt;/p&gt;&#xA;&lt;p&gt;流量控制：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;隔离互相冲突的请求。&lt;/li&gt;&#xA;&lt;li&gt;把消耗资源的请求限制在固定几个结点，避免这类请求把资源都占住影响其他请求。&lt;/li&gt;&#xA;&lt;li&gt;防止一些导致服务挂掉的请求，打到全部结点，就是挂了几台服务以后，把这个请求给屏蔽掉，这个比较难。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/7nfSvxZ4vJAxpIN5rCdaCw&#34;&gt;https://mp.weixin.qq.com/s/7nfSvxZ4vJAxpIN5rCdaCw&lt;/a&gt;&#xA;&lt;a href=&#34;https://dn-coding-net-production-pp.qbox.me/5c5eab94-4e42-4cd4-b827-8a3699204a31.png&#34;&gt;https://dn-coding-net-production-pp.qbox.me/5c5eab94-4e42-4cd4-b827-8a3699204a31.png&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>如何定位一个文件</title>
      <link>http://zjykzk.github.io/posts/cs/linux/open-file-progress/</link>
      <pubDate>Wed, 24 Oct 2018 14:57:53 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/linux/open-file-progress/</guid>
      <description>&lt;p&gt;linux的VFS包含4个重要概念：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;superblock，包含文件系统的信息，管理整个文件系统。&lt;/li&gt;&#xA;&lt;li&gt;inode，索引文件（index node），代表一个文件，包含文件的元数据和数据，不包含文件名。&lt;/li&gt;&#xA;&lt;li&gt;dentry，目录项，代表路径中的每个部分，包含文件路径到inode的映射。&lt;/li&gt;&#xA;&lt;li&gt;file，文件，是文件在进程中的表示。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;同时，在linux中一切兼文件，包括目录。目录的内容是文件名和inode号。&lt;/p&gt;&#xA;&lt;p&gt;当打开一个文件&lt;code&gt;/bin/vim&lt;/code&gt;，系统首先把路径分解成&lt;code&gt;/&lt;/code&gt;、&lt;code&gt;bin&lt;/code&gt;、&lt;code&gt;vim&lt;/code&gt;，根据dentry查&lt;code&gt;vim&lt;/code&gt;的inode，如果dentry还没有&lt;code&gt;bin&lt;/code&gt;，会根据superblock中&lt;strong&gt;根目录&lt;/strong&gt;的inode号得到它的子目录信息，其中就有&lt;code&gt;bin&lt;/code&gt;和它的inode，并把它放到dentry中，然后根据&lt;code&gt;bin&lt;/code&gt;的内容找到&lt;code&gt;vim&lt;/code&gt;的inode。最终，返回一个文件描述符（file descriptor）。&lt;/p&gt;</description>
    </item>
    <item>
      <title>slave和master同步连接经常重连，导致发送消息失败</title>
      <link>http://zjykzk.github.io/posts/cs/rocketmq/slave-sync-from-master-disconnect/</link>
      <pubDate>Mon, 22 Oct 2018 17:07:02 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/rocketmq/slave-sync-from-master-disconnect/</guid>
      <description>&lt;h2 id=&#34;缘起&#34;&gt;缘起&lt;/h2&gt;&#xA;&lt;p&gt;封装RocketMQ的组件boots-broker每天都返回几个的500。排查发现是因为slave向master同步消息的时候，由于没有及时向master报告自己的同步进度，从而master没有向slave及时同步消息，导致消息发送失败。&lt;/p&gt;&#xA;&lt;h2 id=&#34;排查过程&#34;&gt;排查过程&lt;/h2&gt;&#xA;&lt;p&gt;查看boots-broker日志，发现问题日志：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;[TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 1008ms, size of queue: 0&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;说明，RocketMQ处理发送消息比较慢。可是，从&lt;code&gt;size of queue&lt;/code&gt;可以看出，堆积的消息为0。&lt;/p&gt;&#xA;&lt;p&gt;查看机器资源消耗情况，发现资源都是充裕的。&lt;/p&gt;&#xA;&lt;p&gt;查看RocketMQ日志，发现store.log中有异常，master中的store.log周期性的发生以下日志：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;2018-10-22 15:44:07 INFO AcceptSocketService - HAService receive new connection, /10.38.34.27:54052&#xA;2018-10-22 15:44:07 INFO ReadSocketService - ReadSocketService service started&#xA;2018-10-22 15:44:07 INFO WriteSocketService - WriteSocketService service started&#xA;2018-10-22 15:44:08 INFO WriteSocketService - WriteSocketService service end&#xA;2018-10-22 15:44:12 INFO ReadSocketService - slave[/10.38.34.27:54052] request offset 157843228&#xA;2018-10-22 15:44:12 INFO WriteSocketService - master transfer data from 157843228 to slave[/10.38.34.27:54052], and slave request 157843228&#xA;2018-10-22 15:44:33 WARN ReadSocketService - ha housekeeping, found this connection[/10.38.34.27:54052] expired, 20019&#xA;2018-10-22 15:44:33 INFO ReadSocketService - ReadSocketService service end&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;从上可以看出，slave主动向master建立连接，5s之后发送自己当前同步的进度，master收到以后向slave发送同步数据，最后master由于slave的连接过期，主动断开连接。&lt;/p&gt;</description>
    </item>
    <item>
      <title>熔断</title>
      <link>http://zjykzk.github.io/posts/cs/dist/circuit-breaker/</link>
      <pubDate>Fri, 12 Oct 2018 14:23:18 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/dist/circuit-breaker/</guid>
      <description>&lt;h2 id=&#34;缘起&#34;&gt;缘起&lt;/h2&gt;&#xA;&lt;p&gt;在分布式系统中，会有很多的RPC调用，当某个服务超载时候，继续接收请求只会让系统变得不可用，甚至会导致多个系统的连锁反应。因此在这样的情况下，最好是把后续的请求挡住，直接返回错误。等到系统恢复正常以后再处理请求。熔断借鉴了电闸中的保险丝功能，当因为某个意外原因（比如插座进水导致短路）导致线路中的电流过大而产生大量热量，保险丝就会被融化掉，从而中断线路中的电流，防止事故发生。&lt;/p&gt;&#xA;&lt;h2 id=&#34;设计&#34;&gt;设计&lt;/h2&gt;&#xA;&lt;p&gt;通俗来说，它是一个服务代理（逻辑上说），监测服务的状态，决定是否处理当前的请求，如果不处理返回错误。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;服务状态&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;服务状态一般是通过记录请求失败的情况来表示，比如说服务因为文件句柄占用过多导致一致无法建立连接，从而请求失败，熔断器认为当前服务状态存在不可用情况。&lt;/p&gt;&#xA;&lt;p&gt;熔断器包含三个状态：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;关闭（Closed）状态：在这个状态下，请求都会被转发给后端服务。同时会记录请求失败的次数，当请求失败次数在一段时间超过一定次数就会进入&lt;strong&gt;打开&lt;/strong&gt;状态。另外，失败次数会在特定时间间隔内重置。最后，除了基于一段时间内失败次数这个条件以外还可以使用连续失败次数。&lt;/li&gt;&#xA;&lt;li&gt;打开（Open）状态：在这个状态下，熔断器会直接拒绝请求，返回错误，而不去调用后端服务。同时，会有一个定时器，时间到的时候会变成&lt;strong&gt;半打开&lt;/strong&gt;状态。目的假设服务会在一段时间内恢复正常。&lt;/li&gt;&#xA;&lt;li&gt;半打开（Half Open）状态：在这个状态下，熔断器会尝试把部分请求转发给后端服务，目的是为了探测后端服务是否恢复。当请求失败的情况下会进入&lt;strong&gt;打开&lt;/strong&gt;状态，成功情况下会进入&lt;strong&gt;关闭&lt;/strong&gt;状态，同时重置计数。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/circuit-breaker.png&#34; alt=&#34;circuit breaker&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;设计重点&#34;&gt;设计重点&lt;/h2&gt;&#xA;&lt;p&gt;在设计过程中需要考虑以下几个点。&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;错误类型。后端服务会因为不同的问题返回不同的错误信息。针对不同的错误信息，熔断器可以采取不同的策略。比如说，针对限流错误，可以采用重试，如果连接拒绝大概率是服务宕机了，这中情况直接返回错误就可以了。另外，根据不同的错误类型可以使用不同的熔断条件，比如超时的threshold为10， 而连接拒绝的threshold值为3。&lt;/li&gt;&#xA;&lt;li&gt;日志监控。熔断器记录状态变化以及失败的请求应该被记录下来。这些信息反应的服务质量。方便管理员进一步处理。&lt;/li&gt;&#xA;&lt;li&gt;测试服务可用。在&lt;strong&gt;半打开&lt;/strong&gt;状态下，可以通过定制的接口探测后端服务是否恢复，而不是用用户的请求来探测。可以提高服务的质量。&lt;/li&gt;&#xA;&lt;li&gt;返回错误。返回给用户的错误，区分后端服务返回的错误和熔断器产生的错误。&lt;/li&gt;&#xA;&lt;li&gt;手工重置。因为有时候后端服务恢复时间的不确定性，导致熔断器判断失误。提供手工重置，可以方便熔断器的状态切换。&lt;/li&gt;&#xA;&lt;li&gt;并发问题。熔断器需要做计数，多个请求之间存在数据竞争。需要避免熔断器自己的开销影响请求的响应时间。可以采用无锁计数实现。&lt;/li&gt;&#xA;&lt;li&gt;资源区分。有时候，资源是分布在不同的服务器上，是独立。最好，熔断器对请求也做资源区分，针对在不同资源请求做熔断，不然一个资源有问题会影响其他资源的访问。&lt;/li&gt;&#xA;&lt;li&gt;重试错误的请求。有时候，错误和请求的参数有关系。把这部分请求记录下来，可以准备探测后端服务是否恢复。但是要做好重复请求的处理，比如幂等。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;实现&#34;&gt;实现&lt;/h2&gt;&#xA;&lt;p&gt;Netflix中的&lt;a href=&#34;https://github.com/Netflix/Hystrix/wiki/How-it-Works#CircuitBreaker&#34;&gt;Hystrix&lt;/a&gt;有一个完整的实现。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/hystrix-circuit-breaker-1280.png&#34; alt=&#34;hystrix circuit breaker，图片来自hystrix的github wiki&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;流程如下：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;allowRequest()&lt;/code&gt;通过函数&lt;code&gt;isOpen()&lt;/code&gt;判断是否处理请求。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;isOpen()&lt;/code&gt;判断逻辑：&#xA;&lt;ul&gt;&#xA;&lt;li&gt;如果熔断器处在打开状态，并且定时没到，返回&lt;code&gt;false&lt;/code&gt;，请求处理完毕，否则进入半打开状态并返回&lt;code&gt;true&lt;/code&gt;，走下一步。&lt;/li&gt;&#xA;&lt;li&gt;如果最近一秒内失败率超过了某个百分比，返回&lt;code&gt;false&lt;/code&gt;，请求处理完毕，否则返回&lt;code&gt;true&lt;/code&gt;，走下一步。&lt;/li&gt;&#xA;&lt;li&gt;返回&lt;code&gt;true&lt;/code&gt;，走下一步。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;markSuccess(duration)&lt;/code&gt;，表示请求处理成功，更新处理成功次数和处理时间，同时如果熔断器处于打开状态，那么需要重置计数，并把状态变成关闭状态。&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;markFailure(duration)&lt;/code&gt;，表示请求处理失败，更新处理失败次数。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Hystrix维护了10个时间间隔为1秒的桶，用于记录请求处理结果成功、失败、超时、拒绝的数量。每过1秒就会创建一个新的桶，如果桶的数量超过10个，最旧的那个会被删除掉。&lt;/p&gt;</description>
    </item>
    <item>
      <title>guava中RateLimiter的设计</title>
      <link>http://zjykzk.github.io/posts/cs/design/guava-ratelimiter/</link>
      <pubDate>Thu, 11 Oct 2018 15:33:32 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/design/guava-ratelimiter/</guid>
      <description>&lt;p&gt;guava中的&lt;a href=&#34;https://github.com/google/guava/blob/master/guava/src/com/google/common/util/concurrent/RateLimiter.java#L131&#34;&gt;RateLimiter&lt;/a&gt;实现了比较有意思的功能：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;平滑。&lt;/li&gt;&#xA;&lt;li&gt;记录未使用的信息。&lt;/li&gt;&#xA;&lt;li&gt;保存下次请求被满足的时间。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;平滑&#34;&gt;平滑&lt;/h2&gt;&#xA;&lt;p&gt;通过令牌桶算法实现。&lt;/p&gt;&#xA;&lt;h2 id=&#34;记录未使用信息&#34;&gt;记录未使用信息&lt;/h2&gt;&#xA;&lt;p&gt;实现中通过&lt;code&gt;storedPermits&lt;/code&gt;表示有多长时间没有被使用了。这个信息可以处理资源的两种情况：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;资源充足。这个实现是Burst模式。&lt;/li&gt;&#xA;&lt;li&gt;资源超载。比如说缓存过期，导致请求处理变慢。这个实现是Warmup模式。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;code&gt;storedPermits&lt;/code&gt;的计算公式：&lt;code&gt;min(maxPermits, timeNotUsedMicros/coolDownIntervalMicros())&lt;/code&gt;，其中&lt;code&gt;coolDownIntervalMicros()&lt;/code&gt;和&lt;code&gt;maxPermits&lt;/code&gt;在不同模式下面计算方式不同。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Burst模式&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;当RateLimiter发现资源没有没使用一段时间以后，任务现在资源的十分充分的，当请求过来的时候直接可以满足。&lt;code&gt;storedPermits&lt;/code&gt;代表的就是当前充足资源的数量。&lt;/p&gt;&#xA;&lt;p&gt;另外，&lt;code&gt;coolDownIntervalMicros()&lt;/code&gt;返回&lt;code&gt;stableIntervalMicros&lt;/code&gt;，&lt;code&gt;maxPermits&lt;/code&gt;等于&lt;code&gt;permitsPerSecond&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Warmup模式&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;          ^ throttling&#xA;          |&#xA;    cold  +                  /&#xA; interval |                 /.&#xA;          |                / .&#xA;          |               /  .   ← &amp;#34;warmup period&amp;#34; is the area of the trapezoid between&#xA;          |              /   .     thresholdPermits and maxPermits&#xA;          |             /    .&#xA;          |            /     .&#xA;          |           /      .&#xA;   stable +----------/  WARM .&#xA; interval |          .   UP  .&#xA;          |          . PERIOD.&#xA;          |          .       .&#xA;        0 +----------+-------+--------------→ storedPermits&#xA;          0 thresholdPermits maxPermits&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上图是warmup模式消耗&lt;code&gt;storedPermits&lt;/code&gt;所需要时间的建模。&lt;/p&gt;</description>
    </item>
    <item>
      <title>限流</title>
      <link>http://zjykzk.github.io/posts/cs/dist/rate-limit/</link>
      <pubDate>Thu, 30 Aug 2018 16:48:26 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/dist/rate-limit/</guid>
      <description>&lt;h2 id=&#34;缘起&#34;&gt;缘起&lt;/h2&gt;&#xA;&lt;p&gt;为了保证API的可用性，以及系统的可靠性，需要为API限速。不然，API请求量大到系统无法处理时就会出现系统变慢，甚至宕机的情况。常见的限速场景：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;挡住某个用户的过多请求（用户激增或者恶意请求），确保正常处理其他用户请求。&lt;/li&gt;&#xA;&lt;li&gt;挡住过多的低优先级的请求，确保核心请求得到处理。&lt;/li&gt;&#xA;&lt;li&gt;由于系统内部错误，导致系统处理能力下降，调节系统的处理能力。&lt;/li&gt;&#xA;&lt;li&gt;挡住过多某类请求，确保其他请求可以得到处理。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;限速类型&#34;&gt;限速类型&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;请求限速&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;限制API在一秒中内能够处理的请求数量。如果超过这个数量，等待或者拒绝服务。通常情况下这个是首选。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;并发限制&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;针对资源敏感的请求，比如CPU密集型API，进行并发限制，限制某一时刻最多只有有限个请求正在被处理。防止因为这些请求占用资源，导致其他请求得不到处理。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;基于资源利用率限速&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;针对不同的请求分配了不同百分比的资源，当某一类请求超载时，对这类请求限速。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;基于worker限速&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;这个是基于代码特征的限速。每类API通过不同的worker线程负责处理，当worker线程中出现请求堆积时进行限速。&lt;/p&gt;&#xA;&lt;h2 id=&#34;限速结果&#34;&gt;限速结果&lt;/h2&gt;&#xA;&lt;p&gt;http服务的话按照场景返回429或者503。&lt;/p&gt;&#xA;&lt;h2 id=&#34;常用算法&#34;&gt;常用算法&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;计数&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;单位时间内计数，超过这个数量时，拒绝服务，每个单位时间开始后计数清零。缺点是在时间边界处，会超过上限。比如，每秒限速100，在0.9s的时候来了100个请求全部得到处理，在下一秒0.1s来了100个请求。在0.9s到1.1s这个范围小于1s，但是请求达到了200。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt; 0.1s 0.2s 0.3s 0.4s 0.5s 0.6s 0.7s 0.8s 0.9s 0.1s 0.2s&#xA;+----+----+----+----+----+----+----+----+----+----+----+---&#xA;| 0  | 0  | 0  | 0  | 0  | 0  | 0  | 0  | 100| 100| 0  | 0 &#xA;+----+----+----+----+----+----+----+----+----+----+----+---&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;队列&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;请求过来的时候，先如队列，处理逻辑处理队列中的请求。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;基于大小的队列：当队列大小超过一个阀值的时候，拒绝新来的请求。&lt;/li&gt;&#xA;&lt;li&gt;基于时间的队列：请求在队列里面的时间超过多长时间没有被处理，立即返回。RocketMQ就是采用这种方式。&lt;/li&gt;&#xA;&lt;li&gt;优先级队列：对请求做优先级分类，不同优先级的请求进入不同的队列。为了避免低优先级请求被饿死，需要对不同优先级队列分配不同的处理时间。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Leaky_bucket&#34;&gt;漏桶&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/leaky-bucket.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;有一个容量固定的桶，桶中的请求以恒定的速率被处理。请求过来的时候，尝试进入桶，当桶满时被丢弃。本质上是队列后面加一个速率限制器。&lt;/p&gt;&#xA;&lt;p&gt;漏桶还有一个变形，在漏桶前面加一个队列。当桶满的时候，先放入队列，这样可以保留一部分请求。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Token_bucket&#34;&gt;令牌桶&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/token-bucket.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;以恒定的速率向桶中加入token，当请求过来的时候从桶中获取token。如果桶空了，请求等待或者丢弃。相比漏桶令牌桶还可以做蓄水，当桶满的时候可以预留一部分token，可以做到突发(burst)的请求。&lt;/p&gt;&#xA;&lt;h2 id=&#34;实现&#34;&gt;实现&lt;/h2&gt;&#xA;&lt;p&gt;Guava中的&lt;a href=&#34;https://github.com/google/guava/blob/master/guava/src/com/google/common/util/concurrent/RateLimiter.java#L131&#34;&gt;RateLimter&lt;/a&gt;是一个平滑的基于令牌桶的实现，同时还实现了warm up特点的一个&lt;a href=&#34;https://github.com/google/guava/blob/master/guava/src/com/google/common/util/concurrent/RateLimiter.java#L161&#34;&gt;Ratelimiter&lt;/a&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>分布式ID生成算法</title>
      <link>http://zjykzk.github.io/posts/cs/dist/uuid/</link>
      <pubDate>Wed, 22 Aug 2018 11:08:28 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/dist/uuid/</guid>
      <description>&lt;p&gt;分布式Unique ID在分布式系统使用很广泛，常用的用途有：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;请求的ID，用于跟踪请求链路。&lt;/li&gt;&#xA;&lt;li&gt;消息队列中的unique id。&lt;/li&gt;&#xA;&lt;li&gt;业务对象的id。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;总结下生成分布式ID常用算法。&lt;/p&gt;&#xA;&lt;h2 id=&#34;数据库自增id&#34;&gt;数据库自增id&lt;/h2&gt;&#xA;&lt;p&gt;通过MySQL中的&lt;code&gt;auto_increment&lt;/code&gt;特性来实现数据库唯一的ID。问题是扩展性差，性能受限于一台机器。可以做的优化是使用多个数据库实例，设置相同的步长和不同的起始值，避免重复产生ID。通过一个这种方式可以利用多台机器的资源。同时，还有一个优化是获取ID的时候可以批量获取ID，这样可以减少DB的操作，减少响应时间。&lt;/p&gt;&#xA;&lt;p&gt;基于Redis，Postgres，Oracle也有类似的方案。&lt;/p&gt;&#xA;&lt;h2 id=&#34;uuid&#34;&gt;&lt;a href=&#34;http://www.ietf.org/rfc/rfc4122.txt&#34;&gt;UUID&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;UUID由&lt;code&gt;[0-9a-f-]&lt;/code&gt;字符组成，总共16个字节，转换成16进制的格式为：&lt;code&gt;XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;数据由5个部分组成：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;时间戳，占60位。&lt;/li&gt;&#xA;&lt;li&gt;时钟序列，占13位。&lt;/li&gt;&#xA;&lt;li&gt;结点编号，占48位。&lt;/li&gt;&#xA;&lt;li&gt;版本号，版本不同以上1-3个字段的数据来源也不一样，占4位。&lt;/li&gt;&#xA;&lt;li&gt;UUID类型，用于解析UUID数据中的意义，占3位。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;每个数据的位置：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;    0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7&#xA;   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+&#xA;   |                          time_low                             |&#xA;   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+&#xA;   |       time_mid                |         time_hi_and_version   |&#xA;   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+&#xA;   |clk_seq_hi_res |  clk_seq_low  |         node (0-1)            |&#xA;   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+&#xA;   |                         node (2-5)                            |&#xA;   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;time_hi_and_version&lt;/code&gt;的第4-7位是版本号，&lt;code&gt;clk_seq_hi_res&lt;/code&gt;的第5-7位是UUID类型编号。&lt;/p&gt;</description>
    </item>
    <item>
      <title>mongodb索引</title>
      <link>http://zjykzk.github.io/posts/cs/mongodb/</link>
      <pubDate>Fri, 20 Jul 2018 16:18:23 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/mongodb/</guid>
      <description>&lt;h2 id=&#34;默认索引&#34;&gt;默认索引&lt;/h2&gt;&#xA;&lt;p&gt;每个文档默认都有一个字段&lt;code&gt;_id&lt;/code&gt;，这个字段会自动生成唯一索引，这个索引无法删除。这个字段的值可以是用户指定，如果不指定mongodb会自动生成。&lt;/p&gt;&#xA;&lt;p&gt;生成的规则：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;|&amp;lt;-- 4 --&amp;gt;|&amp;lt;- 3 -&amp;gt;|&amp;lt;-2-&amp;gt;|&amp;lt;-- 3 --&amp;gt;|&#xA;+---------+-------+-----+---------+&#xA;|unix time| mid   | pid | counter |&#xA;+---------+-------+-----+---------+&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;包含四个字段：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;unix时间戳，4个字节&lt;/li&gt;&#xA;&lt;li&gt;机器id，3个字节&lt;/li&gt;&#xA;&lt;li&gt;进程id，2个字节&lt;/li&gt;&#xA;&lt;li&gt;计数器，3个字节，自增，从一个随机数开始&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;索引类型&#34;&gt;索引类型&lt;/h2&gt;&#xA;&lt;h3 id=&#34;单字段索引&#34;&gt;单字段索引&lt;/h3&gt;&#xA;&lt;p&gt;文档中的任何字段或者子文档的字段都可以当作索引，字段的值也可以是一个文档。&lt;/p&gt;&#xA;&lt;h3 id=&#34;复合索引compound-index&#34;&gt;复合索引（compound index）&lt;/h3&gt;&#xA;&lt;p&gt;一个文档中的多个字段组成一个索引。最多支持31个字段。&lt;/p&gt;&#xA;&lt;h4 id=&#34;prefixes&#34;&gt;Prefixes&lt;/h4&gt;&#xA;&lt;p&gt;当查询的条件是索引的前面几个字段时会使用复合索引。&lt;/p&gt;&#xA;&lt;p&gt;比如：有索引&lt;code&gt;{a:1,b:1,c:1}&lt;/code&gt;，查询条件&lt;code&gt;{a:&amp;quot;a&amp;quot;,b:&amp;quot;b&amp;quot;}&lt;/code&gt;就会使用这个索引，但是&lt;code&gt;{b:&amp;quot;b&amp;quot;}&lt;/code&gt;这样的查询条件就无法使用。&lt;/p&gt;&#xA;&lt;h4 id=&#34;排序&#34;&gt;排序&lt;/h4&gt;&#xA;&lt;p&gt;索引的顺序先按第一个字段排序，如果第一个字段相等，按照第二个字段排序，依次类推后面的字段顺序。因此，&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果有以下索引&lt;code&gt;{a:1,b:1}&lt;/code&gt;，支持排序&lt;code&gt;{a:-1,b:-1}/{a:1:b:1}&lt;/code&gt;，不支持排序&lt;code&gt;{a:-1:b:1}/{a:1:b:-1}&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;只支持&lt;strong&gt;Prefixes&lt;/strong&gt;的排序。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;多值索引multikey-index&#34;&gt;多值索引（multikey index）&lt;/h3&gt;&#xA;&lt;p&gt;字段的值是一个数组，就会自动把这个索引变成多值索引，支持范围查询。&lt;/p&gt;&#xA;&lt;h3 id=&#34;地理空间索引geospatial-index&#34;&gt;地理空间索引（geospatial index）&lt;/h3&gt;&#xA;&lt;p&gt;包含两种索引：2d/2dsphere index&lt;/p&gt;&#xA;&lt;h3 id=&#34;文本索引text-indexes&#34;&gt;文本索引（text indexes）&lt;/h3&gt;&#xA;&lt;p&gt;作用于值是字符串或者是字符串数组的字段，查询字段中是否包含查询字符串。&lt;/p&gt;&#xA;&lt;h3 id=&#34;哈希索引hashed-indexes&#34;&gt;哈希索引（hashed indexes）&lt;/h3&gt;&#xA;&lt;p&gt;用于基于hash的sharding。&lt;/p&gt;&#xA;&lt;h3 id=&#34;交集索引index-intersection&#34;&gt;交集索引（index intersection）&lt;/h3&gt;&#xA;&lt;p&gt;如果查询条件中出现使用了多个索引，包括&lt;strong&gt;Prefixes&lt;/strong&gt;索引。mongodb可能会使用多个索引进行查询，然后取交集。是否使用了这个索引，可以通过&lt;code&gt;explain&lt;/code&gt;来确定。&lt;/p&gt;&#xA;&lt;p&gt;当查询需要排序，同时排序的字段需要的索引和查询条件无法组成一个或者部分&lt;code&gt;query predicate&lt;/code&gt;，那就无法使用这个索引了。&lt;/p&gt;&#xA;&lt;p&gt;比如：有索引&lt;code&gt;{a:1}/{b:1,c:1}&lt;/code&gt;，查询&lt;code&gt;db.col.find({a:&#39;a&#39;}).sort({b:1})&lt;/code&gt;无法使用，虽然排序中包含字段&lt;code&gt;b&lt;/code&gt;，但是查询条件中无法使用这个索引；而查询&lt;code&gt;db.col.find({a:&#39;a&#39;,b:&#39;b&#39;}).sort({c:1})&lt;/code&gt;却可以使用两个索引，这是因为查询条件中有&lt;code&gt;{b:&#39;b&#39;}&lt;/code&gt;和排序字段&lt;code&gt;{c:1}&lt;/code&gt;，索引&lt;code&gt;{b:1,c:1}&lt;/code&gt;组成部分查询条件。&lt;/p&gt;&#xA;&lt;h2 id=&#34;索引的属性&#34;&gt;索引的属性&lt;/h2&gt;&#xA;&lt;h3 id=&#34;唯一性&#34;&gt;唯一性&lt;/h3&gt;&#xA;&lt;p&gt;可以指定一个索引唯一。&lt;/p&gt;&#xA;&lt;h3 id=&#34;部分索引partial-indexes&#34;&gt;部分索引（partial indexes）&lt;/h3&gt;&#xA;&lt;p&gt;只索引满足条件的文档，它是稀疏索引的超集，相比稀疏索引采用部分索引。&lt;/p&gt;&#xA;&lt;h3 id=&#34;稀疏索引sparse-indexes&#34;&gt;稀疏索引（sparse indexes）&lt;/h3&gt;&#xA;&lt;p&gt;只索引存在该字段值的文档。&lt;/p&gt;&#xA;&lt;h4 id=&#34;ttltime-to-live索引&#34;&gt;TTL（time to live）索引&lt;/h4&gt;&#xA;&lt;p&gt;过期索引，针对值为日期或者日期数组的字段。如果字段值超过了过期日期，就会自动删除。过期时间可以动态修改的，有两种方式指定过期行为：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;指定字段日期和过期时长。&lt;/li&gt;&#xA;&lt;li&gt;指定过期日期，同时过期时长为0。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;优化&#34;&gt;优化&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果查询的内容和条件都只引用索引时，那么只需要扫描索引数据，不需要查询文档内容。&lt;/li&gt;&#xA;&lt;li&gt;background构建，增量式构建索引。构建时，可以处理其他请求，但是构建索引的请求会被阻塞。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;限制&#34;&gt;限制&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;每个index entry的大小不能超过1024字节，超过这个大小的文档会无法插入。&lt;/li&gt;&#xA;&lt;li&gt;每个collection最多拥有64个索引。&lt;/li&gt;&#xA;&lt;li&gt;索引名字长度 最多128字符，名字规范：&lt;!-- raw HTML omitted --&gt;.&lt;!-- raw HTML omitted --&gt;.$&lt;!-- raw HTML omitted --&gt; ，其中index name，默认是字段名字+类型，这个名字可以在创建索引的时候指定。&lt;/li&gt;&#xA;&lt;li&gt;复合索引最多允许使用31个字段。&lt;/li&gt;&#xA;&lt;li&gt;查询条件不能同时使用文本索引和地理空间索引。&lt;/li&gt;&#xA;&lt;li&gt;2dsphere index的值只能是几何数据。&lt;/li&gt;&#xA;&lt;li&gt;多值索引无法做cover query优化，比如：字段&lt;code&gt;{a:[{b:1},{b:2}]}&lt;/code&gt;。&lt;/li&gt;&#xA;&lt;li&gt;地理空间索引无法做cover query优化。&lt;/li&gt;&#xA;&lt;li&gt;构建索引的请求执行时构建会有一个内存限制，超过这个限制会使用临时文件。可以阀值可以修改。&lt;/li&gt;&#xA;&lt;li&gt;text/2d/geoHaystack索引无法使用collation。&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>接口在哪里定义？</title>
      <link>http://zjykzk.github.io/posts/cs/design/interface-owner/</link>
      <pubDate>Sun, 15 Jul 2018 15:11:11 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/design/interface-owner/</guid>
      <description>&lt;p&gt;接口放在哪里决定了源代码依赖问题。因此，依赖是接口定义唯一考量，其他问题都可以归结为依赖问题，而定义的包永远是被依赖包。&lt;/p&gt;&#xA;&lt;p&gt;接口定义的位置有三种情况：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;使用者&lt;/li&gt;&#xA;&lt;li&gt;实现者&lt;/li&gt;&#xA;&lt;li&gt;单独一个第三方位置&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;strong&gt;放在使用者这边&lt;/strong&gt;，那么实现者依赖使用者的接口定义。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;好处&lt;/strong&gt;：可以并行开发，尤其是类似golang这样的语言，实现一接口不需要引用具体的接口定义，即使在必须引用的开发语言里面也只需要实现相关的接口，集成的时候加上是很简单的。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;坏处&lt;/strong&gt;：在实现者依赖接口定义源代码的情况下，实现者代码要提出来重用，必须要得要包含使用者的接口定义&lt;/p&gt;&#xA;&lt;p&gt;这样的方式比较适合多个使用者，单个实现者的情况。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;放在实现者这边&lt;/strong&gt;，那么使用者依赖实现者的接口定义。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;好处&lt;/strong&gt;：实现者是一个独立的包，可以很方便的重用。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;坏处&lt;/strong&gt;：使用者开发的时候需要引用实现者的接口定义，增加并行开发的难度，这里可以自己mock接口，集成的时候改成实现者的接口即可。&lt;/p&gt;&#xA;&lt;p&gt;这样的方式适合单个使用者，多个实现者情况。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;单独放在第三方位置&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;好处&lt;/strong&gt;：定义完接口以后，使用者和实现者都可以并行开发，同时实现者包的重用和使用者解耦。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;坏处&lt;/strong&gt;：包的管理变得复杂，包含接口的包会变得很薄&lt;/p&gt;&#xA;&lt;p&gt;这样的方式适合多个使用者，多个实现者情况。&lt;/p&gt;&#xA;&lt;h2&gt;&lt;/h2&gt;</description>
    </item>
    <item>
      <title>常用面向对象设计原则</title>
      <link>http://zjykzk.github.io/posts/cs/design/soild/</link>
      <pubDate>Wed, 04 Jul 2018 22:28:20 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/design/soild/</guid>
      <description>&lt;h2 id=&#34;设计&#34;&gt;设计&lt;/h2&gt;&#xA;&lt;p&gt;软件的复杂来源于需求的易变，意味着软件本身容易修改。好设计的目的就是提供软件的可修改能力，也就是可维护性、扩展性。SOILD原则就是在设计过程中达到这个目标的一些原则。&lt;/p&gt;&#xA;&lt;h2 id=&#34;单一职责原则&#34;&gt;单一职责原则&lt;/h2&gt;&#xA;&lt;p&gt;又名SRP（Single Responsibility Principle）。针对一个函数、类、组件、架构的修改有且只有一个理由，而理由的来自于使用者。&lt;/p&gt;&#xA;&lt;p&gt;这样的好处是把拥有相同修改理由的函数、类、组件组织在一起，不同的分开，达到修改的时候不会影响其他代码，增强了可维护性。&lt;/p&gt;&#xA;&lt;p&gt;这是一个定义简单，实操不容易正确的原则。原因在于：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;职责&lt;/strong&gt;无法度量。&lt;/li&gt;&#xA;&lt;li&gt;因为团队、项目背景等待原因，在具体实现的细节中很难做到SRP。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;因此，在设计的时候接口一定做到SRP，实现尽量SRP。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;注：&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;组件层面的SRP，叫做Component common closure，架构层面的SRP叫做axis of change responsibility for creation of architecture boundary。&lt;/p&gt;&#xA;&lt;h2 id=&#34;开闭原则&#34;&gt;开闭原则&lt;/h2&gt;&#xA;&lt;p&gt;又名OCP（Open-Close Principle）。对扩展开发，对修改关闭。&lt;/p&gt;&#xA;&lt;p&gt;通过这样的方式达到添加一个功能时，尽可能少的修改现有源代码、模块、二进制文件，尽可能的通过添加代码来实现。这样减少原来的功能被破坏的概率，达到软件的可维护性、可扩展性、可复用性。因此，它是其他面向对象设计原则的核心。&lt;/p&gt;&#xA;&lt;p&gt;遵守OCP原则的手段是&lt;strong&gt;抽象&lt;/strong&gt;。一个功能的抽象，更依赖于使用者，而非实现者。只有使用者才明白需要抽象什么内容。抽象的难点是找到易变的部分，一个指导原则是“快速失败，下不为例”，有以下几条参考实践：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;TDD，先写测试代码。&lt;/li&gt;&#xA;&lt;li&gt;更短的开发周期。&lt;/li&gt;&#xA;&lt;li&gt;先开发特性，后开发基础设施代码，并经常给使用者review。&lt;/li&gt;&#xA;&lt;li&gt;先开发重要功能。&lt;/li&gt;&#xA;&lt;li&gt;经常并尽早发布，尽可能让用户和使用者使用。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;抽象的对象一般是类、模块以及组件。几个比较的好的实践：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;在函数参数、类抽象中提供稳定的接口定义。&lt;/li&gt;&#xA;&lt;li&gt;通过元数据抽象逻辑，比如通过配置的形式表达逻辑。&lt;/li&gt;&#xA;&lt;li&gt;定义项目章程，建立团队文化，沉淀优秀的习惯，提高开发效率。&lt;/li&gt;&#xA;&lt;li&gt;在架构层面，分析功能变化的来源、时机以及原因，把功能划分为不同的组件，底层组件依赖高层组件，高层组件不会受到底层组件变化的影响，同时避免循环依赖。&lt;/li&gt;&#xA;&lt;li&gt;抽象的时候需要避免过度抽象，带来不必要的复杂度。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;里氏替换原则&#34;&gt;里氏替换原则&lt;/h2&gt;&#xA;&lt;p&gt;又名LSP（Liskov Substitutiion Principle）。基类能够被子类代替，并且保证程序行为不变。&lt;/p&gt;&#xA;&lt;p&gt;OCP的实现需要使用抽象和多态，静态语言中继承是多态的一个重要实现方式。LSP就是解决继承带来的一些问题，比如侵入性、耦合性、缺乏灵活性。遵守LSP能够更加容易遵守OCP，因为子类可以替换基类，达到不修改原来代码，通过扩展的方式，添加逻辑。提高程序的健壮性，版本升级的兼容性。&lt;/p&gt;&#xA;&lt;p&gt;继承中常说的IS-A，强调的是方法的行为，子类中的方法行为要和基类中的一致，而不是性质一致。这个行为需要从设计的使用者角度来判断模块。模块逻辑的一致性，说的就是这个行为需要一致。所以，IS-A语义是子类替换时，保证程序行为一致。&lt;/p&gt;&#xA;&lt;p&gt;虽然这里LSP强调代码中的继承，其实LSP也适用于其他约定的服务、组件，这些内容修改、替换以后都不应该影响原来程序的行为。&lt;/p&gt;&#xA;&lt;p&gt;几个比较好的实践：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;当子类中override的方法工作比较少时，可能违反LSP。&lt;/li&gt;&#xA;&lt;li&gt;采用DBC（design by contract）编程方法。约定方法的前置条件和后置条件，在LSP下，子类中的前置条件只能比基类的弱，而子类中的后置条件只能比基类的强。因为，如果子类中的前置条件强，那么替换以后原来基类的前置条件下的输入就没法满足了，同样如果子类的后置条件弱，那么方法的输出在一些情况下程序行为就会和原来的不一样。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;依赖反转原则&#34;&gt;依赖反转原则&lt;/h2&gt;&#xA;&lt;p&gt;又名DIP（Dependence Inversion Principle）。高层不依赖底层，依赖抽象，底层也只依赖抽象；抽象不依赖细节，细节依赖抽象。&lt;/p&gt;&#xA;&lt;p&gt;反转（inversion）包含两层含义：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;控制流和源代码依赖相反，a模块执行时会调用b模块函数，但是源代码层面来说b模块会依赖a模块。&lt;/li&gt;&#xA;&lt;li&gt;接口所有者，原先a模块使用b模块定义的接口，而现在接口放在了a模块中，从而从源代码层面来说b模块依赖a模块。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;为什么要依赖抽象？显然抽象比实现细节稳定。从编程语言角度上来说，接口变了实现不变，而实现变了，接口不一定变，显然接口更加稳定。因此，接口的稳定也十分重要。&lt;/p&gt;&#xA;&lt;p&gt;DIP能够减少类、模块之间的耦合，提供系统的稳定性，提高代码的复用性、可扩展性、可读性和可维护性。它是其他OO设计技巧的基础。&lt;/p&gt;&#xA;&lt;p&gt;建立依赖的方式：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;构造函数传递依赖对象。&lt;/li&gt;&#xA;&lt;li&gt;setter方法传递对象。&lt;/li&gt;&#xA;&lt;li&gt;接口声明依赖对象，接口中的方法参数、返回值中引用其他接口。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;几个比较好的实践：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;每个类尽量有接口或者抽象类。&lt;/li&gt;&#xA;&lt;li&gt;变量的表面类型尽量是接口、抽象类型或者是不易变的类。&lt;/li&gt;&#xA;&lt;li&gt;任何类不从易变的具体类派生。在维护代码的时候这个实践经常会被破坏。&lt;/li&gt;&#xA;&lt;li&gt;尽量不要override基类的方法。&lt;/li&gt;&#xA;&lt;li&gt;创建对象时考虑使用工厂模式。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;接口分离原则&#34;&gt;接口分离原则&lt;/h2&gt;&#xA;&lt;p&gt;又名ISP（Interface Segregation Principles）。使用者不应该依赖它不使用的方法。所以，分离的使用者意味着分离的接口。&lt;/p&gt;</description>
    </item>
    <item>
      <title>一致性hash算法</title>
      <link>http://zjykzk.github.io/posts/cs/dist/cons-hash/</link>
      <pubDate>Sat, 28 Apr 2018 13:58:46 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/dist/cons-hash/</guid>
      <description>&lt;h2 id=&#34;一致性hash&#34;&gt;一致性hash&lt;/h2&gt;&#xA;&lt;h3 id=&#34;目标&#34;&gt;目标&lt;/h3&gt;&#xA;&lt;p&gt;缓存的机器扩容、缩容时，尽量保持数据的命中率。常规的hash算法，&lt;code&gt;hash(key)mod N&lt;/code&gt; （N表示缓存结点），当N变化时同一个key查询的缓存结点都会变化，导致缓存没有命中，造成很大的数据库压力。&lt;/p&gt;&#xA;&lt;h3 id=&#34;原理&#34;&gt;原理&lt;/h3&gt;&#xA;&lt;p&gt;hash函数值大小32位，因此输出的范围是&lt;code&gt;0~2^32-1&lt;/code&gt;。把这个范围形成一个环，同时对数据进行hash计算以外，对缓存的机器也做hash计算。这些计算出来的值在这个环上都有对应的一个点。&lt;/p&gt;&#xA;&lt;p&gt;假设数据的hash值分别为&lt;code&gt;K1&lt;/code&gt;,&lt;code&gt;K2&lt;/code&gt;,&lt;code&gt;K3&lt;/code&gt;,&lt;code&gt;K4&lt;/code&gt;,&lt;code&gt;K5&lt;/code&gt;,&lt;code&gt;K6&lt;/code&gt;，以及缓存结点的hash值&lt;code&gt;H1&lt;/code&gt;,&lt;code&gt;H2&lt;/code&gt;,&lt;code&gt;H3&lt;/code&gt;,大小关系为&lt;code&gt;H1&amp;lt;K3&amp;lt;K4&amp;lt;K5&amp;lt;H2&amp;lt;K6&amp;lt;H3&amp;lt;K1&amp;lt;K2&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;每个数据所在的缓存结点是在这个环上顺时针方向遇到的第一个缓存结点既是。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/dist/ch1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;因此&lt;code&gt;K1&lt;/code&gt;,&lt;code&gt;K2&lt;/code&gt;落在&lt;code&gt;H1&lt;/code&gt;,&lt;code&gt;K3&lt;/code&gt;,&lt;code&gt;K4&lt;/code&gt;,&lt;code&gt;K5&lt;/code&gt;落在&lt;code&gt;H2&lt;/code&gt;,&lt;code&gt;K6&lt;/code&gt;落在&lt;code&gt;H3&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;添加一个新的缓存结点&lt;code&gt;H4&lt;/code&gt;，它的hash值落在&lt;code&gt;K4&lt;/code&gt;和&lt;code&gt;K5&lt;/code&gt;之间。按照规则，&lt;code&gt;K3&lt;/code&gt;,&lt;code&gt;K4&lt;/code&gt;将落在&lt;code&gt;H4&lt;/code&gt;，也就是说&lt;code&gt;K3&lt;/code&gt;,&lt;code&gt;K4&lt;/code&gt;将会失效而其他的数据不会影响。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/dist/ch2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;减少缓存结点&lt;code&gt;H3&lt;/code&gt;，&lt;code&gt;K6&lt;/code&gt;会受到影响，它将落在缓存结点&lt;code&gt;H1&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/dist/ch3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;在次基础上可以抽象出一层缓存的虚拟缓存结点，这样的好处是可以事先确定缓存结点数量，让数据均匀的分布在每个虚拟缓存结点上面。每个物理缓存结点对应一个或者多个缓存结点。如下图中，有个4个虚拟缓存结点&lt;code&gt;VH1/VH2/VH3/VH4&lt;/code&gt;，两个物理缓存结点&lt;code&gt;H1/H2&lt;/code&gt;，分别对应&lt;code&gt;VH1/VH2和VH3/VH4&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/dist/ch4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>golang中的tls</title>
      <link>http://zjykzk.github.io/posts/cs/golang/tls/</link>
      <pubDate>Tue, 27 Feb 2018 19:51:16 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/golang/tls/</guid>
      <description>&lt;p&gt;在golang中，为了性能的目的，当前执行的&lt;a href=&#34;https://github.com/golang/go/blob/release-branch.go1.8/src/runtime/runtime2.go#L332&#34;&gt;&lt;code&gt;g&lt;/code&gt;&lt;/a&gt;是保存在当前线程的TLS中的，而TLS的地址在结构体&lt;a href=&#34;https://github.com/golang/go/blob/release-branch.go1.8/src/runtime/runtime2.go#L412&#34;&gt;&lt;code&gt;m&lt;/code&gt;&lt;/a&gt;里面。问题是怎么放进去的呢？&lt;/p&gt;&#xA;&lt;p&gt;可以从程序的启动入手，顺藤摸瓜。&lt;/p&gt;&#xA;&lt;p&gt;编写一个打印&lt;code&gt;hello,world&lt;/code&gt;的程序&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;// hello.go&#xA;&#xA;package main&#xA;&#xA;func main() {&#xA;        print(&amp;#34;hello, world&amp;#34;)&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;编译生成可执行文件&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;go build -o hello hello.go&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;用gdb进行调试，找到程序的入口 &lt;a href=&#34;https://github.com/golang/go/blob/release-branch.go1.8/src/runtime/rt0_linux_amd64.s#L7&#34;&gt;&lt;code&gt;_rt0_amd64_linux&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;gdb hello&#xA;(gdb) info files&#xA;...&#xA;Entry point: 0x448f20&#xA;...&#xA;(gdb) list *0x448f20&#xA;0x448f20 is in _rt0_amd64_linux (/home/zenk/tools/goroot/src/runtime/rt0_linux_amd64.s:8)&#xA;3       // license that can be found in the LICENSE file.&#xA;4&#xA;5       #include &amp;#34;textflag.h&amp;#34;&#xA;6&#xA;7       TEXT _rt0_amd64_linux(SB),NOSPLIT,$-8&#xA;8               LEAQ    8(SP), SI // argv&#xA;9               MOVQ    0(SP), DI // argc&#xA;10              MOVQ    $main(SB), AX&#xA;11              JMP     AX&#xA;12&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;发现&lt;code&gt;_rt0_amd64_linux&lt;/code&gt;调用了&lt;a href=&#34;https://github.com/golang/go/blob/release-branch.go1.8/src/runtime/rt0_linux_amd64.s#L72&#34;&gt;&lt;code&gt;main&lt;/code&gt;&lt;/a&gt;函数，后者调用了&lt;a href=&#34;https://github.com/golang/go/blob/release-branch.go1.8/src/runtime/asm_amd64.s#L10&#34;&gt;&lt;code&gt;runtime.rt0_go&lt;/code&gt;&lt;/a&gt;。而在函数&lt;code&gt;runtime.rt0_go&lt;/code&gt;中&lt;/p&gt;</description>
    </item>
    <item>
      <title>vim常用操作</title>
      <link>http://zjykzk.github.io/posts/cs/vim-tips/</link>
      <pubDate>Wed, 10 Jan 2018 18:16:35 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/vim-tips/</guid>
      <description>&lt;ol&gt;&#xA;&lt;li&gt;在命令模式使用函数&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;:%s/ab(.*)c/\=submatch(1) . &amp;#39;test&amp;#39;/gc&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;窗口间切换&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;跳转至某个窗口：窗口number + c-w + w：&#xA;跳至当前位置的左边某个窗口：c-w &amp;lt;number&amp;gt;h&#xA;跳至当前位置的右边某个窗口：c-w &amp;lt;number&amp;gt;l&#xA;跳至当前位置的上边某个窗口：c-w &amp;lt;number&amp;gt;j&#xA;跳至当前位置的下边某个窗口：c-w &amp;lt;number&amp;gt;k&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;全文缩进&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;gg=G&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;4&#34;&gt;&#xA;&lt;li&gt;把数字替换成原来的数字减一&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;:%s/(\d+)/\=submatch(1)-1/gc&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;5&#34;&gt;&#xA;&lt;li&gt;移动屏幕&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;H // 把当前行的位置移到最上面&#xA;M // 把当前行的位置移到屏幕中间&#xA;L // 把当前的位置移到屏幕底部&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;6&#34;&gt;&#xA;&lt;li&gt;全局操作&lt;code&gt;g&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;:{range}g/patten/{range}/cmd // 后面的range是基于前面查询的结果&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;7&#34;&gt;&#xA;&lt;li&gt;移动窗口&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;CTRL-W [K/J/H/L/T] //  把窗口移到最上面、下面、左边、右边、新标签&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;8&#34;&gt;&#xA;&lt;li&gt;跳到某个字符的左（右）边&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;t{char} // 跳转到左边&#xA;T{char} // 跳转到右边&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;9&#34;&gt;&#xA;&lt;li&gt;在vim8的终端滚动&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Ctrl-w N&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>jit的基本原理以及实现</title>
      <link>http://zjykzk.github.io/posts/cs/jit/</link>
      <pubDate>Wed, 03 Jan 2018 15:12:25 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/jit/</guid>
      <description>&lt;h2 id=&#34;基本原理&#34;&gt;基本原理&lt;/h2&gt;&#xA;&lt;p&gt;JIT（Just-In-Time）是指程序运行的过程中生成可执行的代码。这里有两个工作：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;生成可以执行的代码&lt;/li&gt;&#xA;&lt;li&gt;执行代码&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;生成代码&#34;&gt;生成代码&lt;/h3&gt;&#xA;&lt;p&gt;生成的代码是平台相关，一般就是一些机器码。&lt;/p&gt;&#xA;&lt;h3 id=&#34;执行代码&#34;&gt;执行代码&lt;/h3&gt;&#xA;&lt;p&gt;生成的代码如果要被执行，必须要确保代码所在的内存拥有可执行的标志。在linux下面通过&lt;code&gt;mmap&lt;/code&gt;系统调用映射一块可执行的内存，然后把相关的代码复制到这块内存中。最后，把内存首地址转换成函数地址并进行调用。&lt;/p&gt;&#xA;&lt;h2 id=&#34;helloworld&#34;&gt;Hello，World&lt;/h2&gt;&#xA;&lt;p&gt;一个基于x86_64平台的JIT代码， 通过系统调用&lt;code&gt;write&lt;/code&gt;实现打印&lt;code&gt;hello,world！&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;h3 id=&#34;基于x86_64平台的jit代码&#34;&gt;基于x86_64平台的JIT代码&lt;/h3&gt;&#xA;&lt;p&gt;linux下面系统调用通过软中断来实现，参数通过寄存器来传递。寄存器的使用情况如下：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;+----------+--------+--------+--------+--------+--------+--------+&#xA;| Syscall #| Param 1| Param 2| Param 3| Param 4| Param 5| Param 6|&#xA;+----------+--------+--------+--------+--------+--------+--------+&#xA;| rax      |  rdi   |  rsi   |   rdx  |   r10  |   r8   |   r9   |&#xA;+----------+--------+--------+--------+--------+--------+--------+&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;系统调用&lt;a href=&#34;http://man7.org/linux/man-pages/man2/write.2.html&#34;&gt;write(int fd, const void *buf, size_t count)&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;参数&lt;code&gt;fd&lt;/code&gt;:文件描述符号&lt;/li&gt;&#xA;&lt;li&gt;参数&lt;code&gt;buf&lt;/code&gt;:输出的内存起始地址&lt;/li&gt;&#xA;&lt;li&gt;参数&lt;code&gt;count&lt;/code&gt;:输出的字节数&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;因此，x86_64平台下调用&lt;code&gt;write&lt;/code&gt;的机器码为&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;0:  48 c7 c0 01 00 00 00    mov    rax,0x1&#xA;7:  48 c7 c7 01 00 00 00    mov    rdi,0x1&#xA;e:  48 c7 c2 0c 00 00 00    mov    rdx,0xc&#xA;15: 48 8d 35 03 00 00 00    lea    rsi,[rip+0x4]        # 0x1f&#xA;1c: 0f 05                   syscall&#xA;1e: c3 cc                   ret&#xA;1f: 48 65 6c 6c 6f 20 57 6f 72 6c 64 21   // Hello World!&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中：&lt;/p&gt;</description>
    </item>
    <item>
      <title>rocketmq store模块</title>
      <link>http://zjykzk.github.io/posts/cs/rocketmq/store/</link>
      <pubDate>Fri, 08 Dec 2017 17:59:56 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/rocketmq/store/</guid>
      <description>&lt;h2 id=&#34;功能&#34;&gt;功能&lt;/h2&gt;&#xA;&lt;p&gt;store模块是rocketmq的核心模块。主要功能有：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;消息存储&lt;/li&gt;&#xA;&lt;li&gt;消息索引&lt;/li&gt;&#xA;&lt;li&gt;消费队列&lt;/li&gt;&#xA;&lt;li&gt;主从同步&lt;/li&gt;&#xA;&lt;li&gt;延迟消息&lt;/li&gt;&#xA;&lt;li&gt;清理过期的消息和消费队列&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;消息存储&#34;&gt;消息存储&lt;/h2&gt;&#xA;&lt;p&gt;负责消息存储，包括写消息，刷盘。&lt;/p&gt;&#xA;&lt;h3 id=&#34;消息文件&#34;&gt;消息文件&lt;/h3&gt;&#xA;&lt;p&gt;消息保存在默认值为&lt;code&gt;${user.home}\store\commitlog&lt;/code&gt;文件夹下，可以通过配置项&lt;code&gt;storePathCommitLog&lt;/code&gt;修改。所有的消息都写入一个逻辑文件，每个逻辑文件包含大小相等的物理文件。&lt;/p&gt;&#xA;&lt;h3 id=&#34;写消息&#34;&gt;写消息&lt;/h3&gt;&#xA;&lt;p&gt;写消息在不同的场景下面会有不同的逻辑。&lt;/p&gt;&#xA;&lt;h4 id=&#34;同步刷盘&#34;&gt;同步刷盘&lt;/h4&gt;&#xA;&lt;p&gt;每条消息要写到磁盘以后才算完成。&lt;/p&gt;&#xA;&lt;p&gt;在同步刷盘的场景下，会有一个定期检查消息是否已经写入磁盘的线程：&lt;code&gt;GroupCommitService&lt;/code&gt;，除了检查还会进行刷盘的操作 。写消息的时候会生成一个&lt;code&gt;GroupCommitRequest&lt;/code&gt;提交到&lt;code&gt;GroupCommitService&lt;/code&gt;，并等待被唤醒或者超时。当&lt;code&gt;GroupCommitService&lt;/code&gt;发现已经刷盘的最后一个消息的索引大于等于本消息的索引时就会唤醒&lt;code&gt;GroupCommitRequest&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;备注&lt;/strong&gt;：以上的场景还依赖于消息的属性&lt;code&gt;WAIT&lt;/code&gt;，只有该属性为空或者为&lt;code&gt;true&lt;/code&gt;才会执行同步刷盘逻辑，默认是空的。&lt;/p&gt;&#xA;&lt;h4 id=&#34;异步刷盘&#34;&gt;异步刷盘&lt;/h4&gt;&#xA;&lt;p&gt;在异步刷盘的场景下，会有一个把数据刷到磁盘的辅助线程：&lt;code&gt;FlushRealTimeService&lt;/code&gt;。写消息仅仅唤醒该线程就结束了写盘操作。&lt;/p&gt;&#xA;&lt;h4 id=&#34;主从同步&#34;&gt;主从同步&lt;/h4&gt;&#xA;&lt;p&gt;每条消息要等一个从broker同步完才算完成。&lt;/p&gt;&#xA;&lt;p&gt;在主从同步的场景下，会有一个定期检查消息是否已经被从broker同步的辅助线程：&lt;code&gt;GroupTransferService&lt;/code&gt;。写消息的时候会生成一个&lt;code&gt;GroupCommitRequest&lt;/code&gt;提交给&lt;code&gt;GroupTransferService&lt;/code&gt;，并等待被唤醒或者超时。当&lt;code&gt;GroupTransferService&lt;/code&gt;发现从broker已经同步的最后一个消息的索引大于本次消息的索引时就会唤醒&lt;code&gt;GroupCommitRequest&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;h4 id=&#34;写buffer&#34;&gt;写buffer&lt;/h4&gt;&#xA;&lt;p&gt;使用了写buffer以后，写消息的全部逻辑就是把消息写入buffer。同时，系统会有一个线程&lt;code&gt;CommitRealTimeService&lt;/code&gt;定期把消息写入文件。&lt;/p&gt;&#xA;&lt;h3 id=&#34;核心代码&#34;&gt;核心代码&lt;/h3&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;org.apache.rocketmq.store.CommitLog&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;消费队列&#34;&gt;消费队列&lt;/h2&gt;&#xA;&lt;p&gt;每个topic对应多个消费队列，这个是提高消费并发度的前提。&lt;/p&gt;&#xA;&lt;h3 id=&#34;结构&#34;&gt;结构&lt;/h3&gt;&#xA;&lt;p&gt;每个消费队列对应一个逻辑文件，文件中对应每个消息的内容大小是固定的20个字节，包含消息的偏移量，大小以及tag哈希值。&lt;/p&gt;&#xA;&lt;h4 id=&#34;文件目录&#34;&gt;文件目录&lt;/h4&gt;&#xA;&lt;p&gt;数据保存在目录&lt;code&gt;${rootpath}/consumequeue&lt;/code&gt;下面，&lt;code&gt;rootpath&lt;/code&gt; 通过配置项&lt;code&gt;storePathRootDir&lt;/code&gt;指定，默认的是&lt;code&gt;${user.home}/store&lt;/code&gt;。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;${rootpath}/consumequeue&#xA;└── 0%default                     // topic&#xA;    ├── 0                         // queue 0&#xA;    │   └── 00000000000000000000&#xA;    ├── 1                         // queue 1&#xA;    │   └── 00000000000000000000&#xA;    ├── 2                         // queue 2&#xA;    │   └── 00000000000000000000&#xA;    └── 3                         // queue 3&#xA;        └── 00000000000000000000&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&#34;队列元素&#34;&gt;队列元素&lt;/h4&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;|&amp;lt;----- 8 byte -----&amp;gt;|&amp;lt;- 4 byte -&amp;gt;|&amp;lt;------ 8 byte ------&amp;gt;|&#xA;+--------------------+------------+----------------------+&#xA;|   commitlog offset |   size     | message tag hash code|&#xA;+--------------------+------------+----------------------+&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;执行&#34;&gt;执行&lt;/h3&gt;&#xA;&lt;p&gt;通过线程&lt;code&gt;ReputMessageService&lt;/code&gt;的分派消息的逻辑执行。&lt;/p&gt;</description>
    </item>
    <item>
      <title>记一次mongo数据库优化经历</title>
      <link>http://zjykzk.github.io/posts/cs/first-optimal/</link>
      <pubDate>Tue, 24 Oct 2017 18:46:11 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/first-optimal/</guid>
      <description>&lt;h1 id=&#34;缘起&#34;&gt;缘起&lt;/h1&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;p&gt;最近，做一个项目：封装一个MQ，提供发送、拉取、查询的基本功能，需要保证一条消息只被消费一次。写完了基本功能以后，开始做benchmark。结果超级糟糕：&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: center&#34;&gt;发送线程数量&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: center&#34;&gt;消费线程数量&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: center&#34;&gt;发送TPS&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: center&#34;&gt;消费TPS&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;3&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;3&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;200-400&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;20-60&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;而且，随着消费线程的数量增加发送&amp;amp;消费的TPS都下降。&lt;/p&gt;&#xA;&lt;h1 id=&#34;排查&#34;&gt;排查&lt;/h1&gt;&#xA;&lt;h2 id=&#34;接口&#34;&gt;接口&lt;/h2&gt;&#xA;&lt;p&gt;一次发送涉及的数据库操作：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;一次topic查询&lt;/li&gt;&#xA;&lt;li&gt;一次跟MQ之间的RPC&lt;/li&gt;&#xA;&lt;li&gt;一次写统计数据&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;一次消费涉及的数据库操作：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;两次cas操作&lt;/li&gt;&#xA;&lt;li&gt;两次写统计操作&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;系统状态&#34;&gt;系统状态&lt;/h2&gt;&#xA;&lt;h3 id=&#34;磁盘io&#34;&gt;磁盘IO&lt;/h3&gt;&#xA;&lt;p&gt;通过命令 &lt;code&gt;iotop&lt;/code&gt; 发现：mongodb写磁盘速度最大2M/s。&lt;/p&gt;&#xA;&lt;h3 id=&#34;网络&#34;&gt;网络&lt;/h3&gt;&#xA;&lt;p&gt;通过命令 &lt;code&gt;nethogs&lt;/code&gt; 发现：mongodb的通信速度最大200+KB/s。&lt;/p&gt;&#xA;&lt;h3 id=&#34;系统总体情况&#34;&gt;系统总体情况&lt;/h3&gt;&#xA;&lt;p&gt;通过命令&lt;code&gt;vmstat&lt;/code&gt;发现：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;系统和用户的CPU使用率都超低，两者加起来不到5%，系统的中断和上下文切换非常高，特别是上下文切换，达到了十几万/s&lt;/li&gt;&#xA;&lt;li&gt;从缓存写到磁盘的io比较高好几百/s&lt;/li&gt;&#xA;&lt;li&gt;内存使用率非常低&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;结论&#34;&gt;结论&lt;/h3&gt;&#xA;&lt;p&gt;问题一定是使用mongodb上面。&lt;/p&gt;&#xA;&lt;h2 id=&#34;排查-1&#34;&gt;排查&lt;/h2&gt;&#xA;&lt;h3 id=&#34;profile程序&#34;&gt;profile程序&lt;/h3&gt;&#xA;&lt;p&gt;通过golang自带的profile功能，在程序里面添加profile代码，通过&lt;code&gt;go tool pprof&lt;/code&gt;对程序做profile，用 &lt;code&gt;go-torch&lt;/code&gt;生成火焰图。发现果不其然，一个请求过程中，数据操作耗时占整体的40%以上。&lt;/p&gt;&#xA;&lt;p&gt;发送消息火焰图&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/create.job.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;拉取消息火焰图&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/pull.job.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;确认消息火焰图&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/finish.job.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;通过看程序以及对需求的分析，程序可以做优化：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;统计数据可以不用每次都去写数据库，把它放在内存或者写本地磁盘，定期刷到数据库&lt;/li&gt;&#xA;&lt;li&gt;去重以后的消息，可以放在内存，减少拉取消息时候一次cas操作&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;mongodb&#34;&gt;mongodb&lt;/h3&gt;&#xA;&lt;p&gt;通过命令 &lt;code&gt;mongostat&lt;/code&gt; 查看mongodb的运行状态，发现随着消费线程并发的提高锁的百分比越来越高最后超过的90%。查看mongodb的版本是2.4.9，它用的数据库锁。换个mongodb版本，避免锁的开销，通过了解公司线上使用的版本3.0.15，并使用wireTiger存储引擎。果断按照这个环境进行benchmark，结果仍然不尽任意。查看&lt;strong&gt;profiler&lt;/strong&gt;，一个类似mysql的慢查询的命令。通过以下命令加上专家的讲解，从&lt;strong&gt;信息 nscannedObjects : 71040&lt;/strong&gt;，发现扫描对象比较多，从代码确认是缺少了一个索引。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;&amp;gt; db.setProfilingLevel(2);&#xA;{&amp;#34;was&amp;#34; : 0 , &amp;#34;slowms&amp;#34; : 100, &amp;#34;ok&amp;#34; : 1}       // &amp;#34;was&amp;#34; 表示旧的设置&#xA;&amp;gt; db.system.profile.find().sort({millis:-1}) // 列出耗时的操作，按照操作耗时排序，这条语句会列出扫描的对象数量，锁等关键信息&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;在程序里面加上索引，再次benchmark达到预期。&lt;/p&gt;</description>
    </item>
    <item>
      <title>map 内部实现</title>
      <link>http://zjykzk.github.io/posts/cs/golang/map/</link>
      <pubDate>Thu, 15 Jun 2017 19:13:25 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/golang/map/</guid>
      <description>&lt;h1 id=&#34;类型&#34;&gt;类型&lt;/h1&gt;&#xA;&lt;p&gt;golang中的map是一个 &lt;strong&gt;指针&lt;/strong&gt;。当执行语句 &lt;code&gt;make(map[string]string)&lt;/code&gt; 的时候，其实是调用了 &lt;code&gt;makemap&lt;/code&gt; 函数：&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// file: runtime/hashmap.go:L222&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;func&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;makemap&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;t&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;maptype&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;hint64&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;h&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;hmap&lt;/span&gt;, &lt;span style=&#34;color:#a6e22e&#34;&gt;bucket&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;unsafe&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Pointer&lt;/span&gt;) &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;hmap&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;显然，&lt;code&gt;makemap&lt;/code&gt; 返回的是指针。&lt;/p&gt;&#xA;&lt;h1 id=&#34;数据结构&#34;&gt;数据结构&lt;/h1&gt;&#xA;&lt;h2 id=&#34;hashmap&#34;&gt;hashmap&lt;/h2&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// hash map&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;type&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;hmap&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;struct&lt;/span&gt; {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 元素的个数 == len()返回的值，必须放在第一个位置因为 len函数需要使用&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;count&lt;/span&gt;     &lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// map标记:&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 1. key和value是否包指针&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 2. 是否正在扩容&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 3. 是否是同样大小的扩容&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 4. 是否正在 `range`方式访问当前的buckets&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 5. 是否有 `range`方式访问旧的bucket&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;flags&lt;/span&gt;     &lt;span style=&#34;color:#66d9ef&#34;&gt;uint8&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;B&lt;/span&gt;         &lt;span style=&#34;color:#66d9ef&#34;&gt;uint8&lt;/span&gt;  &lt;span style=&#34;color:#75715e&#34;&gt;// log_2(B) == bucket数量&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;noverflow&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;uint16&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;// overflow bucket的数量，是个近似值&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;hash0&lt;/span&gt;     &lt;span style=&#34;color:#66d9ef&#34;&gt;uint32&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;// hash种子&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;buckets&lt;/span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;unsafe&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Pointer&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;// bucket slice指针，如果count == 0，这里的值为 nil&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;oldbuckets&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;unsafe&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;Pointer&lt;/span&gt; &lt;span style=&#34;color:#75715e&#34;&gt;// bucket slice指针，仅当在扩容的时候不为nil&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;nevacuate&lt;/span&gt;  &lt;span style=&#34;color:#66d9ef&#34;&gt;uintptr&lt;/span&gt;        &lt;span style=&#34;color:#75715e&#34;&gt;// 扩容时已经移到新的map中的bucket数量&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 当key和value的类型不包含指针的时候，key和value就会做inline处理(怎么处理的)&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;// 保证overflow的bucket活着，不被gc回收&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;overflow&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;[]&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;&lt;span style=&#34;color:#a6e22e&#34;&gt;bmap&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;bucket&#34;&gt;bucket&lt;/h2&gt;&#xA;&lt;p&gt;每个bucket固定包含8个key和value。实现上面是一个固定的大小连续内存块，分成四部分：&lt;/p&gt;</description>
    </item>
    <item>
      <title>补码</title>
      <link>http://zjykzk.github.io/posts/cs/complement/</link>
      <pubDate>Tue, 30 May 2017 23:18:02 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/complement/</guid>
      <description>&lt;h2 id=&#34;加法&#34;&gt;加法&lt;/h2&gt;&#xA;&lt;p&gt;2个十进制数字的非正式算法：两个数字中相同位置的数相加，如果结果超过10产生进位，该进位在下一位数相加时加上。直到两个数字的所有位数都加完为止。&lt;/p&gt;&#xA;&lt;p&gt;考虑十进制的2位数加法，例如：16 + 26。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;    1 6&#xA;  + 2 6&#xA; -------&#xA;    4 2&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上例中的加法过程是：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;6+6&lt;/code&gt; 得2，产生进位&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;1 + 2 + 1&lt;/code&gt; 的4，其中最后加1是&lt;code&gt;1&lt;/code&gt;步骤的几位，最终结果是 &lt;code&gt;42&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;减法&#34;&gt;减法&lt;/h2&gt;&#xA;&lt;p&gt;2个10进制数字的非正式算法：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;如果被减数大于等于减数，两个数字中相同位置的数相减，如果被减数小于减数，从高位借一位，轮到高位计算时要多减去一个1。直到两个数字的所有位都减完为止。&lt;/li&gt;&#xA;&lt;li&gt;如果被减数小于减数，交互减数与被减数的位置进行 &lt;code&gt;1&lt;/code&gt; 操作，把结果加一个负号&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;考虑十进制的2位数减法，例如：16 - 25。&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;    1 6&#xA;  + 2 5&#xA; -------&#xA;    - 9&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;上例中的加法过程是：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;code&gt;16&lt;/code&gt; 比&lt;code&gt;25&lt;/code&gt;小，交换两个数的位置&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;5&lt;/code&gt;比 &lt;code&gt;6&lt;/code&gt; 小产生借位， &lt;code&gt;15-6&lt;/code&gt; 得到 &lt;code&gt;9&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;2-1-1&lt;/code&gt; 得到0，最后一个 &lt;code&gt;1&lt;/code&gt;是借位&lt;/li&gt;&#xA;&lt;li&gt;加上负号，最终的结果是 &lt;code&gt;-9&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;补码&#34;&gt;补码&lt;/h2&gt;&#xA;&lt;p&gt;加法需要记录进位，而减法需要记录借位，比较大小，记录符号。这样减法的复杂度就要比较加法高。&lt;/p&gt;&#xA;&lt;h3 id=&#34;减法变加法&#34;&gt;减法变加法&lt;/h3&gt;&#xA;&lt;p&gt;注意到&lt;code&gt;16-25=16+(-25)&lt;/code&gt;，如果&lt;code&gt;-25&lt;/code&gt;能够表示成一个正数，那么减法就变成了加法。&lt;/p&gt;&#xA;&lt;p&gt;2位10进制的整数范围0-99，取一半用来做正数和零，一半做负数，分布如下：&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;0 - 0&#xA;1 - 1&#xA;...&#xA;49 - 49&#xA;50 - -50&#xA;51 - -49&#xA;...&#xA;99 - -1&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;按照这个分布，&lt;code&gt;-25&lt;/code&gt;对应着&lt;code&gt;75&lt;/code&gt;，从而得到&lt;code&gt;16-25=16+75=91&lt;/code&gt;，再根据上面的正负数的分布&lt;code&gt;91&lt;/code&gt;就是&lt;code&gt;-9&lt;/code&gt;，完全与&lt;code&gt;16-25=-9&lt;/code&gt;吻合。&lt;/p&gt;</description>
    </item>
    <item>
      <title>GO 内存模型</title>
      <link>http://zjykzk.github.io/posts/cs/golang/go-memory-model/</link>
      <pubDate>Tue, 28 Mar 2017 11:22:09 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/golang/go-memory-model/</guid>
      <description>&lt;p&gt;内存模型定义了一系列的条件，在这些条件下，多个goroutine对一个变量进行读写，保证一个goroutine读取到的值是是另外一个goroutine写入的某个值。&lt;/p&gt;&#xA;&lt;h2 id=&#34;happens-before&#34;&gt;Happens Before&lt;/h2&gt;&#xA;&lt;p&gt;编译器会对程序做优化，比如指令重排。在go语言中规定，在同一个goroutine里面，程序表达的顺序就是读写的顺序。但是，多个goroutine执行同样的代码时，就会出现读写顺序不一样的情况。例如，代码：&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; = &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt; = &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt;);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在编译器的优化下，代码的执行顺序有可能变成下面这样的情况：&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt; = &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#a6e22e&#34;&gt;a&lt;/span&gt;);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt; = &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#a6e22e&#34;&gt;b&lt;/span&gt;);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;但是，多个goroutine执行时，就无法保证打印&lt;em&gt;a&lt;/em&gt;的时候，&lt;em&gt;b&lt;/em&gt;的值一定是1.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;happens before&lt;/strong&gt;定义了内存操作的顺序，它是一种偏序。&lt;em&gt;e1&lt;/em&gt; happens before &lt;em&gt;e2&lt;/em&gt;, &lt;em&gt;e2&lt;/em&gt; happens after &lt;em&gt;e1&lt;/em&gt; 。如果 &lt;em&gt;e1&lt;/em&gt; 既不happens before &lt;em&gt;e2&lt;/em&gt; 也不happens after &lt;em&gt;e2&lt;/em&gt; ，那么 &lt;em&gt;e1&lt;/em&gt; 和 &lt;em&gt;e2&lt;/em&gt; 是并发执行的。它有传递的性质（自反性，对称性就不考虑了）。这个关系就决定了共享变量在某个上下文下面读写顺序，那么它的具体值变化也就确定了。&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;在一个goroutine中，happens before的顺序就是代码表达的顺序。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;共享变量 &lt;em&gt;v&lt;/em&gt; 的读操作 &lt;em&gt;r&lt;/em&gt; ，能够读到是另一个对变量 &lt;em&gt;v&lt;/em&gt; 写操作 &lt;em&gt;w&lt;/em&gt; 写入的值的条件是：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;em&gt;w&lt;/em&gt; happens before &lt;em&gt;r&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;没有其他的对变量 &lt;em&gt;v&lt;/em&gt; 写操作happens before &lt;em&gt;r&lt;/em&gt; 并且happens after &lt;em&gt;w&lt;/em&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;这两个条件并不能保证有一个与 &lt;em&gt;r&amp;amp;w&lt;/em&gt; 没有任何happens before关系的对共享变量 &lt;em&gt;v&lt;/em&gt; 写操作 &lt;em&gt;w&amp;rsquo;&lt;/em&gt; 的存在，导致 &lt;em&gt;r&lt;/em&gt; 读到的是 &lt;em&gt;w&amp;rsquo;&lt;/em&gt; 的结果。所以，保证 &lt;em&gt;r&lt;/em&gt; 的结果是 &lt;em&gt;w&lt;/em&gt; 的值的条件是：&lt;/p&gt;</description>
    </item>
    <item>
      <title>字符串</title>
      <link>http://zjykzk.github.io/posts/cs/str/</link>
      <pubDate>Thu, 19 Jan 2017 14:05:14 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/str/</guid>
      <description>&lt;h1 id=&#34;为什么要字符&#34;&gt;为什么要字符&lt;/h1&gt;&#xA;&lt;p&gt;人类发明了文字，同时想用计算机来处理文字。由此，就产生了字符。每个字符代码一个文字的图形。&lt;/p&gt;&#xA;&lt;h1 id=&#34;字符串的表示&#34;&gt;字符串的表示&lt;/h1&gt;&#xA;&lt;p&gt;在计算机内部，只有01的信息。因此，为了能让计算机能够认识字符串，每个字符就的被映射成01数据。这个映射功能就叫编码。&lt;/p&gt;&#xA;&lt;h2 id=&#34;ascii&#34;&gt;ASCII&lt;/h2&gt;&#xA;&lt;p&gt;ASCII是美国19世纪60年代发明的一种编码，总共规定了128个字符，每个字符有1个字节大小。范围从0-127，比如&lt;code&gt;A&lt;/code&gt;的编码是&lt;code&gt;01000001&lt;/code&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;unicode&#34;&gt;Unicode&lt;/h2&gt;&#xA;&lt;p&gt;世界语言文字异常丰富，每个国家都有自己独特的语言文字。ASCII的编码无法编码所有的文字，因此产生了很多编码，比如中文的BIG5，GB2312等等。这些编码无法兼容，比如&lt;code&gt;中&lt;/code&gt;在GB2312编码是&lt;code&gt;1101011011010000&lt;/code&gt;，BIG5的编码是&lt;code&gt;1010010010100100&lt;/code&gt;。因此，Unicode就出现了。Unicode规定了每个字符的唯一编号，目前已经有100多万个字符。需要注意的是Unicode只规定了字符的编号，没有规定二进制的表示。&lt;/p&gt;&#xA;&lt;h2 id=&#34;utf8编码&#34;&gt;Utf8编码&lt;/h2&gt;&#xA;&lt;p&gt;utf8是Ken Thompson于1992年创建，现在已经标准化为RFC 3629。是目前使用最为广泛的unicode编码方式，其他的有utf-16，utf-32。它的特点是变长的，使用1-4个字节表示一个字符，不同的符号有不同的长度。&lt;/p&gt;&#xA;&lt;p&gt;utf8编码规则：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;  1. 一个字节的编码，最高位为0，其他的位表示unicode编号&#xA;  2. n个字节的编码（n&amp;gt;1），第一个字节的n位都是1，第n+1位是0，后面的每个字节的最高两位都是10，其余的位用来表示unicode编号&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;下表表示了utf8的编码，z表示用于编码的bit&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;unicode范围&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;utf8编码&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;十六进制表示&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;二进制表示&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;000000 - 00007F&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;0zzzzzzz&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;000080 - 0007FF&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;110zzzzz 10zzzzzz&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;000800 - 00D7FF/00E000 - 00FFFF&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;1110zzzz 10zzzzzz 10zzzzzz&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;010000 - 10FFFF&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;11110zzz 10zzzzzz 10zzzzzz 10zzzzzz&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h1 id=&#34;环境中的编码&#34;&gt;环境中的编码&lt;/h1&gt;&#xA;&lt;p&gt;一个程序读取字符的输入的时候，读取的是二进制的数据。如果程序需要理解这个字符串是什么意思，必须了解字符的编码。同理，程序输出字符串的时候必须告知字符串的编码，不然使用者就无法理解程序的输出。程序中遇到乱码的问题，都是因为一个程序输出的字符串的编码和另一个程序接受字符串时使用的编码不一致导致的。因此，在解决编码的问题的思路就是搞清楚涉及到了哪几个环境。&lt;/p&gt;&#xA;&lt;p&gt;比如：一个程序打印一个字符串到终端。程序的编码是utf8，终端显示的编码是gbk。这样就会造成乱码。&lt;/p&gt;&#xA;&lt;h1 id=&#34;不同语言的字符串的支持&#34;&gt;不同语言的字符串的支持&lt;/h1&gt;&#xA;&lt;h2 id=&#34;python-中的字符串&#34;&gt;python 中的字符串&lt;/h2&gt;&#xA;&lt;h3 id=&#34;python-2&#34;&gt;python 2&lt;/h3&gt;&#xA;&lt;h4 id=&#34;字符类型&#34;&gt;字符类型&lt;/h4&gt;&#xA;&lt;p&gt;分为byte字符串(str)和unicode(unicode)，前者的内容是字节，后者的内容是unicode中的编号。默认的是byte字符串。&lt;/p&gt;&#xA;&lt;h4 id=&#34;重要方法&#34;&gt;重要方法&lt;/h4&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# &amp;lt;type &amp;#39;str&amp;#39;&amp;gt; to &amp;lt;type &amp;#39;unicode&amp;#39;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 如果 s 是&amp;#39;unicode&amp;#39;类型，python会先通过encode函数把s转换成&amp;#39;str&amp;#39;类型&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# encode函数的encoding是sys.getdefaultencoding()的值&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;s&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;decode(encoding)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# &amp;lt;type &amp;#39;unicode&amp;#39;&amp;gt; to &amp;lt;type &amp;#39;str&amp;#39;&amp;gt;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 如果u是&amp;#39;str&amp;#39;类型，python会通过decode函数把u转换成&amp;#39;unicode&amp;#39;类型&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# decode函数的encoding是sys.getdefaultencoding()的值&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;u&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;encode(encoding)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 获取系统默认的编码&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;getdefaultencoding()&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 修改系统的默认编码&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;setdefaultencoding(encoding)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 修改代码&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; sys&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;reload(sys) &lt;span style=&#34;color:#75715e&#34;&gt;# 因为python初始化的时候会把setdefaultencoding方法给删除掉&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sys&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;setdefaultencoding(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;utf8&amp;#39;&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;codecs&#34;&gt;codecs&lt;/h4&gt;&#xA;&lt;p&gt;指定encoding参数生成file-object-like对象，利用：&lt;/p&gt;</description>
    </item>
    <item>
      <title>prometheus</title>
      <link>http://zjykzk.github.io/posts/cs/prometheus/</link>
      <pubDate>Sun, 09 Oct 2016 14:45:21 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/prometheus/</guid>
      <description>&lt;h2 id=&#34;架构&#34;&gt;架构&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/promutheus.arch.svg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;基本概念&#34;&gt;基本概念&lt;/h2&gt;&#xA;&lt;h3 id=&#34;数据模型&#34;&gt;数据模型&lt;/h3&gt;&#xA;&lt;p&gt;prometheus把数据当作时间序列进行存储。&#xA;每个时间序列通过 &lt;strong&gt;metric name&lt;/strong&gt;和 &lt;strong&gt;key-value pairs&lt;/strong&gt;(也叫做 &lt;strong&gt;label&lt;/strong&gt;)标识。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;metric name&lt;/strong&gt;表示需要进行测量的系统指标。&#xA;它允许包含ASCII字母，数字，下划线和分号。&#xA;正则表示为：[a-zA-Z_:][a-zA-Z0-9_:]*。&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;label&lt;/strong&gt;表示一个系统指标的维度，可以按照这个维度进行查询统计。&#xA;Label名字允许包含ASCII字母，数字以及下划线。&#xA;正则表示为：[a-zA-Z_][a-zA-Z0-9_]*。同时，“__”开头的名字系统保留的。&#xA;Label值允许任意的Unicode字符&lt;/p&gt;&#xA;&lt;h3 id=&#34;度量类型&#34;&gt;度量类型&lt;/h3&gt;&#xA;&lt;h4 id=&#34;counter&#34;&gt;Counter&lt;/h4&gt;&#xA;&lt;p&gt;累计统计度量的单个值。适用于只增不减度量，比如累计请求数量。&lt;/p&gt;&#xA;&lt;h4 id=&#34;gauge&#34;&gt;Gauge&lt;/h4&gt;&#xA;&lt;p&gt;统计度量的单个值。适用于可以增减的度量，比如当前的内存使用情况。&lt;/p&gt;&#xA;&lt;h4 id=&#34;histogram&#34;&gt;Histogram&lt;/h4&gt;&#xA;&lt;p&gt;统计度量事件发生的次数以及度量值的和。还支持统计小于某个阀值的度量事件发生的次数。&lt;/p&gt;&#xA;&lt;p&gt;这个度量类型有三个时间序列统计：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&amp;lt;base_name&amp;gt;_bucket{le=&amp;ldquo;upper inclusive bound&amp;rdquo;}：小于某个阀值的度量事件发生的次数&lt;/li&gt;&#xA;&lt;li&gt;&amp;lt;base_name&amp;gt;_sum：度量值的和&lt;/li&gt;&#xA;&lt;li&gt;&amp;lt;base_name&amp;gt;_count：度量事件发生的次数&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;summary&#34;&gt;Summary&lt;/h4&gt;&#xA;&lt;p&gt;统计度量时间发生的次数以及度量值的和。还支持统计某个百分比内的度量事件发生的次数。&lt;/p&gt;&#xA;&lt;p&gt;这个度量类型有三个时间序列统计：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&amp;lt;base_name&amp;gt;{quantile=&amp;quot;&amp;lt;p&amp;gt;&amp;quot;}：度量值在前百分之p的度量事件发生的次数&lt;/li&gt;&#xA;&lt;li&gt;&amp;lt;base_name&amp;gt;_sum：度量值的和&lt;/li&gt;&#xA;&lt;li&gt;&amp;lt;base_name&amp;gt;_count：度量事件发生的次数&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;job--instance&#34;&gt;Job &amp;amp; Instance&lt;/h3&gt;&#xA;&lt;p&gt;在prometheus里面对监控的对象分成Job和Instance。Instance代表一个监控的实例。比如&#xA;一个支付进程。Job代表一个监控的逻辑单位。&#xA;比如支付服务，它在多台机器上面部署着，每台机器对应一个Instance。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;job: payment-server&#xA;&lt;ul&gt;&#xA;&lt;li&gt;instance 1: 1.2.3.4:5678&lt;/li&gt;&#xA;&lt;li&gt;instance 2: 1.2.3.5:5689&lt;/li&gt;&#xA;&lt;li&gt;instance 3: 1.2.3.6:5689&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;自动生成的label和时间序列&#34;&gt;自动生成的label和时间序列&lt;/h4&gt;&#xA;&lt;p&gt;当prometheus抓取一个目标的时候，会自动生成时间序列以及label，用来标识抓取的目标状态。&lt;/p&gt;&#xA;&lt;p&gt;label:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;job: 配置好的job名字&lt;/li&gt;&#xA;&lt;li&gt;instance:&amp;lt;host&amp;gt;:&amp;lt;port&amp;gt;格式的url&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;时间序列：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;up{job=&amp;quot;&amp;lt;job-name&amp;gt;&amp;quot;, instance=&amp;quot;&amp;lt;host:port&amp;gt;&amp;quot;}：1 表示监控目标活着，0表示挂了&lt;/li&gt;&#xA;&lt;li&gt;scrape_duration_seconds{job=&amp;quot;&amp;lt;job-name&amp;gt;&amp;quot;, instance=&amp;quot;&amp;lt;host:port&amp;gt;&amp;quot;}：抓取日志的时间&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>增加bug的编程实践</title>
      <link>http://zjykzk.github.io/posts/cs/bug-op/</link>
      <pubDate>Sat, 04 Jun 2016 11:12:13 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/bug-op/</guid>
      <description>&lt;h2 id=&#34;思路不清晰&#34;&gt;思路不清晰&lt;/h2&gt;&#xA;&lt;p&gt;思路没有完全确定情况下写代码。造成不确定的情况有多方面：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;1. 求快，把相似的需求当做一样的需求&#xA;2. 缺少设计，大体明白实现方案，就开始编码&#xA;3. 知识不充分，集中在前端的css、布局&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;strong&gt;怎么办？&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;快是可以做到，心里不要慌就是。&lt;/em&gt;&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;1. 需求分析到位&#xA;2. 仔细查看现有的代码&#xA;3. 遗留代码多问老员工&#xA;4. 放下别人对你问代码时的负面情绪&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;h2 id=&#34;破窗原理&#34;&gt;破窗原理&lt;/h2&gt;&#xA;&lt;p&gt;在一个代码质量差的项目里面，就很容易被一种“别人也是这样，我也就这样得了”，尤其是在你不熟悉代码的情况下。&lt;strong&gt;短期内，代码是写给自己的，维护的人是自己，长期内是给别人的，对自己好就是对别人好，还有需要执行力。&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>flume</title>
      <link>http://zjykzk.github.io/posts/cs/flume/</link>
      <pubDate>Sun, 27 Mar 2016 22:17:17 +0800</pubDate>
      <guid>http://zjykzk.github.io/posts/cs/flume/</guid>
      <description>&lt;h1 id=&#34;架构&#34;&gt;架构&lt;/h1&gt;&#xA;&lt;p&gt;&lt;img src=&#34;../../imgs/flume.dot.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;概念&#34;&gt;概念&lt;/h1&gt;&#xA;&lt;h2 id=&#34;source&#34;&gt;source&lt;/h2&gt;&#xA;&lt;p&gt;数据的生成源。比如：读取一个本地文件，MQ等等。一个数据单元被封装成一个&lt;strong&gt;event&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;h3 id=&#34;event&#34;&gt;event&lt;/h3&gt;&#xA;&lt;p&gt;数据单元，从&lt;strong&gt;source&lt;/strong&gt;产生，直到被序列化到存储中。&lt;strong&gt;event&lt;/strong&gt;包含&lt;em&gt;header&lt;/em&gt;，&lt;em&gt;body&lt;/em&gt;两个部分：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;header: 一个map数据，可以被&lt;strong&gt;interceptor&lt;/strong&gt;引用&lt;/li&gt;&#xA;&lt;li&gt;body: 一个字节序列，具体日志数据&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;interceptor&#34;&gt;interceptor&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;source&lt;/strong&gt;读取一个&lt;strong&gt;event&lt;/strong&gt;在放到&lt;strong&gt;channel&lt;/strong&gt;中之前，&lt;strong&gt;event&lt;/strong&gt;可以被添加数据。比如说：采集机器的主机名称，时间戳。&lt;/p&gt;&#xA;&lt;h2 id=&#34;channel&#34;&gt;channel&lt;/h2&gt;&#xA;&lt;p&gt;数据队列，高可用的保障。&lt;strong&gt;source&lt;/strong&gt;产生的数据先放到这里，&lt;strong&gt;sink&lt;/strong&gt;接着从这里取出来放到存储当中。&lt;/p&gt;&#xA;&lt;h3 id=&#34;channel-selector&#34;&gt;channel selector&lt;/h3&gt;&#xA;&lt;p&gt;两个作用：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;复制：把一个&lt;strong&gt;event&lt;/strong&gt;写到一个或者多个&lt;strong&gt;channel&lt;/strong&gt;中&lt;/li&gt;&#xA;&lt;li&gt;路由：根据&lt;strong&gt;event&lt;/strong&gt;中的某个属性值，把数据写到指定的&lt;strong&gt;channel&lt;/strong&gt;中&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;sink&#34;&gt;sink&lt;/h2&gt;&#xA;&lt;p&gt;负责把&lt;strong&gt;channel&lt;/strong&gt;中的数据写入目标存储。&lt;/p&gt;&#xA;&lt;h3 id=&#34;sink-processor&#34;&gt;sink processor&lt;/h3&gt;&#xA;&lt;p&gt;选择&lt;strong&gt;sink&lt;/strong&gt;，在这里可以完成负载均衡和容错处理。&lt;/p&gt;&#xA;&lt;h3 id=&#34;event-serializer&#34;&gt;event serializer&lt;/h3&gt;&#xA;&lt;p&gt;把&lt;strong&gt;event&lt;/strong&gt;中的数据，转换成存储需要的格式。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
